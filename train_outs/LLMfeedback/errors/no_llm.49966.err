2025-06-07 10:54:20.798309: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1749268460.817844 3103735 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1749268460.823655 3103735 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1749268460.837507 3103735 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1749268460.837575 3103735 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1749268460.837586 3103735 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1749268460.837594 3103735 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-06-07 10:54:20.841879: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Detected CUDA files, patching ldflags
Could not load the custom kernel for multi-scale deformable attention: CUDA_HOME environment variable is not set. Please set it to your CUDA install root.
[rank: 0] Seed set to 42
/work/20010751/SemanticEditing/get_scenegraph.py:48: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  weights = torch.load(pth_path)
/home/20010751/.conda/envs/bksdm/lib/python3.12/site-packages/transformers/models/detr/feature_extraction_detr.py:50: FutureWarning: The class DetrFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use DetrImageProcessor instead.
  warnings.warn(
The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.
/home/20010751/.conda/envs/bksdm/lib/python3.12/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.
Some kwargs in processor config are unused and will not have any effect: candidate_resolutions, ignore_id, mask_prompt, image_mean, add_special_token, pad_token, image_token, image_std, sft_format, downsample_ratio, normalize, patch_size. 
DeepseekVLV2ForCausalLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
DeepseekV2ForCausalLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
/work/20010751/SemanticEditing/finetuning.py:106: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  weights = torch.load(pth_path)
/work/20010751/SemanticEditing/pretrained_frameworks/SceneGraph/egtr/model/deformable_detr.py:833: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(weights_path, map_location="cuda")
Some weights of DetrForSceneGraphGeneration were not initialized from the model checkpoint at ./pretrained_frameworks/SceneGraph/egtr/pretrained/deformable-detr and are newly initialized: ['connectivity_layer.layers.0.bias', 'connectivity_layer.layers.0.weight', 'connectivity_layer.layers.1.bias', 'connectivity_layer.layers.1.weight', 'connectivity_layer.layers.2.bias', 'connectivity_layer.layers.2.weight', 'final_obj_proj.bias', 'final_obj_proj.weight', 'final_sub_proj.bias', 'final_sub_proj.weight', 'proj_k.0.bias', 'proj_k.0.weight', 'proj_k.1.bias', 'proj_k.1.weight', 'proj_k.2.bias', 'proj_k.2.weight', 'proj_k.3.bias', 'proj_k.3.weight', 'proj_k.4.bias', 'proj_k.4.weight', 'proj_k.5.bias', 'proj_k.5.weight', 'proj_q.0.bias', 'proj_q.0.weight', 'proj_q.1.bias', 'proj_q.1.weight', 'proj_q.2.bias', 'proj_q.2.weight', 'proj_q.3.bias', 'proj_q.3.weight', 'proj_q.4.bias', 'proj_q.4.weight', 'proj_q.5.bias', 'proj_q.5.weight', 'rel_dist', 'rel_predictor.layers.0.bias', 'rel_predictor.layers.0.weight', 'rel_predictor.layers.1.bias', 'rel_predictor.layers.1.weight', 'rel_predictor.layers.2.bias', 'rel_predictor.layers.2.weight', 'rel_predictor_gate.bias', 'rel_predictor_gate.weight', 'triplet_dist']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of DetrForSceneGraphGeneration were not initialized from the model checkpoint at ./pretrained_frameworks/SceneGraph/egtr/pretrained/deformable-detr and are newly initialized because the shapes did not match:
- class_embed.0.bias: found shape torch.Size([91]) in the checkpoint and torch.Size([150]) in the model instantiated
- class_embed.0.weight: found shape torch.Size([91, 256]) in the checkpoint and torch.Size([150, 256]) in the model instantiated
- model.query_position_embeddings.weight: found shape torch.Size([300, 512]) in the checkpoint and torch.Size([200, 512]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/work/20010751/SemanticEditing/finetuning.py:119: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(ckpt_path, map_location="cpu")["state_dict"]
/home/20010751/.conda/envs/bksdm/lib/python3.12/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self.scaler = torch.cuda.amp.GradScaler(**kwargs)
06/07/2025 10:54:45 - INFO - __main__ - Distributed environment: DistributedType.MULTI_GPU  Backend: nccl
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: fp16

{'timestep_spacing', 'variance_type', 'clip_sample_range', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.
{'use_quant_conv', 'force_upcast', 'mid_block_add_attention', 'shift_factor', 'use_post_quant_conv', 'latents_mean', 'latents_std', 'scaling_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at pretrained_frameworks/pretrained_IEDMs/instruct-pix2pix.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
{'time_embedding_type', 'projection_class_embeddings_input_dim', 'timestep_post_act', 'mid_block_only_cross_attention', 'addition_time_embed_dim', 'conv_out_kernel', 'reverse_transformer_layers_per_block', 'time_embedding_dim', 'resnet_out_scale_factor', 'resnet_skip_time_act', 'dropout', 'cross_attention_norm', 'encoder_hid_dim_type', 'conv_in_kernel', 'encoder_hid_dim', 'class_embeddings_concat', 'attention_type', 'time_cond_proj_dim', 'num_attention_heads', 'addition_embed_type', 'transformer_layers_per_block', 'addition_embed_type_num_heads', 'time_embedding_act_fn'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing UNet2DConditionModel.

All the weights of UNet2DConditionModel were initialized from the model checkpoint at pretrained_frameworks/pretrained_IEDMs/instruct-pix2pix.
If your task is similar to the task the model of the checkpoint was trained on, you can already use UNet2DConditionModel for predictions without further training.
06/07/2025 10:54:45 - INFO - __main__ - Initializing the InstructPix2Pix UNet from the pretrained UNet.
06/07/2025 10:54:49 - INFO - __main__ - ***** Running training *****
06/07/2025 10:54:49 - INFO - __main__ -   Num examples = 5751
06/07/2025 10:54:49 - INFO - __main__ -   Num Epochs = 70
06/07/2025 10:54:49 - INFO - __main__ -   Instantaneous batch size per device = 64
06/07/2025 10:54:49 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 256
06/07/2025 10:54:49 - INFO - __main__ -   Gradient Accumulation steps = 4
06/07/2025 10:54:49 - INFO - __main__ -   Total optimization steps = 1610
06/07/2025 10:54:49 - INFO - __main__ -   LLM feedback start = 1449
  0%|          | 0/1610 [00:00<?, ?it/s]Steps:   0%|          | 0/1610 [00:00<?, ?it/s]/home/20010751/.conda/envs/bksdm/lib/python3.12/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
Steps:   0%|          | 0/1610 [00:15<?, ?it/s, lr=5e-5, step_loss=0.234]Steps:   0%|          | 0/1610 [00:22<?, ?it/s, lr=5e-5, step_loss=0.199]Steps:   0%|          | 0/1610 [00:29<?, ?it/s, lr=5e-5, step_loss=0.214]Steps:   0%|          | 1/1610 [00:37<16:48:38, 37.61s/it, lr=5e-5, step_loss=0.214]Steps:   0%|          | 1/1610 [00:37<16:48:38, 37.61s/it, lr=5e-5, step_loss=0.273]Steps:   0%|          | 1/1610 [00:45<16:48:38, 37.61s/it, lr=5e-5, step_loss=0.164]Steps:   0%|          | 1/1610 [00:53<16:48:38, 37.61s/it, lr=5e-5, step_loss=0.128]Steps:   0%|          | 1/1610 [01:01<16:48:38, 37.61s/it, lr=5e-5, step_loss=0.0796]Steps:   0%|          | 2/1610 [01:08<15:02:28, 33.67s/it, lr=5e-5, step_loss=0.0796]Steps:   0%|          | 2/1610 [01:08<15:02:28, 33.67s/it, lr=5e-5, step_loss=0.155] Steps:   0%|          | 2/1610 [01:15<15:02:28, 33.67s/it, lr=5e-5, step_loss=0.108]Steps:   0%|          | 2/1610 [01:23<15:02:28, 33.67s/it, lr=5e-5, step_loss=0.112]Steps:   0%|          | 2/1610 [01:33<15:02:28, 33.67s/it, lr=5e-5, step_loss=0.114]Steps:   0%|          | 3/1610 [01:40<14:41:48, 32.92s/it, lr=5e-5, step_loss=0.114]Steps:   0%|          | 3/1610 [01:40<14:41:48, 32.92s/it, lr=5e-5, step_loss=0.108]Steps:   0%|          | 3/1610 [01:48<14:41:48, 32.92s/it, lr=5e-5, step_loss=0.0943]Steps:   0%|          | 3/1610 [01:56<14:41:48, 32.92s/it, lr=5e-5, step_loss=0.0821]Steps:   0%|          | 3/1610 [02:04<14:41:48, 32.92s/it, lr=5e-5, step_loss=0.0943]Steps:   0%|          | 4/1610 [02:11<14:25:08, 32.32s/it, lr=5e-5, step_loss=0.0943]Steps:   0%|          | 4/1610 [02:11<14:25:08, 32.32s/it, lr=5e-5, step_loss=0.0831]Steps:   0%|          | 4/1610 [02:20<14:25:08, 32.32s/it, lr=5e-5, step_loss=0.0811]Steps:   0%|          | 4/1610 [02:28<14:25:08, 32.32s/it, lr=5e-5, step_loss=0.0733]Steps:   0%|          | 4/1610 [02:37<14:25:08, 32.32s/it, lr=5e-5, step_loss=0.0943]Steps:   0%|          | 5/1610 [02:44<14:31:05, 32.56s/it, lr=5e-5, step_loss=0.0943]Steps:   0%|          | 5/1610 [02:44<14:31:05, 32.56s/it, lr=5e-5, step_loss=0.0829]Steps:   0%|          | 5/1610 [02:53<14:31:05, 32.56s/it, lr=5e-5, step_loss=0.0903]Steps:   0%|          | 5/1610 [03:00<14:31:05, 32.56s/it, lr=5e-5, step_loss=0.101] Steps:   0%|          | 5/1610 [03:07<14:31:05, 32.56s/it, lr=5e-5, step_loss=0.0844]Steps:   0%|          | 6/1610 [03:14<14:02:50, 31.53s/it, lr=5e-5, step_loss=0.0844]Steps:   0%|          | 6/1610 [03:14<14:02:50, 31.53s/it, lr=5e-5, step_loss=0.0684]Steps:   0%|          | 6/1610 [03:21<14:02:50, 31.53s/it, lr=5e-5, step_loss=0.0863]Steps:   0%|          | 6/1610 [03:29<14:02:50, 31.53s/it, lr=5e-5, step_loss=0.0539]Steps:   0%|          | 6/1610 [03:38<14:02:50, 31.53s/it, lr=5e-5, step_loss=0.0699]Steps:   0%|          | 7/1610 [03:46<14:07:47, 31.73s/it, lr=5e-5, step_loss=0.0699]Steps:   0%|          | 7/1610 [03:46<14:07:47, 31.73s/it, lr=5e-5, step_loss=0.0568]Steps:   0%|          | 7/1610 [03:54<14:07:47, 31.73s/it, lr=5e-5, step_loss=0.0573]Steps:   0%|          | 7/1610 [04:02<14:07:47, 31.73s/it, lr=5e-5, step_loss=0.0476]Steps:   0%|          | 7/1610 [04:11<14:07:47, 31.73s/it, lr=5e-5, step_loss=0.0501]Steps:   0%|          | 8/1610 [04:18<14:10:54, 31.87s/it, lr=5e-5, step_loss=0.0501]Steps:   0%|          | 8/1610 [04:18<14:10:54, 31.87s/it, lr=5e-5, step_loss=0.0684]Steps:   0%|          | 8/1610 [04:26<14:10:54, 31.87s/it, lr=5e-5, step_loss=0.0756]Steps:   0%|          | 8/1610 [04:34<14:10:54, 31.87s/it, lr=5e-5, step_loss=0.0601]Steps:   0%|          | 8/1610 [04:43<14:10:54, 31.87s/it, lr=5e-5, step_loss=0.0647]Steps:   1%|          | 9/1610 [04:50<14:13:13, 31.98s/it, lr=5e-5, step_loss=0.0647]Steps:   1%|          | 9/1610 [04:51<14:13:13, 31.98s/it, lr=5e-5, step_loss=0.0543]Steps:   1%|          | 9/1610 [04:58<14:13:13, 31.98s/it, lr=5e-5, step_loss=0.0836]Steps:   1%|          | 9/1610 [05:05<14:13:13, 31.98s/it, lr=5e-5, step_loss=0.0748]Steps:   1%|          | 9/1610 [05:13<14:13:13, 31.98s/it, lr=5e-5, step_loss=0.0568]Steps:   1%|          | 10/1610 [05:22<14:08:05, 31.80s/it, lr=5e-5, step_loss=0.0568]Steps:   1%|          | 10/1610 [05:22<14:08:05, 31.80s/it, lr=5e-5, step_loss=0.0659]Steps:   1%|          | 10/1610 [05:29<14:08:05, 31.80s/it, lr=5e-5, step_loss=0.082] Steps:   1%|          | 10/1610 [05:38<14:08:05, 31.80s/it, lr=5e-5, step_loss=0.0486]Steps:   1%|          | 10/1610 [05:46<14:08:05, 31.80s/it, lr=5e-5, step_loss=0.0564]Steps:   1%|          | 11/1610 [05:54<14:10:32, 31.92s/it, lr=5e-5, step_loss=0.0564]Steps:   1%|          | 11/1610 [05:54<14:10:32, 31.92s/it, lr=5e-5, step_loss=0.0795]Steps:   1%|          | 11/1610 [06:03<14:10:32, 31.92s/it, lr=5e-5, step_loss=0.0713]Steps:   1%|          | 11/1610 [06:11<14:10:32, 31.92s/it, lr=5e-5, step_loss=0.0458]Steps:   1%|          | 11/1610 [06:20<14:10:32, 31.92s/it, lr=5e-5, step_loss=0.0588]Steps:   1%|          | 12/1610 [06:28<14:22:17, 32.38s/it, lr=5e-5, step_loss=0.0588]Steps:   1%|          | 12/1610 [06:28<14:22:17, 32.38s/it, lr=5e-5, step_loss=0.0769]Steps:   1%|          | 12/1610 [06:35<14:22:17, 32.38s/it, lr=5e-5, step_loss=0.0568]Steps:   1%|          | 12/1610 [06:43<14:22:17, 32.38s/it, lr=5e-5, step_loss=0.0494]Steps:   1%|          | 12/1610 [06:51<14:22:17, 32.38s/it, lr=5e-5, step_loss=0.0665]Steps:   1%|          | 13/1610 [06:59<14:16:50, 32.19s/it, lr=5e-5, step_loss=0.0665]Steps:   1%|          | 13/1610 [06:59<14:16:50, 32.19s/it, lr=5e-5, step_loss=0.0451]Steps:   1%|          | 13/1610 [07:06<14:16:50, 32.19s/it, lr=5e-5, step_loss=0.0729]Steps:   1%|          | 13/1610 [07:15<14:16:50, 32.19s/it, lr=5e-5, step_loss=0.0589]Steps:   1%|          | 13/1610 [07:22<14:16:50, 32.19s/it, lr=5e-5, step_loss=0.0582]Steps:   1%|          | 14/1610 [07:30<14:08:14, 31.89s/it, lr=5e-5, step_loss=0.0582]Steps:   1%|          | 14/1610 [07:30<14:08:14, 31.89s/it, lr=5e-5, step_loss=0.0522]Steps:   1%|          | 14/1610 [07:39<14:08:14, 31.89s/it, lr=5e-5, step_loss=0.0525]Steps:   1%|          | 14/1610 [07:47<14:08:14, 31.89s/it, lr=5e-5, step_loss=0.0512]Steps:   1%|          | 14/1610 [07:55<14:08:14, 31.89s/it, lr=5e-5, step_loss=0.0534]Steps:   1%|          | 15/1610 [08:03<14:13:29, 32.11s/it, lr=5e-5, step_loss=0.0534]Steps:   1%|          | 15/1610 [08:03<14:13:29, 32.11s/it, lr=5e-5, step_loss=0.0707]Steps:   1%|          | 15/1610 [08:10<14:13:29, 32.11s/it, lr=5e-5, step_loss=0.0852]Steps:   1%|          | 15/1610 [08:18<14:13:29, 32.11s/it, lr=5e-5, step_loss=0.0615]Steps:   1%|          | 15/1610 [08:26<14:13:29, 32.11s/it, lr=5e-5, step_loss=0.0605]Steps:   1%|          | 16/1610 [08:34<14:01:08, 31.66s/it, lr=5e-5, step_loss=0.0605]Steps:   1%|          | 16/1610 [08:34<14:01:08, 31.66s/it, lr=5e-5, step_loss=0.0486]Steps:   1%|          | 16/1610 [08:42<14:01:08, 31.66s/it, lr=5e-5, step_loss=0.089] Steps:   1%|          | 16/1610 [08:51<14:01:08, 31.66s/it, lr=5e-5, step_loss=0.0775]Steps:   1%|          | 16/1610 [08:59<14:01:08, 31.66s/it, lr=5e-5, step_loss=0.0749]Steps:   1%|          | 17/1610 [09:07<14:11:12, 32.06s/it, lr=5e-5, step_loss=0.0749]Steps:   1%|          | 17/1610 [09:07<14:11:12, 32.06s/it, lr=5e-5, step_loss=0.0367]Steps:   1%|          | 17/1610 [09:14<14:11:12, 32.06s/it, lr=5e-5, step_loss=0.0461]Steps:   1%|          | 17/1610 [09:22<14:11:12, 32.06s/it, lr=5e-5, step_loss=0.0609]Steps:   1%|          | 17/1610 [09:30<14:11:12, 32.06s/it, lr=5e-5, step_loss=0.0294]Steps:   1%|          | 18/1610 [09:38<14:06:10, 31.89s/it, lr=5e-5, step_loss=0.0294]Steps:   1%|          | 18/1610 [09:38<14:06:10, 31.89s/it, lr=5e-5, step_loss=0.0692]Steps:   1%|          | 18/1610 [09:46<14:06:10, 31.89s/it, lr=5e-5, step_loss=0.0399]Steps:   1%|          | 18/1610 [09:55<14:06:10, 31.89s/it, lr=5e-5, step_loss=0.0698]Steps:   1%|          | 18/1610 [10:03<14:06:10, 31.89s/it, lr=5e-5, step_loss=0.0629]Steps:   1%|          | 19/1610 [10:10<14:04:42, 31.86s/it, lr=5e-5, step_loss=0.0629]Steps:   1%|          | 19/1610 [10:10<14:04:42, 31.86s/it, lr=5e-5, step_loss=0.0573]Steps:   1%|          | 19/1610 [10:18<14:04:42, 31.86s/it, lr=5e-5, step_loss=0.0735]Steps:   1%|          | 19/1610 [10:26<14:04:42, 31.86s/it, lr=5e-5, step_loss=0.0538]Steps:   1%|          | 19/1610 [10:34<14:04:42, 31.86s/it, lr=5e-5, step_loss=0.0663]Steps:   1%|          | 20/1610 [10:42<14:08:20, 32.01s/it, lr=5e-5, step_loss=0.0663]Steps:   1%|          | 20/1610 [10:42<14:08:20, 32.01s/it, lr=5e-5, step_loss=0.0491]Steps:   1%|          | 20/1610 [10:51<14:08:20, 32.01s/it, lr=5e-5, step_loss=0.0362]Steps:   1%|          | 20/1610 [10:59<14:08:20, 32.01s/it, lr=5e-5, step_loss=0.0423]Steps:   1%|          | 20/1610 [11:06<14:08:20, 32.01s/it, lr=5e-5, step_loss=0.0715]Steps:   1%|â–         | 21/1610 [11:14<14:03:55, 31.87s/it, lr=5e-5, step_loss=0.0715]Steps:   1%|â–         | 21/1610 [11:14<14:03:55, 31.87s/it, lr=5e-5, step_loss=0.0594]Steps:   1%|â–         | 21/1610 [11:22<14:03:55, 31.87s/it, lr=5e-5, step_loss=0.0588]Steps:   1%|â–         | 21/1610 [11:30<14:03:55, 31.87s/it, lr=5e-5, step_loss=0.0712]Steps:   1%|â–         | 21/1610 [11:37<14:03:55, 31.87s/it, lr=5e-5, step_loss=0.0671]Steps:   1%|â–         | 22/1610 [11:45<14:01:07, 31.78s/it, lr=5e-5, step_loss=0.0671]Steps:   1%|â–         | 22/1610 [11:45<14:01:07, 31.78s/it, lr=5e-5, step_loss=0.0678]Steps:   1%|â–         | 22/1610 [11:53<14:01:07, 31.78s/it, lr=5e-5, step_loss=0.0553]Steps:   1%|â–         | 23/1610 [11:54<10:59:30, 24.93s/it, lr=5e-5, step_loss=0.0553]Steps:   1%|â–         | 23/1610 [11:54<10:59:30, 24.93s/it, lr=5e-5, step_loss=0.0577]Steps:   1%|â–         | 23/1610 [12:08<10:59:30, 24.93s/it, lr=5e-5, step_loss=0.0421]Steps:   1%|â–         | 23/1610 [12:16<10:59:30, 24.93s/it, lr=5e-5, step_loss=0.0626]Steps:   1%|â–         | 23/1610 [12:24<10:59:30, 24.93s/it, lr=5e-5, step_loss=0.0671]Steps:   1%|â–         | 24/1610 [12:32<12:37:24, 28.65s/it, lr=5e-5, step_loss=0.0671]Steps:   1%|â–         | 24/1610 [12:32<12:37:24, 28.65s/it, lr=5e-5, step_loss=0.0469]Steps:   1%|â–         | 24/1610 [12:40<12:37:24, 28.65s/it, lr=5e-5, step_loss=0.0552]Steps:   1%|â–         | 24/1610 [12:48<12:37:24, 28.65s/it, lr=5e-5, step_loss=0.0655]Steps:   1%|â–         | 24/1610 [12:56<12:37:24, 28.65s/it, lr=5e-5, step_loss=0.0465]Steps:   2%|â–         | 25/1610 [13:03<12:54:39, 29.32s/it, lr=5e-5, step_loss=0.0465]Steps:   2%|â–         | 25/1610 [13:03<12:54:39, 29.32s/it, lr=5e-5, step_loss=0.0661]Steps:   2%|â–         | 25/1610 [13:10<12:54:39, 29.32s/it, lr=5e-5, step_loss=0.0424]Steps:   2%|â–         | 25/1610 [13:18<12:54:39, 29.32s/it, lr=5e-5, step_loss=0.0581]Steps:   2%|â–         | 25/1610 [13:26<12:54:39, 29.32s/it, lr=5e-5, step_loss=0.084] Steps:   2%|â–         | 26/1610 [13:34<13:11:27, 29.98s/it, lr=5e-5, step_loss=0.084]Steps:   2%|â–         | 26/1610 [13:34<13:11:27, 29.98s/it, lr=5e-5, step_loss=0.0735]Steps:   2%|â–         | 26/1610 [13:42<13:11:27, 29.98s/it, lr=5e-5, step_loss=0.0803]Steps:   2%|â–         | 26/1610 [13:50<13:11:27, 29.98s/it, lr=5e-5, step_loss=0.068] Steps:   2%|â–         | 26/1610 [13:58<13:11:27, 29.98s/it, lr=5e-5, step_loss=0.0384]Steps:   2%|â–         | 27/1610 [14:06<13:26:06, 30.55s/it, lr=5e-5, step_loss=0.0384]Steps:   2%|â–         | 27/1610 [14:06<13:26:06, 30.55s/it, lr=5e-5, step_loss=0.0594]Steps:   2%|â–         | 27/1610 [14:13<13:26:06, 30.55s/it, lr=5e-5, step_loss=0.0567]Steps:   2%|â–         | 27/1610 [14:21<13:26:06, 30.55s/it, lr=5e-5, step_loss=0.0452]Steps:   2%|â–         | 27/1610 [14:29<13:26:06, 30.55s/it, lr=5e-5, step_loss=0.0753]Steps:   2%|â–         | 28/1610 [14:37<13:25:47, 30.56s/it, lr=5e-5, step_loss=0.0753]Steps:   2%|â–         | 28/1610 [14:37<13:25:47, 30.56s/it, lr=5e-5, step_loss=0.0433]Steps:   2%|â–         | 28/1610 [14:45<13:25:47, 30.56s/it, lr=5e-5, step_loss=0.0706]Steps:   2%|â–         | 28/1610 [14:53<13:25:47, 30.56s/it, lr=5e-5, step_loss=0.0486]