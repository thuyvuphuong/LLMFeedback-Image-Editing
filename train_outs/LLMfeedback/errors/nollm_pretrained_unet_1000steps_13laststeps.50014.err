2025-06-08 09:28:00.121456: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1749349680.141825 3632663 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1749349680.147718 3632663 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1749349680.162329 3632663 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1749349680.162428 3632663 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1749349680.162438 3632663 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1749349680.162446 3632663 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-06-08 09:28:00.166598: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Detected CUDA files, patching ldflags
Could not load the custom kernel for multi-scale deformable attention: CUDA_HOME environment variable is not set. Please set it to your CUDA install root.
[rank: 0] Seed set to 42
/work/20010751/SemanticEditing/get_scenegraph.py:48: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  weights = torch.load(pth_path)
/home/20010751/.conda/envs/bksdm/lib/python3.12/site-packages/transformers/models/detr/feature_extraction_detr.py:50: FutureWarning: The class DetrFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use DetrImageProcessor instead.
  warnings.warn(
The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.
/home/20010751/.conda/envs/bksdm/lib/python3.12/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.
Some kwargs in processor config are unused and will not have any effect: downsample_ratio, image_std, image_mean, normalize, mask_prompt, ignore_id, pad_token, add_special_token, sft_format, image_token, patch_size, candidate_resolutions. 
DeepseekVLV2ForCausalLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
DeepseekV2ForCausalLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
/work/20010751/SemanticEditing/finetuning.py:106: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  weights = torch.load(pth_path)
/work/20010751/SemanticEditing/pretrained_frameworks/SceneGraph/egtr/model/deformable_detr.py:833: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(weights_path, map_location="cuda")
Some weights of DetrForSceneGraphGeneration were not initialized from the model checkpoint at ./pretrained_frameworks/SceneGraph/egtr/pretrained/deformable-detr and are newly initialized: ['connectivity_layer.layers.0.bias', 'connectivity_layer.layers.0.weight', 'connectivity_layer.layers.1.bias', 'connectivity_layer.layers.1.weight', 'connectivity_layer.layers.2.bias', 'connectivity_layer.layers.2.weight', 'final_obj_proj.bias', 'final_obj_proj.weight', 'final_sub_proj.bias', 'final_sub_proj.weight', 'proj_k.0.bias', 'proj_k.0.weight', 'proj_k.1.bias', 'proj_k.1.weight', 'proj_k.2.bias', 'proj_k.2.weight', 'proj_k.3.bias', 'proj_k.3.weight', 'proj_k.4.bias', 'proj_k.4.weight', 'proj_k.5.bias', 'proj_k.5.weight', 'proj_q.0.bias', 'proj_q.0.weight', 'proj_q.1.bias', 'proj_q.1.weight', 'proj_q.2.bias', 'proj_q.2.weight', 'proj_q.3.bias', 'proj_q.3.weight', 'proj_q.4.bias', 'proj_q.4.weight', 'proj_q.5.bias', 'proj_q.5.weight', 'rel_dist', 'rel_predictor.layers.0.bias', 'rel_predictor.layers.0.weight', 'rel_predictor.layers.1.bias', 'rel_predictor.layers.1.weight', 'rel_predictor.layers.2.bias', 'rel_predictor.layers.2.weight', 'rel_predictor_gate.bias', 'rel_predictor_gate.weight', 'triplet_dist']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of DetrForSceneGraphGeneration were not initialized from the model checkpoint at ./pretrained_frameworks/SceneGraph/egtr/pretrained/deformable-detr and are newly initialized because the shapes did not match:
- class_embed.0.bias: found shape torch.Size([91]) in the checkpoint and torch.Size([150]) in the model instantiated
- class_embed.0.weight: found shape torch.Size([91, 256]) in the checkpoint and torch.Size([150, 256]) in the model instantiated
- model.query_position_embeddings.weight: found shape torch.Size([300, 512]) in the checkpoint and torch.Size([200, 512]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/work/20010751/SemanticEditing/finetuning.py:119: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(ckpt_path, map_location="cpu")["state_dict"]
/home/20010751/.conda/envs/bksdm/lib/python3.12/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self.scaler = torch.cuda.amp.GradScaler(**kwargs)
06/08/2025 09:28:31 - INFO - __main__ - Distributed environment: DistributedType.MULTI_GPU  Backend: nccl
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: fp16

{'timestep_spacing', 'clip_sample_range', 'rescale_betas_zero_snr', 'variance_type'} was not found in config. Values will be initialized to default values.
{'latents_std', 'scaling_factor', 'mid_block_add_attention', 'shift_factor', 'use_post_quant_conv', 'force_upcast', 'use_quant_conv', 'latents_mean'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at pretrained_frameworks/pretrained_IEDMs/instruct-pix2pix.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
All model checkpoint weights were used when initializing UNet2DConditionModel.

All the weights of UNet2DConditionModel were initialized from the model checkpoint at finetuned_models/ip2p_nollm_res256_lr5e-4/checkpoint-1000.
If your task is similar to the task the model of the checkpoint was trained on, you can already use UNet2DConditionModel for predictions without further training.
06/08/2025 09:28:31 - INFO - __main__ - Initializing the InstructPix2Pix UNet from the pretrained UNet.
06/08/2025 09:28:36 - INFO - __main__ - ***** Running training *****
06/08/2025 09:28:36 - INFO - __main__ -   Num examples = 5751
06/08/2025 09:28:36 - INFO - __main__ -   Num Epochs = 17
06/08/2025 09:28:36 - INFO - __main__ -   Instantaneous batch size per device = 64
06/08/2025 09:28:36 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 256
06/08/2025 09:28:36 - INFO - __main__ -   Gradient Accumulation steps = 4
06/08/2025 09:28:36 - INFO - __main__ -   Total optimization steps = 391
06/08/2025 09:28:36 - INFO - __main__ -   LLM feedback start = 391
  0%|          | 0/391 [00:00<?, ?it/s]Steps:   0%|          | 0/391 [00:00<?, ?it/s]/home/20010751/.conda/envs/bksdm/lib/python3.12/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
Steps:   0%|          | 0/391 [00:16<?, ?it/s, lr=5e-5, step_loss=0.0622]Steps:   0%|          | 0/391 [00:24<?, ?it/s, lr=5e-5, step_loss=0.0405]Steps:   0%|          | 0/391 [00:32<?, ?it/s, lr=5e-5, step_loss=0.0379]Steps:   0%|          | 1/391 [00:41<4:27:03, 41.09s/it, lr=5e-5, step_loss=0.0379]Steps:   0%|          | 1/391 [00:41<4:27:03, 41.09s/it, lr=5e-5, step_loss=0.0684]Steps:   0%|          | 1/391 [00:49<4:27:03, 41.09s/it, lr=5e-5, step_loss=0.0939]Steps:   0%|          | 1/391 [00:57<4:27:03, 41.09s/it, lr=5e-5, step_loss=0.0641]Steps:   0%|          | 1/391 [01:06<4:27:03, 41.09s/it, lr=5e-5, step_loss=0.0344]Steps:   1%|          | 2/391 [01:14<3:56:06, 36.42s/it, lr=5e-5, step_loss=0.0344]Steps:   1%|          | 2/391 [01:14<3:56:06, 36.42s/it, lr=5e-5, step_loss=0.0812]Steps:   1%|          | 2/391 [01:21<3:56:06, 36.42s/it, lr=5e-5, step_loss=0.0559]Steps:   1%|          | 2/391 [01:30<3:56:06, 36.42s/it, lr=5e-5, step_loss=0.0609]Steps:   1%|          | 2/391 [01:39<3:56:06, 36.42s/it, lr=5e-5, step_loss=0.0627]Steps:   1%|          | 3/391 [01:47<3:45:24, 34.86s/it, lr=5e-5, step_loss=0.0627]Steps:   1%|          | 3/391 [01:47<3:45:24, 34.86s/it, lr=5e-5, step_loss=0.0608]Steps:   1%|          | 3/391 [01:55<3:45:24, 34.86s/it, lr=5e-5, step_loss=0.0556]Steps:   1%|          | 3/391 [02:04<3:45:24, 34.86s/it, lr=5e-5, step_loss=0.0449]Steps:   1%|          | 3/391 [02:12<3:45:24, 34.86s/it, lr=5e-5, step_loss=0.053] Steps:   1%|          | 4/391 [02:20<3:41:04, 34.28s/it, lr=5e-5, step_loss=0.053]Steps:   1%|          | 4/391 [02:20<3:41:04, 34.28s/it, lr=5e-5, step_loss=0.0469]Steps:   1%|          | 4/391 [02:29<3:41:04, 34.28s/it, lr=5e-5, step_loss=0.0509]Steps:   1%|          | 4/391 [02:38<3:41:04, 34.28s/it, lr=5e-5, step_loss=0.0454]Steps:   1%|          | 4/391 [02:47<3:41:04, 34.28s/it, lr=5e-5, step_loss=0.0633]Steps:   1%|▏         | 5/391 [02:55<3:42:19, 34.56s/it, lr=5e-5, step_loss=0.0633]Steps:   1%|▏         | 5/391 [02:55<3:42:19, 34.56s/it, lr=5e-5, step_loss=0.0511]Steps:   1%|▏         | 5/391 [03:05<3:42:19, 34.56s/it, lr=5e-5, step_loss=0.0601]Steps:   1%|▏         | 5/391 [03:13<3:42:19, 34.56s/it, lr=5e-5, step_loss=0.0677]Steps:   1%|▏         | 5/391 [03:20<3:42:19, 34.56s/it, lr=5e-5, step_loss=0.0572]Steps:   2%|▏         | 6/391 [03:28<3:37:23, 33.88s/it, lr=5e-5, step_loss=0.0572]Steps:   2%|▏         | 6/391 [03:28<3:37:23, 33.88s/it, lr=5e-5, step_loss=0.0427]Steps:   2%|▏         | 6/391 [03:36<3:37:23, 33.88s/it, lr=5e-5, step_loss=0.0611]Steps:   2%|▏         | 6/391 [03:45<3:37:23, 33.88s/it, lr=5e-5, step_loss=0.0357]Steps:   2%|▏         | 6/391 [03:54<3:37:23, 33.88s/it, lr=5e-5, step_loss=0.0469]Steps:   2%|▏         | 7/391 [04:03<3:39:23, 34.28s/it, lr=5e-5, step_loss=0.0469]Steps:   2%|▏         | 7/391 [04:03<3:39:23, 34.28s/it, lr=5e-5, step_loss=0.0394]Steps:   2%|▏         | 7/391 [04:12<3:39:23, 34.28s/it, lr=5e-5, step_loss=0.0415]Steps:   2%|▏         | 7/391 [04:21<3:39:23, 34.28s/it, lr=5e-5, step_loss=0.032] Steps:   2%|▏         | 7/391 [04:30<3:39:23, 34.28s/it, lr=5e-5, step_loss=0.0321]Steps:   2%|▏         | 8/391 [04:38<3:40:27, 34.54s/it, lr=5e-5, step_loss=0.0321]Steps:   2%|▏         | 8/391 [04:38<3:40:27, 34.54s/it, lr=5e-5, step_loss=0.0495]Steps:   2%|▏         | 8/391 [04:47<3:40:27, 34.54s/it, lr=5e-5, step_loss=0.0584]Steps:   2%|▏         | 8/391 [04:55<3:40:27, 34.54s/it, lr=5e-5, step_loss=0.0446]Steps:   2%|▏         | 8/391 [05:05<3:40:27, 34.54s/it, lr=5e-5, step_loss=0.0474]Steps:   2%|▏         | 9/391 [05:13<3:41:22, 34.77s/it, lr=5e-5, step_loss=0.0474]Steps:   2%|▏         | 9/391 [05:13<3:41:22, 34.77s/it, lr=5e-5, step_loss=0.0368]Steps:   2%|▏         | 9/391 [05:22<3:41:22, 34.77s/it, lr=5e-5, step_loss=0.0653]Steps:   2%|▏         | 9/391 [05:29<3:41:22, 34.77s/it, lr=5e-5, step_loss=0.0571]Steps:   2%|▏         | 9/391 [05:38<3:41:22, 34.77s/it, lr=5e-5, step_loss=0.041] Steps:   3%|▎         | 10/391 [05:47<3:39:31, 34.57s/it, lr=5e-5, step_loss=0.041]Steps:   3%|▎         | 10/391 [05:47<3:39:31, 34.57s/it, lr=5e-5, step_loss=0.0496]Steps:   3%|▎         | 10/391 [05:56<3:39:31, 34.57s/it, lr=5e-5, step_loss=0.0644]Steps:   3%|▎         | 10/391 [06:07<3:39:31, 34.57s/it, lr=5e-5, step_loss=0.035] Steps:   3%|▎         | 10/391 [06:16<3:39:31, 34.57s/it, lr=5e-5, step_loss=0.0442]Steps:   3%|▎         | 11/391 [06:25<3:43:59, 35.37s/it, lr=5e-5, step_loss=0.0442]Steps:   3%|▎         | 11/391 [06:25<3:43:59, 35.37s/it, lr=5e-5, step_loss=0.0624]Steps:   3%|▎         | 11/391 [06:34<3:43:59, 35.37s/it, lr=5e-5, step_loss=0.0563]Steps:   3%|▎         | 11/391 [06:43<3:43:59, 35.37s/it, lr=5e-5, step_loss=0.0337]Steps:   3%|▎         | 11/391 [06:52<3:43:59, 35.37s/it, lr=5e-5, step_loss=0.0447]Steps:   3%|▎         | 12/391 [07:01<3:44:48, 35.59s/it, lr=5e-5, step_loss=0.0447]Steps:   3%|▎         | 12/391 [07:01<3:44:48, 35.59s/it, lr=5e-5, step_loss=0.0617]Steps:   3%|▎         | 12/391 [07:08<3:44:48, 35.59s/it, lr=5e-5, step_loss=0.0437]Steps:   3%|▎         | 12/391 [07:17<3:44:48, 35.59s/it, lr=5e-5, step_loss=0.0389]Steps:   3%|▎         | 12/391 [07:26<3:44:48, 35.59s/it, lr=5e-5, step_loss=0.0522]Steps:   3%|▎         | 13/391 [07:35<3:41:52, 35.22s/it, lr=5e-5, step_loss=0.0522]Steps:   3%|▎         | 13/391 [07:35<3:41:52, 35.22s/it, lr=5e-5, step_loss=0.0332]Steps:   3%|▎         | 13/391 [07:43<3:41:52, 35.22s/it, lr=5e-5, step_loss=0.0574]Steps:   3%|▎         | 13/391 [07:52<3:41:52, 35.22s/it, lr=5e-5, step_loss=0.047] Steps:   3%|▎         | 13/391 [08:00<3:41:52, 35.22s/it, lr=5e-5, step_loss=0.0461]Steps:   4%|▎         | 14/391 [08:09<3:39:09, 34.88s/it, lr=5e-5, step_loss=0.0461]Steps:   4%|▎         | 14/391 [08:09<3:39:09, 34.88s/it, lr=5e-5, step_loss=0.0413]Steps:   4%|▎         | 14/391 [08:19<3:39:09, 34.88s/it, lr=5e-5, step_loss=0.04]  Steps:   4%|▎         | 14/391 [08:27<3:39:09, 34.88s/it, lr=5e-5, step_loss=0.0409]Steps:   4%|▎         | 14/391 [08:36<3:39:09, 34.88s/it, lr=5e-5, step_loss=0.0425]Steps:   4%|▍         | 15/391 [08:45<3:40:30, 35.19s/it, lr=5e-5, step_loss=0.0425]Steps:   4%|▍         | 15/391 [08:45<3:40:30, 35.19s/it, lr=5e-5, step_loss=0.0569]Steps:   4%|▍         | 15/391 [08:52<3:40:30, 35.19s/it, lr=5e-5, step_loss=0.0708]Steps:   4%|▍         | 15/391 [09:01<3:40:30, 35.19s/it, lr=5e-5, step_loss=0.0506]Steps:   4%|▍         | 15/391 [09:09<3:40:30, 35.19s/it, lr=5e-5, step_loss=0.0482]Steps:   4%|▍         | 16/391 [09:18<3:35:58, 34.56s/it, lr=5e-5, step_loss=0.0482]Steps:   4%|▍         | 16/391 [09:18<3:35:58, 34.56s/it, lr=5e-5, step_loss=0.0377]Steps:   4%|▍         | 16/391 [09:27<3:35:58, 34.56s/it, lr=5e-5, step_loss=0.0741]Steps:   4%|▍         | 16/391 [09:36<3:35:58, 34.56s/it, lr=5e-5, step_loss=0.0661]Steps:   4%|▍         | 16/391 [09:45<3:35:58, 34.56s/it, lr=5e-5, step_loss=0.0596]Steps:   4%|▍         | 17/391 [09:53<3:36:45, 34.77s/it, lr=5e-5, step_loss=0.0596]Steps:   4%|▍         | 17/391 [09:53<3:36:45, 34.77s/it, lr=5e-5, step_loss=0.028] Steps:   4%|▍         | 17/391 [10:01<3:36:45, 34.77s/it, lr=5e-5, step_loss=0.0351]Steps:   4%|▍         | 17/391 [10:09<3:36:45, 34.77s/it, lr=5e-5, step_loss=0.0488]Steps:   4%|▍         | 17/391 [10:18<3:36:45, 34.77s/it, lr=5e-5, step_loss=0.0225]Steps:   5%|▍         | 18/391 [10:27<3:34:28, 34.50s/it, lr=5e-5, step_loss=0.0225]Steps:   5%|▍         | 18/391 [10:27<3:34:28, 34.50s/it, lr=5e-5, step_loss=0.0568]Steps:   5%|▍         | 18/391 [10:36<3:34:28, 34.50s/it, lr=5e-5, step_loss=0.0302]Steps:   5%|▍         | 18/391 [10:46<3:34:28, 34.50s/it, lr=5e-5, step_loss=0.0576]Steps:   5%|▍         | 18/391 [10:55<3:34:28, 34.50s/it, lr=5e-5, step_loss=0.0507]Steps:   5%|▍         | 19/391 [11:02<3:34:49, 34.65s/it, lr=5e-5, step_loss=0.0507]Steps:   5%|▍         | 19/391 [11:02<3:34:49, 34.65s/it, lr=5e-5, step_loss=0.0457]Steps:   5%|▍         | 19/391 [11:11<3:34:49, 34.65s/it, lr=5e-5, step_loss=0.0591]Steps:   5%|▍         | 19/391 [11:20<3:34:49, 34.65s/it, lr=5e-5, step_loss=0.0448]Steps:   5%|▍         | 19/391 [11:29<3:34:49, 34.65s/it, lr=5e-5, step_loss=0.054] Steps:   5%|▌         | 20/391 [11:37<3:34:28, 34.69s/it, lr=5e-5, step_loss=0.054]Steps:   5%|▌         | 20/391 [11:37<3:34:28, 34.69s/it, lr=5e-5, step_loss=0.0398]Steps:   5%|▌         | 20/391 [11:46<3:34:28, 34.69s/it, lr=5e-5, step_loss=0.0284]Steps:   5%|▌         | 20/391 [11:54<3:34:28, 34.69s/it, lr=5e-5, step_loss=0.0338]Steps:   5%|▌         | 20/391 [12:02<3:34:28, 34.69s/it, lr=5e-5, step_loss=0.0598]Steps:   5%|▌         | 21/391 [12:10<3:31:00, 34.22s/it, lr=5e-5, step_loss=0.0598]Steps:   5%|▌         | 21/391 [12:10<3:31:00, 34.22s/it, lr=5e-5, step_loss=0.0499]Steps:   5%|▌         | 21/391 [12:18<3:31:00, 34.22s/it, lr=5e-5, step_loss=0.0493]Steps:   5%|▌         | 21/391 [12:27<3:31:00, 34.22s/it, lr=5e-5, step_loss=0.0582]Steps:   5%|▌         | 21/391 [12:35<3:31:00, 34.22s/it, lr=5e-5, step_loss=0.0567]Steps:   6%|▌         | 22/391 [12:44<3:29:42, 34.10s/it, lr=5e-5, step_loss=0.0567]Steps:   6%|▌         | 22/391 [12:44<3:29:42, 34.10s/it, lr=5e-5, step_loss=0.0538]Steps:   6%|▌         | 22/391 [12:53<3:29:42, 34.10s/it, lr=5e-5, step_loss=0.0466]Steps:   6%|▌         | 23/391 [12:54<2:44:16, 26.78s/it, lr=5e-5, step_loss=0.0466]Steps:   6%|▌         | 23/391 [12:54<2:44:16, 26.78s/it, lr=5e-5, step_loss=0.0479]Steps:   6%|▌         | 23/391 [13:09<2:44:16, 26.78s/it, lr=5e-5, step_loss=0.0341]Steps:   6%|▌         | 23/391 [13:18<2:44:16, 26.78s/it, lr=5e-5, step_loss=0.0517]Steps:   6%|▌         | 23/391 [13:26<2:44:16, 26.78s/it, lr=5e-5, step_loss=0.059] Steps:   6%|▌         | 24/391 [13:35<3:10:44, 31.19s/it, lr=5e-5, step_loss=0.059]Steps:   6%|▌         | 24/391 [13:35<3:10:44, 31.19s/it, lr=5e-5, step_loss=0.0383]Steps:   6%|▌         | 24/391 [13:44<3:10:44, 31.19s/it, lr=5e-5, step_loss=0.0463]Steps:   6%|▌         | 24/391 [13:52<3:10:44, 31.19s/it, lr=5e-5, step_loss=0.0546]Steps:   6%|▌         | 24/391 [14:00<3:10:44, 31.19s/it, lr=5e-5, step_loss=0.0385]Steps:   6%|▋         | 25/391 [14:07<3:11:37, 31.41s/it, lr=5e-5, step_loss=0.0385]Steps:   6%|▋         | 25/391 [14:07<3:11:37, 31.41s/it, lr=5e-5, step_loss=0.0552]Steps:   6%|▋         | 25/391 [14:15<3:11:37, 31.41s/it, lr=5e-5, step_loss=0.0352]Steps:   6%|▋         | 25/391 [14:23<3:11:37, 31.41s/it, lr=5e-5, step_loss=0.0494]Steps:   6%|▋         | 25/391 [14:32<3:11:37, 31.41s/it, lr=5e-5, step_loss=0.07]  Steps:   7%|▋         | 26/391 [14:40<3:13:25, 31.80s/it, lr=5e-5, step_loss=0.07]Steps:   7%|▋         | 26/391 [14:40<3:13:25, 31.80s/it, lr=5e-5, step_loss=0.063]Steps:   7%|▋         | 26/391 [14:48<3:13:25, 31.80s/it, lr=5e-5, step_loss=0.0711]Steps:   7%|▋         | 26/391 [14:56<3:13:25, 31.80s/it, lr=5e-5, step_loss=0.0574]Steps:   7%|▋         | 26/391 [15:04<3:13:25, 31.80s/it, lr=5e-5, step_loss=0.0316]Steps:   7%|▋         | 27/391 [15:13<3:14:59, 32.14s/it, lr=5e-5, step_loss=0.0316]Steps:   7%|▋         | 27/391 [15:13<3:14:59, 32.14s/it, lr=5e-5, step_loss=0.0507]Steps:   7%|▋         | 27/391 [15:20<3:14:59, 32.14s/it, lr=5e-5, step_loss=0.0482]Steps:   7%|▋         | 27/391 [15:28<3:14:59, 32.14s/it, lr=5e-5, step_loss=0.0366]Steps:   7%|▋         | 27/391 [15:36<3:14:59, 32.14s/it, lr=5e-5, step_loss=0.0653]Steps:   7%|▋         | 28/391 [15:44<3:13:13, 31.94s/it, lr=5e-5, step_loss=0.0653]Steps:   7%|▋         | 28/391 [15:44<3:13:13, 31.94s/it, lr=5e-5, step_loss=0.0358]Steps:   7%|▋         | 28/391 [15:52<3:13:13, 31.94s/it, lr=5e-5, step_loss=0.0612]Steps:   7%|▋         | 28/391 [16:01<3:13:13, 31.94s/it, lr=5e-5, step_loss=0.04]  Steps:   7%|▋         | 28/391 [16:09<3:13:13, 31.94s/it, lr=5e-5, step_loss=0.0451]Steps:   7%|▋         | 29/391 [16:18<3:16:39, 32.59s/it, lr=5e-5, step_loss=0.0451]Steps:   7%|▋         | 29/391 [16:18<3:16:39, 32.59s/it, lr=5e-5, step_loss=0.0345]Steps:   7%|▋         | 29/391 [16:25<3:16:39, 32.59s/it, lr=5e-5, step_loss=0.0506]Steps:   7%|▋         | 29/391 [16:33<3:16:39, 32.59s/it, lr=5e-5, step_loss=0.044] Steps:   7%|▋         | 29/391 [16:42<3:16:39, 32.59s/it, lr=5e-5, step_loss=0.0527]Steps:   8%|▊         | 30/391 [16:50<3:15:11, 32.44s/it, lr=5e-5, step_loss=0.0527]Steps:   8%|▊         | 30/391 [16:50<3:15:11, 32.44s/it, lr=5e-5, step_loss=0.0373]Steps:   8%|▊         | 30/391 [16:59<3:15:11, 32.44s/it, lr=5e-5, step_loss=0.0344]Steps:   8%|▊         | 30/391 [17:08<3:15:11, 32.44s/it, lr=5e-5, step_loss=0.06]  Steps:   8%|▊         | 30/391 [17:15<3:15:11, 32.44s/it, lr=5e-5, step_loss=0.0512]Steps:   8%|▊         | 31/391 [17:23<3:14:23, 32.40s/it, lr=5e-5, step_loss=0.0512]Steps:   8%|▊         | 31/391 [17:23<3:14:23, 32.40s/it, lr=5e-5, step_loss=0.0365]Steps:   8%|▊         | 31/391 [17:31<3:14:23, 32.40s/it, lr=5e-5, step_loss=0.0427]Steps:   8%|▊         | 31/391 [17:40<3:14:23, 32.40s/it, lr=5e-5, step_loss=0.0406]Steps:   8%|▊         | 31/391 [17:48<3:14:23, 32.40s/it, lr=5e-5, step_loss=0.0478]Steps:   8%|▊         | 32/391 [17:57<3:17:10, 32.96s/it, lr=5e-5, step_loss=0.0478]Steps:   8%|▊         | 32/391 [17:57<3:17:10, 32.96s/it, lr=5e-5, step_loss=0.0422]Steps:   8%|▊         | 32/391 [18:05<3:17:10, 32.96s/it, lr=5e-5, step_loss=0.0829]Steps:   8%|▊         | 32/391 [18:13<3:17:10, 32.96s/it, lr=5e-5, step_loss=0.0382]Steps:   8%|▊         | 32/391 [18:21<3:17:10, 32.96s/it, lr=5e-5, step_loss=0.0282]Steps:   8%|▊         | 33/391 [18:30<3:16:44, 32.97s/it, lr=5e-5, step_loss=0.0282]Steps:   8%|▊         | 33/391 [18:30<3:16:44, 32.97s/it, lr=5e-5, step_loss=0.0359]Steps:   8%|▊         | 33/391 [18:39<3:16:44, 32.97s/it, lr=5e-5, step_loss=0.0401]Steps:   8%|▊         | 33/391 [18:46<3:16:44, 32.97s/it, lr=5e-5, step_loss=0.0551]Steps:   8%|▊         | 33/391 [18:55<3:16:44, 32.97s/it, lr=5e-5, step_loss=0.0413]Steps:   9%|▊         | 34/391 [19:04<3:17:44, 33.23s/it, lr=5e-5, step_loss=0.0413]Steps:   9%|▊         | 34/391 [19:04<3:17:44, 33.23s/it, lr=5e-5, step_loss=0.0441]Steps:   9%|▊         | 34/391 [19:11<3:17:44, 33.23s/it, lr=5e-5, step_loss=0.0198]Steps:   9%|▊         | 34/391 [19:18<3:17:44, 33.23s/it, lr=5e-5, step_loss=0.0477]Steps:   9%|▊         | 34/391 [19:26<3:17:44, 33.23s/it, lr=5e-5, step_loss=0.0627]Steps:   9%|▉         | 35/391 [19:35<3:13:45, 32.66s/it, lr=5e-5, step_loss=0.0627]Steps:   9%|▉         | 35/391 [19:35<3:13:45, 32.66s/it, lr=5e-5, step_loss=0.0433]Steps:   9%|▉         | 35/391 [19:44<3:13:45, 32.66s/it, lr=5e-5, step_loss=0.051] Steps:   9%|▉         | 35/391 [19:52<3:13:45, 32.66s/it, lr=5e-5, step_loss=0.0552]Steps:   9%|▉         | 35/391 [20:01<3:13:45, 32.66s/it, lr=5e-5, step_loss=0.0606]Steps:   9%|▉         | 36/391 [20:09<3:15:22, 33.02s/it, lr=5e-5, step_loss=0.0606]Steps:   9%|▉         | 36/391 [20:09<3:15:22, 33.02s/it, lr=5e-5, step_loss=0.0429]Steps:   9%|▉         | 36/391 [20:17<3:15:22, 33.02s/it, lr=5e-5, step_loss=0.0417]Steps:   9%|▉         | 36/391 [20:26<3:15:22, 33.02s/it, lr=5e-5, step_loss=0.0592]Steps:   9%|▉         | 36/391 [20:34<3:15:22, 33.02s/it, lr=5e-5, step_loss=0.0356]Steps:   9%|▉         | 37/391 [20:42<3:14:47, 33.01s/it, lr=5e-5, step_loss=0.0356]Steps:   9%|▉         | 37/391 [20:42<3:14:47, 33.01s/it, lr=5e-5, step_loss=0.0486]Steps:   9%|▉         | 37/391 [20:51<3:14:47, 33.01s/it, lr=5e-5, step_loss=0.0666]Steps:   9%|▉         | 37/391 [20:58<3:14:47, 33.01s/it, lr=5e-5, step_loss=0.0394]Steps:   9%|▉         | 37/391 [21:07<3:14:47, 33.01s/it, lr=5e-5, step_loss=0.0523]Steps:  10%|▉         | 38/391 [21:16<3:16:07, 33.33s/it, lr=5e-5, step_loss=0.0523]Steps:  10%|▉         | 38/391 [21:16<3:16:07, 33.33s/it, lr=5e-5, step_loss=0.0543]Steps:  10%|▉         | 38/391 [21:25<3:16:07, 33.33s/it, lr=5e-5, step_loss=0.0435]Steps:  10%|▉         | 38/391 [21:33<3:16:07, 33.33s/it, lr=5e-5, step_loss=0.0501]Steps:  10%|▉         | 38/391 [21:41<3:16:07, 33.33s/it, lr=5e-5, step_loss=0.0543]Steps:  10%|▉         | 39/391 [21:49<3:15:05, 33.25s/it, lr=5e-5, step_loss=0.0543]Steps:  10%|▉         | 39/391 [21:49<3:15:05, 33.25s/it, lr=5e-5, step_loss=0.0377]Steps:  10%|▉         | 39/391 [21:57<3:15:05, 33.25s/it, lr=5e-5, step_loss=0.0507]Steps:  10%|▉         | 39/391 [22:06<3:15:05, 33.25s/it, lr=5e-5, step_loss=0.0354]Steps:  10%|▉         | 39/391 [22:15<3:15:05, 33.25s/it, lr=5e-5, step_loss=0.0551]Steps:  10%|█         | 40/391 [22:24<3:17:53, 33.83s/it, lr=5e-5, step_loss=0.0551]Steps:  10%|█         | 40/391 [22:24<3:17:53, 33.83s/it, lr=5e-5, step_loss=0.0584]Steps:  10%|█         | 40/391 [22:34<3:17:53, 33.83s/it, lr=5e-5, step_loss=0.0589]Steps:  10%|█         | 40/391 [22:43<3:17:53, 33.83s/it, lr=5e-5, step_loss=0.042] Steps:  10%|█         | 40/391 [22:53<3:17:53, 33.83s/it, lr=5e-5, step_loss=0.0541]Steps:  10%|█         | 41/391 [23:01<3:22:03, 34.64s/it, lr=5e-5, step_loss=0.0541]Steps:  10%|█         | 41/391 [23:01<3:22:03, 34.64s/it, lr=5e-5, step_loss=0.0518]Steps:  10%|█         | 41/391 [23:10<3:22:03, 34.64s/it, lr=5e-5, step_loss=0.0418]Steps:  10%|█         | 41/391 [23:18<3:22:03, 34.64s/it, lr=5e-5, step_loss=0.034] Steps:  10%|█         | 41/391 [23:28<3:22:03, 34.64s/it, lr=5e-5, step_loss=0.0677]Steps:  11%|█         | 42/391 [23:36<3:23:08, 34.92s/it, lr=5e-5, step_loss=0.0677]Steps:  11%|█         | 42/391 [23:36<3:23:08, 34.92s/it, lr=5e-5, step_loss=0.0587]Steps:  11%|█         | 42/391 [23:45<3:23:08, 34.92s/it, lr=5e-5, step_loss=0.0407]Steps:  11%|█         | 42/391 [23:53<3:23:08, 34.92s/it, lr=5e-5, step_loss=0.0545]Steps:  11%|█         | 42/391 [24:02<3:23:08, 34.92s/it, lr=5e-5, step_loss=0.0566]Steps:  11%|█         | 43/391 [24:11<3:21:10, 34.69s/it, lr=5e-5, step_loss=0.0566]Steps:  11%|█         | 43/391 [24:11<3:21:10, 34.69s/it, lr=5e-5, step_loss=0.0597]Steps:  11%|█         | 43/391 [24:20<3:21:10, 34.69s/it, lr=5e-5, step_loss=0.0397]Steps:  11%|█         | 43/391 [24:30<3:21:10, 34.69s/it, lr=5e-5, step_loss=0.0436]Steps:  11%|█         | 43/391 [24:38<3:21:10, 34.69s/it, lr=5e-5, step_loss=0.0318]Steps:  11%|█▏        | 44/391 [24:47<3:23:36, 35.21s/it, lr=5e-5, step_loss=0.0318]Steps:  11%|█▏        | 44/391 [24:47<3:23:36, 35.21s/it, lr=5e-5, step_loss=0.0444]Steps:  11%|█▏        | 44/391 [24:55<3:23:36, 35.21s/it, lr=5e-5, step_loss=0.0466]Steps:  11%|█▏        | 44/391 [25:04<3:23:36, 35.21s/it, lr=5e-5, step_loss=0.0353]Steps:  11%|█▏        | 44/391 [25:13<3:23:36, 35.21s/it, lr=5e-5, step_loss=0.0389]Steps:  12%|█▏        | 45/391 [25:22<3:22:42, 35.15s/it, lr=5e-5, step_loss=0.0389]Steps:  12%|█▏        | 45/391 [25:22<3:22:42, 35.15s/it, lr=5e-5, step_loss=0.0612]Steps:  12%|█▏        | 45/391 [25:31<3:22:42, 35.15s/it, lr=5e-5, step_loss=0.055] Steps:  12%|█▏        | 46/391 [25:32<2:39:33, 27.75s/it, lr=5e-5, step_loss=0.055]Steps:  12%|█▏        | 46/391 [25:32<2:39:33, 27.75s/it, lr=5e-5, step_loss=0.06] Steps:  12%|█▏        | 46/391 [25:49<2:39:33, 27.75s/it, lr=5e-5, step_loss=0.0475]Steps:  12%|█▏        | 46/391 [25:58<2:39:33, 27.75s/it, lr=5e-5, step_loss=0.0404]Steps:  12%|█▏        | 46/391 [26:06<2:39:33, 27.75s/it, lr=5e-5, step_loss=0.04]  Steps:  12%|█▏        | 47/391 [26:14<3:03:01, 31.92s/it, lr=5e-5, step_loss=0.04]Steps:  12%|█▏        | 47/391 [26:14<3:03:01, 31.92s/it, lr=5e-5, step_loss=0.0397]Steps:  12%|█▏        | 47/391 [26:22<3:03:01, 31.92s/it, lr=5e-5, step_loss=0.0499]Steps:  12%|█▏        | 47/391 [26:31<3:03:01, 31.92s/it, lr=5e-5, step_loss=0.0366]Steps:  12%|█▏        | 47/391 [26:41<3:03:01, 31.92s/it, lr=5e-5, step_loss=0.053] Steps:  12%|█▏        | 48/391 [26:50<3:08:48, 33.03s/it, lr=5e-5, step_loss=0.053]Steps:  12%|█▏        | 48/391 [26:50<3:08:48, 33.03s/it, lr=5e-5, step_loss=0.0355]Steps:  12%|█▏        | 48/391 [26:58<3:08:48, 33.03s/it, lr=5e-5, step_loss=0.0602]Steps:  12%|█▏        | 48/391 [27:07<3:08:48, 33.03s/it, lr=5e-5, step_loss=0.049] Steps:  12%|█▏        | 48/391 [27:16<3:08:48, 33.03s/it, lr=5e-5, step_loss=0.0722]Steps:  13%|█▎        | 49/391 [27:25<3:12:38, 33.80s/it, lr=5e-5, step_loss=0.0722]Steps:  13%|█▎        | 49/391 [27:25<3:12:38, 33.80s/it, lr=5e-5, step_loss=0.0417]Steps:  13%|█▎        | 49/391 [27:33<3:12:38, 33.80s/it, lr=5e-5, step_loss=0.0504]Steps:  13%|█▎        | 49/391 [27:43<3:12:38, 33.80s/it, lr=5e-5, step_loss=0.0334]Steps:  13%|█▎        | 49/391 [27:51<3:12:38, 33.80s/it, lr=5e-5, step_loss=0.0439]Steps:  13%|█▎        | 50/391 [28:00<3:12:48, 33.93s/it, lr=5e-5, step_loss=0.0439]Steps:  13%|█▎        | 50/391 [28:00<3:12:48, 33.93s/it, lr=5e-5, step_loss=0.0315]Steps:  13%|█▎        | 50/391 [28:09<3:12:48, 33.93s/it, lr=5e-5, step_loss=0.0477]Steps:  13%|█▎        | 50/391 [28:17<3:12:48, 33.93s/it, lr=5e-5, step_loss=0.0429]Steps:  13%|█▎        | 50/391 [28:25<3:12:48, 33.93s/it, lr=5e-5, step_loss=0.0459]Steps:  13%|█▎        | 51/391 [28:35<3:15:26, 34.49s/it, lr=5e-5, step_loss=0.0459]Steps:  13%|█▎        | 51/391 [28:35<3:15:26, 34.49s/it, lr=5e-5, step_loss=0.0402]Steps:  13%|█▎        | 51/391 [28:43<3:15:26, 34.49s/it, lr=5e-5, step_loss=0.047] Steps:  13%|█▎        | 51/391 [28:51<3:15:26, 34.49s/it, lr=5e-5, step_loss=0.0352]Steps:  13%|█▎        | 51/391 [29:00<3:15:26, 34.49s/it, lr=5e-5, step_loss=0.0415]Steps:  13%|█▎        | 52/391 [29:07<3:10:44, 33.76s/it, lr=5e-5, step_loss=0.0415]Steps:  13%|█▎        | 52/391 [29:07<3:10:44, 33.76s/it, lr=5e-5, step_loss=0.0401]Steps:  13%|█▎        | 52/391 [29:17<3:10:44, 33.76s/it, lr=5e-5, step_loss=0.0598]Steps:  13%|█▎        | 52/391 [29:25<3:10:44, 33.76s/it, lr=5e-5, step_loss=0.049] Steps:  13%|█▎        | 52/391 [29:34<3:10:44, 33.76s/it, lr=5e-5, step_loss=0.0405]Steps:  14%|█▎        | 53/391 [29:43<3:13:39, 34.38s/it, lr=5e-5, step_loss=0.0405]Steps:  14%|█▎        | 53/391 [29:43<3:13:39, 34.38s/it, lr=5e-5, step_loss=0.0309]Steps:  14%|█▎        | 53/391 [29:51<3:13:39, 34.38s/it, lr=5e-5, step_loss=0.055] Steps:  14%|█▎        | 53/391 [29:59<3:13:39, 34.38s/it, lr=5e-5, step_loss=0.0547]Steps:  14%|█▎        | 53/391 [30:08<3:13:39, 34.38s/it, lr=5e-5, step_loss=0.0358]Steps:  14%|█▍        | 54/391 [30:17<3:11:48, 34.15s/it, lr=5e-5, step_loss=0.0358]Steps:  14%|█▍        | 54/391 [30:17<3:11:48, 34.15s/it, lr=5e-5, step_loss=0.0409]Steps:  14%|█▍        | 54/391 [30:25<3:11:48, 34.15s/it, lr=5e-5, step_loss=0.0341]Steps:  14%|█▍        | 54/391 [30:33<3:11:48, 34.15s/it, lr=5e-5, step_loss=0.0482]Steps:  14%|█▍        | 54/391 [30:41<3:11:48, 34.15s/it, lr=5e-5, step_loss=0.0498]Steps:  14%|█▍        | 55/391 [30:50<3:09:53, 33.91s/it, lr=5e-5, step_loss=0.0498]Steps:  14%|█▍        | 55/391 [30:50<3:09:53, 33.91s/it, lr=5e-5, step_loss=0.0687]Steps:  14%|█▍        | 55/391 [31:00<3:09:53, 33.91s/it, lr=5e-5, step_loss=0.0739]Steps:  14%|█▍        | 55/391 [31:08<3:09:53, 33.91s/it, lr=5e-5, step_loss=0.0397]Steps:  14%|█▍        | 55/391 [31:16<3:09:53, 33.91s/it, lr=5e-5, step_loss=0.0433]Steps:  14%|█▍        | 56/391 [31:24<3:08:56, 33.84s/it, lr=5e-5, step_loss=0.0433]Steps:  14%|█▍        | 56/391 [31:24<3:08:56, 33.84s/it, lr=5e-5, step_loss=0.0435]Steps:  14%|█▍        | 56/391 [31:32<3:08:56, 33.84s/it, lr=5e-5, step_loss=0.0385]Steps:  14%|█▍        | 56/391 [31:41<3:08:56, 33.84s/it, lr=5e-5, step_loss=0.0264]Steps:  14%|█▍        | 56/391 [31:50<3:08:56, 33.84s/it, lr=5e-5, step_loss=0.087] Steps:  15%|█▍        | 57/391 [31:58<3:09:25, 34.03s/it, lr=5e-5, step_loss=0.087]Steps:  15%|█▍        | 57/391 [31:58<3:09:25, 34.03s/it, lr=5e-5, step_loss=0.0629]Steps:  15%|█▍        | 57/391 [32:07<3:09:25, 34.03s/it, lr=5e-5, step_loss=0.0674]Steps:  15%|█▍        | 57/391 [32:15<3:09:25, 34.03s/it, lr=5e-5, step_loss=0.057] Steps:  15%|█▍        | 57/391 [32:22<3:09:25, 34.03s/it, lr=5e-5, step_loss=0.0476]Steps:  15%|█▍        | 58/391 [32:31<3:07:24, 33.77s/it, lr=5e-5, step_loss=0.0476]Steps:  15%|█▍        | 58/391 [32:31<3:07:24, 33.77s/it, lr=5e-5, step_loss=0.0453]Steps:  15%|█▍        | 58/391 [32:39<3:07:24, 33.77s/it, lr=5e-5, step_loss=0.0535]Steps:  15%|█▍        | 58/391 [32:47<3:07:24, 33.77s/it, lr=5e-5, step_loss=0.0547]Steps:  15%|█▍        | 58/391 [32:57<3:07:24, 33.77s/it, lr=5e-5, step_loss=0.0482]Steps:  15%|█▌        | 59/391 [33:05<3:06:17, 33.67s/it, lr=5e-5, step_loss=0.0482]Steps:  15%|█▌        | 59/391 [33:05<3:06:17, 33.67s/it, lr=5e-5, step_loss=0.0582]Steps:  15%|█▌        | 59/391 [33:13<3:06:17, 33.67s/it, lr=5e-5, step_loss=0.049] Steps:  15%|█▌        | 59/391 [33:21<3:06:17, 33.67s/it, lr=5e-5, step_loss=0.0604]Steps:  15%|█▌        | 59/391 [33:30<3:06:17, 33.67s/it, lr=5e-5, step_loss=0.035] Steps:  15%|█▌        | 60/391 [33:38<3:05:20, 33.60s/it, lr=5e-5, step_loss=0.035]Steps:  15%|█▌        | 60/391 [33:38<3:05:20, 33.60s/it, lr=5e-5, step_loss=0.0525]Steps:  15%|█▌        | 60/391 [33:48<3:05:20, 33.60s/it, lr=5e-5, step_loss=0.061] Steps:  15%|█▌        | 60/391 [33:56<3:05:20, 33.60s/it, lr=5e-5, step_loss=0.0427]Steps:  15%|█▌        | 60/391 [34:04<3:05:20, 33.60s/it, lr=5e-5, step_loss=0.0707]Steps:  16%|█▌        | 61/391 [34:14<3:08:02, 34.19s/it, lr=5e-5, step_loss=0.0707]Steps:  16%|█▌        | 61/391 [34:14<3:08:02, 34.19s/it, lr=5e-5, step_loss=0.0381]Steps:  16%|█▌        | 61/391 [34:23<3:08:02, 34.19s/it, lr=5e-5, step_loss=0.0523]Steps:  16%|█▌        | 61/391 [34:31<3:08:02, 34.19s/it, lr=5e-5, step_loss=0.0299]Steps:  16%|█▌        | 61/391 [34:40<3:08:02, 34.19s/it, lr=5e-5, step_loss=0.0389]Steps:  16%|█▌        | 62/391 [34:48<3:07:54, 34.27s/it, lr=5e-5, step_loss=0.0389]Steps:  16%|█▌        | 62/391 [34:48<3:07:54, 34.27s/it, lr=5e-5, step_loss=0.0416]Steps:  16%|█▌        | 62/391 [34:58<3:07:54, 34.27s/it, lr=5e-5, step_loss=0.0338]Steps:  16%|█▌        | 62/391 [35:05<3:07:54, 34.27s/it, lr=5e-5, step_loss=0.0428]Steps:  16%|█▌        | 62/391 [35:15<3:07:54, 34.27s/it, lr=5e-5, step_loss=0.0416]Steps:  16%|█▌        | 63/391 [35:24<3:09:28, 34.66s/it, lr=5e-5, step_loss=0.0416]Steps:  16%|█▌        | 63/391 [35:24<3:09:28, 34.66s/it, lr=5e-5, step_loss=0.0507]Steps:  16%|█▌        | 63/391 [35:33<3:09:28, 34.66s/it, lr=5e-5, step_loss=0.0481]Steps:  16%|█▌        | 63/391 [35:42<3:09:28, 34.66s/it, lr=5e-5, step_loss=0.0521]Steps:  16%|█▌        | 63/391 [35:50<3:09:28, 34.66s/it, lr=5e-5, step_loss=0.0468]Steps:  16%|█▋        | 64/391 [35:58<3:08:24, 34.57s/it, lr=5e-5, step_loss=0.0468]Steps:  16%|█▋        | 64/391 [35:58<3:08:24, 34.57s/it, lr=5e-5, step_loss=0.0383]Steps:  16%|█▋        | 64/391 [36:08<3:08:24, 34.57s/it, lr=5e-5, step_loss=0.0396]Steps:  16%|█▋        | 64/391 [36:16<3:08:24, 34.57s/it, lr=5e-5, step_loss=0.0521]Steps:  16%|█▋        | 64/391 [36:25<3:08:24, 34.57s/it, lr=5e-5, step_loss=0.0289]Steps:  17%|█▋        | 65/391 [36:33<3:07:56, 34.59s/it, lr=5e-5, step_loss=0.0289]Steps:  17%|█▋        | 65/391 [36:33<3:07:56, 34.59s/it, lr=5e-5, step_loss=0.0499]Steps:  17%|█▋        | 65/391 [36:42<3:07:56, 34.59s/it, lr=5e-5, step_loss=0.0387]Steps:  17%|█▋        | 65/391 [36:51<3:07:56, 34.59s/it, lr=5e-5, step_loss=0.0343]Steps:  17%|█▋        | 65/391 [36:59<3:07:56, 34.59s/it, lr=5e-5, step_loss=0.0641]Steps:  17%|█▋        | 66/391 [37:07<3:06:31, 34.44s/it, lr=5e-5, step_loss=0.0641]Steps:  17%|█▋        | 66/391 [37:07<3:06:31, 34.44s/it, lr=5e-5, step_loss=0.0474]Steps:  17%|█▋        | 66/391 [37:16<3:06:31, 34.44s/it, lr=5e-5, step_loss=0.0398]Steps:  17%|█▋        | 66/391 [37:25<3:06:31, 34.44s/it, lr=5e-5, step_loss=0.0358]Steps:  17%|█▋        | 66/391 [37:34<3:06:31, 34.44s/it, lr=5e-5, step_loss=0.0544]Steps:  17%|█▋        | 67/391 [37:43<3:08:52, 34.98s/it, lr=5e-5, step_loss=0.0544]Steps:  17%|█▋        | 67/391 [37:43<3:08:52, 34.98s/it, lr=5e-5, step_loss=0.0453]Steps:  17%|█▋        | 67/391 [37:52<3:08:52, 34.98s/it, lr=5e-5, step_loss=0.05]  Steps:  17%|█▋        | 67/391 [38:00<3:08:52, 34.98s/it, lr=5e-5, step_loss=0.0649]Steps:  17%|█▋        | 67/391 [38:09<3:08:52, 34.98s/it, lr=5e-5, step_loss=0.083] Steps:  17%|█▋        | 68/391 [38:17<3:06:37, 34.67s/it, lr=5e-5, step_loss=0.083]Steps:  17%|█▋        | 68/391 [38:17<3:06:37, 34.67s/it, lr=5e-5, step_loss=0.0488]Steps:  17%|█▋        | 68/391 [38:24<3:06:37, 34.67s/it, lr=5e-5, step_loss=0.0417]Steps:  18%|█▊        | 69/391 [38:25<2:23:27, 26.73s/it, lr=5e-5, step_loss=0.0417]Steps:  18%|█▊        | 69/391 [38:25<2:23:27, 26.73s/it, lr=5e-5, step_loss=0.0789]Steps:  18%|█▊        | 69/391 [38:41<2:23:27, 26.73s/it, lr=5e-5, step_loss=0.0518]Steps:  18%|█▊        | 69/391 [38:50<2:23:27, 26.73s/it, lr=5e-5, step_loss=0.0422]Steps:  18%|█▊        | 69/391 [38:58<2:23:27, 26.73s/it, lr=5e-5, step_loss=0.0436]Steps:  18%|█▊        | 70/391 [39:06<2:45:47, 30.99s/it, lr=5e-5, step_loss=0.0436]Steps:  18%|█▊        | 70/391 [39:06<2:45:47, 30.99s/it, lr=5e-5, step_loss=0.0478]Steps:  18%|█▊        | 70/391 [39:15<2:45:47, 30.99s/it, lr=5e-5, step_loss=0.0554]Steps:  18%|█▊        | 70/391 [39:23<2:45:47, 30.99s/it, lr=5e-5, step_loss=0.0519]Steps:  18%|█▊        | 70/391 [39:32<2:45:47, 30.99s/it, lr=5e-5, step_loss=0.0633]Steps:  18%|█▊        | 71/391 [39:40<2:49:52, 31.85s/it, lr=5e-5, step_loss=0.0633]Steps:  18%|█▊        | 71/391 [39:40<2:49:52, 31.85s/it, lr=5e-5, step_loss=0.0624]Steps:  18%|█▊        | 71/391 [39:49<2:49:52, 31.85s/it, lr=5e-5, step_loss=0.0496]Steps:  18%|█▊        | 71/391 [39:57<2:49:52, 31.85s/it, lr=5e-5, step_loss=0.0619]Steps:  18%|█▊        | 71/391 [40:06<2:49:52, 31.85s/it, lr=5e-5, step_loss=0.0363]Steps:  18%|█▊        | 72/391 [40:15<2:53:26, 32.62s/it, lr=5e-5, step_loss=0.0363]Steps:  18%|█▊        | 72/391 [40:15<2:53:26, 32.62s/it, lr=5e-5, step_loss=0.0499]Steps:  18%|█▊        | 72/391 [40:24<2:53:26, 32.62s/it, lr=5e-5, step_loss=0.05]  Steps:  18%|█▊        | 72/391 [40:33<2:53:26, 32.62s/it, lr=5e-5, step_loss=0.0364]Steps:  18%|█▊        | 72/391 [40:42<2:53:26, 32.62s/it, lr=5e-5, step_loss=0.0576]Steps:  19%|█▊        | 73/391 [40:51<2:58:47, 33.74s/it, lr=5e-5, step_loss=0.0576]Steps:  19%|█▊        | 73/391 [40:51<2:58:47, 33.74s/it, lr=5e-5, step_loss=0.0314]Steps:  19%|█▊        | 73/391 [40:59<2:58:47, 33.74s/it, lr=5e-5, step_loss=0.0553]Steps:  19%|█▊        | 73/391 [41:09<2:58:47, 33.74s/it, lr=5e-5, step_loss=0.0843]Steps:  19%|█▊        | 73/391 [41:18<2:58:47, 33.74s/it, lr=5e-5, step_loss=0.0392]Steps:  19%|█▉        | 74/391 [41:27<3:01:12, 34.30s/it, lr=5e-5, step_loss=0.0392]Steps:  19%|█▉        | 74/391 [41:27<3:01:12, 34.30s/it, lr=5e-5, step_loss=0.0573]Steps:  19%|█▉        | 74/391 [41:35<3:01:12, 34.30s/it, lr=5e-5, step_loss=0.0414]Steps:  19%|█▉        | 74/391 [41:44<3:01:12, 34.30s/it, lr=5e-5, step_loss=0.0451]Steps:  19%|█▉        | 74/391 [41:53<3:01:12, 34.30s/it, lr=5e-5, step_loss=0.0598]Steps:  19%|█▉        | 75/391 [42:02<3:02:48, 34.71s/it, lr=5e-5, step_loss=0.0598]Steps:  19%|█▉        | 75/391 [42:02<3:02:48, 34.71s/it, lr=5e-5, step_loss=0.0486]Steps:  19%|█▉        | 75/391 [42:11<3:02:48, 34.71s/it, lr=5e-5, step_loss=0.0408]Steps:  19%|█▉        | 75/391 [42:19<3:02:48, 34.71s/it, lr=5e-5, step_loss=0.039] Steps:  19%|█▉        | 75/391 [42:29<3:02:48, 34.71s/it, lr=5e-5, step_loss=0.0311]Steps:  19%|█▉        | 76/391 [42:37<3:02:13, 34.71s/it, lr=5e-5, step_loss=0.0311]Steps:  19%|█▉        | 76/391 [42:37<3:02:13, 34.71s/it, lr=5e-5, step_loss=0.0436]Steps:  19%|█▉        | 76/391 [42:45<3:02:13, 34.71s/it, lr=5e-5, step_loss=0.0377]Steps:  19%|█▉        | 76/391 [42:53<3:02:13, 34.71s/it, lr=5e-5, step_loss=0.0496]Steps:  19%|█▉        | 76/391 [43:03<3:02:13, 34.71s/it, lr=5e-5, step_loss=0.0678]Steps:  20%|█▉        | 77/391 [43:11<3:00:43, 34.53s/it, lr=5e-5, step_loss=0.0678]Steps:  20%|█▉        | 77/391 [43:11<3:00:43, 34.53s/it, lr=5e-5, step_loss=0.0599]Steps:  20%|█▉        | 77/391 [43:19<3:00:43, 34.53s/it, lr=5e-5, step_loss=0.0493]Steps:  20%|█▉        | 77/391 [43:27<3:00:43, 34.53s/it, lr=5e-5, step_loss=0.0507]Steps:  20%|█▉        | 77/391 [43:36<3:00:43, 34.53s/it, lr=5e-5, step_loss=0.0538]Steps:  20%|█▉        | 78/391 [43:46<3:00:11, 34.54s/it, lr=5e-5, step_loss=0.0538]Steps:  20%|█▉        | 78/391 [43:46<3:00:11, 34.54s/it, lr=5e-5, step_loss=0.0575]Steps:  20%|█▉        | 78/391 [43:55<3:00:11, 34.54s/it, lr=5e-5, step_loss=0.0345]Steps:  20%|█▉        | 78/391 [44:03<3:00:11, 34.54s/it, lr=5e-5, step_loss=0.0458]Steps:  20%|█▉        | 78/391 [44:11<3:00:11, 34.54s/it, lr=5e-5, step_loss=0.0664]Steps:  20%|██        | 79/391 [44:20<2:58:38, 34.35s/it, lr=5e-5, step_loss=0.0664]Steps:  20%|██        | 79/391 [44:20<2:58:38, 34.35s/it, lr=5e-5, step_loss=0.049] Steps:  20%|██        | 79/391 [44:28<2:58:38, 34.35s/it, lr=5e-5, step_loss=0.0643]Steps:  20%|██        | 79/391 [44:36<2:58:38, 34.35s/it, lr=5e-5, step_loss=0.0372]Steps:  20%|██        | 79/391 [44:44<2:58:38, 34.35s/it, lr=5e-5, step_loss=0.0525]Steps:  20%|██        | 80/391 [44:53<2:56:46, 34.11s/it, lr=5e-5, step_loss=0.0525]Steps:  20%|██        | 80/391 [44:53<2:56:46, 34.11s/it, lr=5e-5, step_loss=0.0495]Steps:  20%|██        | 80/391 [45:01<2:56:46, 34.11s/it, lr=5e-5, step_loss=0.0567]Steps:  20%|██        | 80/391 [45:11<2:56:46, 34.11s/it, lr=5e-5, step_loss=0.0741]Steps:  20%|██        | 80/391 [45:18<2:56:46, 34.11s/it, lr=5e-5, step_loss=0.0385]Steps:  21%|██        | 81/391 [45:27<2:55:39, 34.00s/it, lr=5e-5, step_loss=0.0385]Steps:  21%|██        | 81/391 [45:27<2:55:39, 34.00s/it, lr=5e-5, step_loss=0.0444]Steps:  21%|██        | 81/391 [45:35<2:55:39, 34.00s/it, lr=5e-5, step_loss=0.0627]Steps:  21%|██        | 81/391 [45:44<2:55:39, 34.00s/it, lr=5e-5, step_loss=0.0395]Steps:  21%|██        | 81/391 [45:52<2:55:39, 34.00s/it, lr=5e-5, step_loss=0.0428]Steps:  21%|██        | 82/391 [46:01<2:55:04, 34.00s/it, lr=5e-5, step_loss=0.0428]Steps:  21%|██        | 82/391 [46:01<2:55:04, 34.00s/it, lr=5e-5, step_loss=0.0544]Steps:  21%|██        | 82/391 [46:10<2:55:04, 34.00s/it, lr=5e-5, step_loss=0.0599]Steps:  21%|██        | 82/391 [46:19<2:55:04, 34.00s/it, lr=5e-5, step_loss=0.0486]Steps:  21%|██        | 82/391 [46:28<2:55:04, 34.00s/it, lr=5e-5, step_loss=0.0378]Steps:  21%|██        | 83/391 [46:37<2:57:51, 34.65s/it, lr=5e-5, step_loss=0.0378]Steps:  21%|██        | 83/391 [46:37<2:57:51, 34.65s/it, lr=5e-5, step_loss=0.0476]Steps:  21%|██        | 83/391 [46:45<2:57:51, 34.65s/it, lr=5e-5, step_loss=0.0422]Steps:  21%|██        | 83/391 [46:53<2:57:51, 34.65s/it, lr=5e-5, step_loss=0.0515]Steps:  21%|██        | 83/391 [47:02<2:57:51, 34.65s/it, lr=5e-5, step_loss=0.0487]Steps:  21%|██▏       | 84/391 [47:10<2:54:05, 34.03s/it, lr=5e-5, step_loss=0.0487]Steps:  21%|██▏       | 84/391 [47:10<2:54:05, 34.03s/it, lr=5e-5, step_loss=0.046] Steps:  21%|██▏       | 84/391 [47:16<2:54:05, 34.03s/it, lr=5e-5, step_loss=0.0579]Steps:  21%|██▏       | 84/391 [47:25<2:54:05, 34.03s/it, lr=5e-5, step_loss=0.0359]Steps:  21%|██▏       | 84/391 [47:35<2:54:05, 34.03s/it, lr=5e-5, step_loss=0.0703]Steps:  22%|██▏       | 85/391 [47:42<2:51:44, 33.67s/it, lr=5e-5, step_loss=0.0703]Steps:  22%|██▏       | 85/391 [47:42<2:51:44, 33.67s/it, lr=5e-5, step_loss=0.0365]Steps:  22%|██▏       | 85/391 [47:51<2:51:44, 33.67s/it, lr=5e-5, step_loss=0.0414]Steps:  22%|██▏       | 85/391 [47:59<2:51:44, 33.67s/it, lr=5e-5, step_loss=0.0484]Steps:  22%|██▏       | 85/391 [48:08<2:51:44, 33.67s/it, lr=5e-5, step_loss=0.046] Steps:  22%|██▏       | 86/391 [48:16<2:50:45, 33.59s/it, lr=5e-5, step_loss=0.046]Steps:  22%|██▏       | 86/391 [48:16<2:50:45, 33.59s/it, lr=5e-5, step_loss=0.0526]Steps:  22%|██▏       | 86/391 [48:25<2:50:45, 33.59s/it, lr=5e-5, step_loss=0.0395]Steps:  22%|██▏       | 86/391 [48:33<2:50:45, 33.59s/it, lr=5e-5, step_loss=0.0457]Steps:  22%|██▏       | 86/391 [48:41<2:50:45, 33.59s/it, lr=5e-5, step_loss=0.0415]Steps:  22%|██▏       | 87/391 [48:49<2:49:32, 33.46s/it, lr=5e-5, step_loss=0.0415]Steps:  22%|██▏       | 87/391 [48:49<2:49:32, 33.46s/it, lr=5e-5, step_loss=0.056] Steps:  22%|██▏       | 87/391 [48:57<2:49:32, 33.46s/it, lr=5e-5, step_loss=0.0521]Steps:  22%|██▏       | 87/391 [49:05<2:49:32, 33.46s/it, lr=5e-5, step_loss=0.0392]Steps:  22%|██▏       | 87/391 [49:13<2:49:32, 33.46s/it, lr=5e-5, step_loss=0.0366]Steps:  23%|██▎       | 88/391 [49:22<2:47:38, 33.20s/it, lr=5e-5, step_loss=0.0366]Steps:  23%|██▎       | 88/391 [49:22<2:47:38, 33.20s/it, lr=5e-5, step_loss=0.041] Steps:  23%|██▎       | 88/391 [49:30<2:47:38, 33.20s/it, lr=5e-5, step_loss=0.0452]Steps:  23%|██▎       | 88/391 [49:37<2:47:38, 33.20s/it, lr=5e-5, step_loss=0.0447]Steps:  23%|██▎       | 88/391 [49:46<2:47:38, 33.20s/it, lr=5e-5, step_loss=0.0452]Steps:  23%|██▎       | 89/391 [49:54<2:46:34, 33.09s/it, lr=5e-5, step_loss=0.0452]Steps:  23%|██▎       | 89/391 [49:54<2:46:34, 33.09s/it, lr=5e-5, step_loss=0.0516]Steps:  23%|██▎       | 89/391 [50:03<2:46:34, 33.09s/it, lr=5e-5, step_loss=0.0519]Steps:  23%|██▎       | 89/391 [50:12<2:46:34, 33.09s/it, lr=5e-5, step_loss=0.0597]Steps:  23%|██▎       | 89/391 [50:20<2:46:34, 33.09s/it, lr=5e-5, step_loss=0.0319]Steps:  23%|██▎       | 90/391 [50:27<2:45:41, 33.03s/it, lr=5e-5, step_loss=0.0319]Steps:  23%|██▎       | 90/391 [50:27<2:45:41, 33.03s/it, lr=5e-5, step_loss=0.0519]Steps:  23%|██▎       | 90/391 [50:35<2:45:41, 33.03s/it, lr=5e-5, step_loss=0.0481]Steps:  23%|██▎       | 90/391 [50:43<2:45:41, 33.03s/it, lr=5e-5, step_loss=0.0488]Steps:  23%|██▎       | 90/391 [50:50<2:45:41, 33.03s/it, lr=5e-5, step_loss=0.0491]Steps:  23%|██▎       | 91/391 [50:58<2:41:01, 32.20s/it, lr=5e-5, step_loss=0.0491]Steps:  23%|██▎       | 91/391 [50:58<2:41:01, 32.20s/it, lr=5e-5, step_loss=0.0479]Steps:  23%|██▎       | 91/391 [51:06<2:41:01, 32.20s/it, lr=5e-5, step_loss=0.0604]Steps:  24%|██▎       | 92/391 [51:07<2:05:46, 25.24s/it, lr=5e-5, step_loss=0.0604]Steps:  24%|██▎       | 92/391 [51:07<2:05:46, 25.24s/it, lr=5e-5, step_loss=0.0444]Steps:  24%|██▎       | 92/391 [51:23<2:05:46, 25.24s/it, lr=5e-5, step_loss=0.0385]Steps:  24%|██▎       | 92/391 [51:32<2:05:46, 25.24s/it, lr=5e-5, step_loss=0.0565]Steps:  24%|██▎       | 92/391 [51:40<2:05:46, 25.24s/it, lr=5e-5, step_loss=0.0597]Steps:  24%|██▍       | 93/391 [51:47<2:28:45, 29.95s/it, lr=5e-5, step_loss=0.0597]Steps:  24%|██▍       | 93/391 [51:47<2:28:45, 29.95s/it, lr=5e-5, step_loss=0.0453]Steps:  24%|██▍       | 93/391 [51:55<2:28:45, 29.95s/it, lr=5e-5, step_loss=0.0461]Steps:  24%|██▍       | 93/391 [52:04<2:28:45, 29.95s/it, lr=5e-5, step_loss=0.0273]Steps:  24%|██▍       | 93/391 [52:13<2:28:45, 29.95s/it, lr=5e-5, step_loss=0.0412]Steps:  24%|██▍       | 94/391 [52:21<2:33:04, 30.92s/it, lr=5e-5, step_loss=0.0412]Steps:  24%|██▍       | 94/391 [52:21<2:33:04, 30.92s/it, lr=5e-5, step_loss=0.0356]Steps:  24%|██▍       | 94/391 [52:28<2:33:04, 30.92s/it, lr=5e-5, step_loss=0.041] Steps:  24%|██▍       | 94/391 [52:37<2:33:04, 30.92s/it, lr=5e-5, step_loss=0.0671]Steps:  24%|██▍       | 94/391 [52:45<2:33:04, 30.92s/it, lr=5e-5, step_loss=0.0429]Steps:  24%|██▍       | 95/391 [52:53<2:34:50, 31.39s/it, lr=5e-5, step_loss=0.0429]Steps:  24%|██▍       | 95/391 [52:53<2:34:50, 31.39s/it, lr=5e-5, step_loss=0.0287]Steps:  24%|██▍       | 95/391 [53:02<2:34:50, 31.39s/it, lr=5e-5, step_loss=0.0638]Steps:  24%|██▍       | 95/391 [53:10<2:34:50, 31.39s/it, lr=5e-5, step_loss=0.049] Steps:  24%|██▍       | 95/391 [53:18<2:34:50, 31.39s/it, lr=5e-5, step_loss=0.0543]Steps:  25%|██▍       | 96/391 [53:26<2:35:47, 31.69s/it, lr=5e-5, step_loss=0.0543]Steps:  25%|██▍       | 96/391 [53:26<2:35:47, 31.69s/it, lr=5e-5, step_loss=0.051] Steps:  25%|██▍       | 96/391 [53:34<2:35:47, 31.69s/it, lr=5e-5, step_loss=0.0514]Steps:  25%|██▍       | 96/391 [53:41<2:35:47, 31.69s/it, lr=5e-5, step_loss=0.0359]Steps:  25%|██▍       | 96/391 [53:49<2:35:47, 31.69s/it, lr=5e-5, step_loss=0.0428]Steps:  25%|██▍       | 97/391 [53:58<2:36:34, 31.96s/it, lr=5e-5, step_loss=0.0428]Steps:  25%|██▍       | 97/391 [53:58<2:36:34, 31.96s/it, lr=5e-5, step_loss=0.0394]Steps:  25%|██▍       | 97/391 [54:05<2:36:34, 31.96s/it, lr=5e-5, step_loss=0.0324]Steps:  25%|██▍       | 97/391 [54:14<2:36:34, 31.96s/it, lr=5e-5, step_loss=0.052] Steps:  25%|██▍       | 97/391 [54:22<2:36:34, 31.96s/it, lr=5e-5, step_loss=0.0422]Steps:  25%|██▌       | 98/391 [54:33<2:39:49, 32.73s/it, lr=5e-5, step_loss=0.0422]Steps:  25%|██▌       | 98/391 [54:33<2:39:49, 32.73s/it, lr=5e-5, step_loss=0.0363]Steps:  25%|██▌       | 98/391 [54:41<2:39:49, 32.73s/it, lr=5e-5, step_loss=0.0372]Steps:  25%|██▌       | 98/391 [54:53<2:39:49, 32.73s/it, lr=5e-5, step_loss=0.0464]Steps:  25%|██▌       | 98/391 [55:01<2:39:49, 32.73s/it, lr=5e-5, step_loss=0.0364]Steps:  25%|██▌       | 99/391 [55:09<2:44:10, 33.74s/it, lr=5e-5, step_loss=0.0364]Steps:  25%|██▌       | 99/391 [55:09<2:44:10, 33.74s/it, lr=5e-5, step_loss=0.0331]Steps:  25%|██▌       | 99/391 [55:17<2:44:10, 33.74s/it, lr=5e-5, step_loss=0.0474]Steps:  25%|██▌       | 99/391 [55:26<2:44:10, 33.74s/it, lr=5e-5, step_loss=0.0482]Steps:  25%|██▌       | 99/391 [55:39<2:44:10, 33.74s/it, lr=5e-5, step_loss=0.0313]Steps:  26%|██▌       | 100/391 [55:49<2:53:20, 35.74s/it, lr=5e-5, step_loss=0.0313]06/08/2025 10:24:25 - INFO - accelerate.accelerator - Saving current state to finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-100
Configuration saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-100/unet_ema/config.json
Model weights saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-100/unet_ema/diffusion_pytorch_model.safetensors
Configuration saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-100/unet/config.json
Model weights saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-100/unet/diffusion_pytorch_model.safetensors
06/08/2025 10:24:55 - INFO - accelerate.checkpointing - Optimizer state saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-100/optimizer.bin
06/08/2025 10:24:55 - INFO - accelerate.checkpointing - Scheduler state saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-100/scheduler.bin
06/08/2025 10:24:55 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-100/sampler.bin
06/08/2025 10:24:55 - INFO - accelerate.checkpointing - Gradient scaler state saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-100/scaler.pt
06/08/2025 10:24:55 - INFO - accelerate.checkpointing - Random states saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-100/random_states_0.pkl
06/08/2025 10:24:55 - INFO - __main__ - Saved state to finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-100
Steps:  26%|██▌       | 100/391 [56:19<2:53:20, 35.74s/it, lr=5e-5, step_loss=0.0386]Steps:  26%|██▌       | 100/391 [56:30<2:53:20, 35.74s/it, lr=5e-5, step_loss=0.0517]Steps:  26%|██▌       | 100/391 [56:42<2:53:20, 35.74s/it, lr=5e-5, step_loss=0.0676]Steps:  26%|██▌       | 100/391 [56:52<2:53:20, 35.74s/it, lr=5e-5, step_loss=0.0396]Steps:  26%|██▌       | 101/391 [57:04<3:49:46, 47.54s/it, lr=5e-5, step_loss=0.0396]Steps:  26%|██▌       | 101/391 [57:04<3:49:46, 47.54s/it, lr=5e-5, step_loss=0.0519]Steps:  26%|██▌       | 101/391 [57:15<3:49:46, 47.54s/it, lr=5e-5, step_loss=0.0454]Steps:  26%|██▌       | 101/391 [57:25<3:49:46, 47.54s/it, lr=5e-5, step_loss=0.0277]Steps:  26%|██▌       | 101/391 [57:34<3:49:46, 47.54s/it, lr=5e-5, step_loss=0.0368]Steps:  26%|██▌       | 102/391 [57:45<3:38:57, 45.46s/it, lr=5e-5, step_loss=0.0368]Steps:  26%|██▌       | 102/391 [57:45<3:38:57, 45.46s/it, lr=5e-5, step_loss=0.0339]Steps:  26%|██▌       | 102/391 [57:56<3:38:57, 45.46s/it, lr=5e-5, step_loss=0.056] Steps:  26%|██▌       | 102/391 [58:06<3:38:57, 45.46s/it, lr=5e-5, step_loss=0.0558]Steps:  26%|██▌       | 102/391 [58:16<3:38:57, 45.46s/it, lr=5e-5, step_loss=0.0429]Steps:  26%|██▋       | 103/391 [58:28<3:35:24, 44.88s/it, lr=5e-5, step_loss=0.0429]Steps:  26%|██▋       | 103/391 [58:28<3:35:24, 44.88s/it, lr=5e-5, step_loss=0.0288]Steps:  26%|██▋       | 103/391 [58:39<3:35:24, 44.88s/it, lr=5e-5, step_loss=0.0263]Steps:  26%|██▋       | 103/391 [58:49<3:35:24, 44.88s/it, lr=5e-5, step_loss=0.0433]Steps:  26%|██▋       | 103/391 [59:00<3:35:24, 44.88s/it, lr=5e-5, step_loss=0.0541]Steps:  27%|██▋       | 104/391 [59:11<3:32:08, 44.35s/it, lr=5e-5, step_loss=0.0541]Steps:  27%|██▋       | 104/391 [59:11<3:32:08, 44.35s/it, lr=5e-5, step_loss=0.0479]Steps:  27%|██▋       | 104/391 [59:22<3:32:08, 44.35s/it, lr=5e-5, step_loss=0.0504]Steps:  27%|██▋       | 104/391 [59:34<3:32:08, 44.35s/it, lr=5e-5, step_loss=0.0654]Steps:  27%|██▋       | 104/391 [59:45<3:32:08, 44.35s/it, lr=5e-5, step_loss=0.053] Steps:  27%|██▋       | 105/391 [59:56<3:31:19, 44.33s/it, lr=5e-5, step_loss=0.053]Steps:  27%|██▋       | 105/391 [59:56<3:31:19, 44.33s/it, lr=5e-5, step_loss=0.0441]Steps:  27%|██▋       | 105/391 [1:00:06<3:31:19, 44.33s/it, lr=5e-5, step_loss=0.0356]Steps:  27%|██▋       | 105/391 [1:00:18<3:31:19, 44.33s/it, lr=5e-5, step_loss=0.0353]Steps:  27%|██▋       | 105/391 [1:00:29<3:31:19, 44.33s/it, lr=5e-5, step_loss=0.0606]Steps:  27%|██▋       | 106/391 [1:00:42<3:33:15, 44.90s/it, lr=5e-5, step_loss=0.0606]Steps:  27%|██▋       | 106/391 [1:00:42<3:33:15, 44.90s/it, lr=5e-5, step_loss=0.0422]Steps:  27%|██▋       | 106/391 [1:00:54<3:33:15, 44.90s/it, lr=5e-5, step_loss=0.0434]Steps:  27%|██▋       | 106/391 [1:01:07<3:33:15, 44.90s/it, lr=5e-5, step_loss=0.0767]Steps:  27%|██▋       | 106/391 [1:01:19<3:33:15, 44.90s/it, lr=5e-5, step_loss=0.0494]Steps:  27%|██▋       | 107/391 [1:01:30<3:37:24, 45.93s/it, lr=5e-5, step_loss=0.0494]Steps:  27%|██▋       | 107/391 [1:01:30<3:37:24, 45.93s/it, lr=5e-5, step_loss=0.0619]Steps:  27%|██▋       | 107/391 [1:01:42<3:37:24, 45.93s/it, lr=5e-5, step_loss=0.0336]Steps:  27%|██▋       | 107/391 [1:01:52<3:37:24, 45.93s/it, lr=5e-5, step_loss=0.0542]Steps:  27%|██▋       | 107/391 [1:02:03<3:37:24, 45.93s/it, lr=5e-5, step_loss=0.0547]Steps:  28%|██▊       | 108/391 [1:02:13<3:32:04, 44.96s/it, lr=5e-5, step_loss=0.0547]Steps:  28%|██▊       | 108/391 [1:02:13<3:32:04, 44.96s/it, lr=5e-5, step_loss=0.032] Steps:  28%|██▊       | 108/391 [1:02:24<3:32:04, 44.96s/it, lr=5e-5, step_loss=0.0344]Steps:  28%|██▊       | 108/391 [1:02:35<3:32:04, 44.96s/it, lr=5e-5, step_loss=0.039] Steps:  28%|██▊       | 108/391 [1:02:47<3:32:04, 44.96s/it, lr=5e-5, step_loss=0.0331]Steps:  28%|██▊       | 109/391 [1:03:00<3:33:34, 45.44s/it, lr=5e-5, step_loss=0.0331]Steps:  28%|██▊       | 109/391 [1:03:00<3:33:34, 45.44s/it, lr=5e-5, step_loss=0.0333]Steps:  28%|██▊       | 109/391 [1:03:09<3:33:34, 45.44s/it, lr=5e-5, step_loss=0.0546]Steps:  28%|██▊       | 109/391 [1:03:19<3:33:34, 45.44s/it, lr=5e-5, step_loss=0.0482]Steps:  28%|██▊       | 109/391 [1:03:30<3:33:34, 45.44s/it, lr=5e-5, step_loss=0.0449]Steps:  28%|██▊       | 110/391 [1:03:38<3:22:39, 43.27s/it, lr=5e-5, step_loss=0.0449]Steps:  28%|██▊       | 110/391 [1:03:38<3:22:39, 43.27s/it, lr=5e-5, step_loss=0.0567]Steps:  28%|██▊       | 110/391 [1:03:49<3:22:39, 43.27s/it, lr=5e-5, step_loss=0.0426]Steps:  28%|██▊       | 110/391 [1:03:58<3:22:39, 43.27s/it, lr=5e-5, step_loss=0.0497]Steps:  28%|██▊       | 110/391 [1:04:07<3:22:39, 43.27s/it, lr=5e-5, step_loss=0.0461]Steps:  28%|██▊       | 111/391 [1:04:16<3:14:08, 41.60s/it, lr=5e-5, step_loss=0.0461]Steps:  28%|██▊       | 111/391 [1:04:16<3:14:08, 41.60s/it, lr=5e-5, step_loss=0.047] Steps:  28%|██▊       | 111/391 [1:04:24<3:14:08, 41.60s/it, lr=5e-5, step_loss=0.0505]Steps:  28%|██▊       | 111/391 [1:04:33<3:14:08, 41.60s/it, lr=5e-5, step_loss=0.0583]Steps:  28%|██▊       | 111/391 [1:04:45<3:14:08, 41.60s/it, lr=5e-5, step_loss=0.0383]Steps:  29%|██▊       | 112/391 [1:04:56<3:11:38, 41.21s/it, lr=5e-5, step_loss=0.0383]Steps:  29%|██▊       | 112/391 [1:04:56<3:11:38, 41.21s/it, lr=5e-5, step_loss=0.0318]Steps:  29%|██▊       | 112/391 [1:05:08<3:11:38, 41.21s/it, lr=5e-5, step_loss=0.0443]Steps:  29%|██▊       | 112/391 [1:05:16<3:11:38, 41.21s/it, lr=5e-5, step_loss=0.0258]Steps:  29%|██▊       | 112/391 [1:05:24<3:11:38, 41.21s/it, lr=5e-5, step_loss=0.035] Steps:  29%|██▉       | 113/391 [1:05:33<3:05:40, 40.07s/it, lr=5e-5, step_loss=0.035]Steps:  29%|██▉       | 113/391 [1:05:33<3:05:40, 40.07s/it, lr=5e-5, step_loss=0.0351]Steps:  29%|██▉       | 113/391 [1:05:43<3:05:40, 40.07s/it, lr=5e-5, step_loss=0.0565]Steps:  29%|██▉       | 113/391 [1:05:53<3:05:40, 40.07s/it, lr=5e-5, step_loss=0.0487]Steps:  29%|██▉       | 113/391 [1:06:01<3:05:40, 40.07s/it, lr=5e-5, step_loss=0.0407]Steps:  29%|██▉       | 114/391 [1:06:10<3:00:10, 39.03s/it, lr=5e-5, step_loss=0.0407]Steps:  29%|██▉       | 114/391 [1:06:10<3:00:10, 39.03s/it, lr=5e-5, step_loss=0.0389]Steps:  29%|██▉       | 114/391 [1:06:18<3:00:10, 39.03s/it, lr=5e-5, step_loss=0.0443]Steps:  29%|██▉       | 115/391 [1:06:19<2:17:49, 29.96s/it, lr=5e-5, step_loss=0.0443]Steps:  29%|██▉       | 115/391 [1:06:19<2:17:49, 29.96s/it, lr=5e-5, step_loss=0.0438]Steps:  29%|██▉       | 115/391 [1:06:35<2:17:49, 29.96s/it, lr=5e-5, step_loss=0.0506]Steps:  29%|██▉       | 115/391 [1:06:44<2:17:49, 29.96s/it, lr=5e-5, step_loss=0.0695]Steps:  29%|██▉       | 115/391 [1:06:54<2:17:49, 29.96s/it, lr=5e-5, step_loss=0.0394]Steps:  30%|██▉       | 116/391 [1:07:05<2:39:58, 34.90s/it, lr=5e-5, step_loss=0.0394]Steps:  30%|██▉       | 116/391 [1:07:05<2:39:58, 34.90s/it, lr=5e-5, step_loss=0.06]  Steps:  30%|██▉       | 116/391 [1:07:14<2:39:58, 34.90s/it, lr=5e-5, step_loss=0.0277]Steps:  30%|██▉       | 116/391 [1:07:24<2:39:58, 34.90s/it, lr=5e-5, step_loss=0.0353]Steps:  30%|██▉       | 116/391 [1:07:32<2:39:58, 34.90s/it, lr=5e-5, step_loss=0.0472]Steps:  30%|██▉       | 117/391 [1:07:41<2:40:31, 35.15s/it, lr=5e-5, step_loss=0.0472]Steps:  30%|██▉       | 117/391 [1:07:41<2:40:31, 35.15s/it, lr=5e-5, step_loss=0.0613]Steps:  30%|██▉       | 117/391 [1:07:50<2:40:31, 35.15s/it, lr=5e-5, step_loss=0.037] Steps:  30%|██▉       | 117/391 [1:07:57<2:40:31, 35.15s/it, lr=5e-5, step_loss=0.0484]Steps:  30%|██▉       | 117/391 [1:08:06<2:40:31, 35.15s/it, lr=5e-5, step_loss=0.0464]Steps:  30%|███       | 118/391 [1:08:17<2:41:56, 35.59s/it, lr=5e-5, step_loss=0.0464]Steps:  30%|███       | 118/391 [1:08:17<2:41:56, 35.59s/it, lr=5e-5, step_loss=0.0545]Steps:  30%|███       | 118/391 [1:08:26<2:41:56, 35.59s/it, lr=5e-5, step_loss=0.0552]Steps:  30%|███       | 118/391 [1:08:39<2:41:56, 35.59s/it, lr=5e-5, step_loss=0.0355]Steps:  30%|███       | 118/391 [1:08:49<2:41:56, 35.59s/it, lr=5e-5, step_loss=0.0422]Steps:  30%|███       | 119/391 [1:08:58<2:48:04, 37.08s/it, lr=5e-5, step_loss=0.0422]Steps:  30%|███       | 119/391 [1:08:58<2:48:04, 37.08s/it, lr=5e-5, step_loss=0.0534]Steps:  30%|███       | 119/391 [1:09:06<2:48:04, 37.08s/it, lr=5e-5, step_loss=0.0518]Steps:  30%|███       | 119/391 [1:09:18<2:48:04, 37.08s/it, lr=5e-5, step_loss=0.0443]Steps:  30%|███       | 119/391 [1:09:28<2:48:04, 37.08s/it, lr=5e-5, step_loss=0.0598]Steps:  31%|███       | 120/391 [1:09:36<2:49:18, 37.49s/it, lr=5e-5, step_loss=0.0598]Steps:  31%|███       | 120/391 [1:09:36<2:49:18, 37.49s/it, lr=5e-5, step_loss=0.0517]Steps:  31%|███       | 120/391 [1:09:47<2:49:18, 37.49s/it, lr=5e-5, step_loss=0.0524]Steps:  31%|███       | 120/391 [1:09:57<2:49:18, 37.49s/it, lr=5e-5, step_loss=0.0472]Steps:  31%|███       | 120/391 [1:10:06<2:49:18, 37.49s/it, lr=5e-5, step_loss=0.0591]Steps:  31%|███       | 121/391 [1:10:15<2:50:22, 37.86s/it, lr=5e-5, step_loss=0.0591]Steps:  31%|███       | 121/391 [1:10:15<2:50:22, 37.86s/it, lr=5e-5, step_loss=0.0484]Steps:  31%|███       | 121/391 [1:10:26<2:50:22, 37.86s/it, lr=5e-5, step_loss=0.0481]Steps:  31%|███       | 121/391 [1:10:37<2:50:22, 37.86s/it, lr=5e-5, step_loss=0.0604]Steps:  31%|███       | 121/391 [1:10:47<2:50:22, 37.86s/it, lr=5e-5, step_loss=0.0416]Steps:  31%|███       | 122/391 [1:10:59<2:57:16, 39.54s/it, lr=5e-5, step_loss=0.0416]Steps:  31%|███       | 122/391 [1:10:59<2:57:16, 39.54s/it, lr=5e-5, step_loss=0.0456]Steps:  31%|███       | 122/391 [1:11:11<2:57:16, 39.54s/it, lr=5e-5, step_loss=0.0411]Steps:  31%|███       | 122/391 [1:11:22<2:57:16, 39.54s/it, lr=5e-5, step_loss=0.0663]Steps:  31%|███       | 122/391 [1:11:34<2:57:16, 39.54s/it, lr=5e-5, step_loss=0.0682]Steps:  31%|███▏      | 123/391 [1:11:45<3:06:26, 41.74s/it, lr=5e-5, step_loss=0.0682]Steps:  31%|███▏      | 123/391 [1:11:45<3:06:26, 41.74s/it, lr=5e-5, step_loss=0.0429]Steps:  31%|███▏      | 123/391 [1:11:55<3:06:26, 41.74s/it, lr=5e-5, step_loss=0.0322]Steps:  31%|███▏      | 123/391 [1:12:05<3:06:26, 41.74s/it, lr=5e-5, step_loss=0.0588]Steps:  31%|███▏      | 123/391 [1:12:16<3:06:26, 41.74s/it, lr=5e-5, step_loss=0.0513]Steps:  32%|███▏      | 124/391 [1:12:26<3:04:38, 41.49s/it, lr=5e-5, step_loss=0.0513]Steps:  32%|███▏      | 124/391 [1:12:26<3:04:38, 41.49s/it, lr=5e-5, step_loss=0.0348]Steps:  32%|███▏      | 124/391 [1:12:37<3:04:38, 41.49s/it, lr=5e-5, step_loss=0.0366]Steps:  32%|███▏      | 124/391 [1:12:48<3:04:38, 41.49s/it, lr=5e-5, step_loss=0.0501]Steps:  32%|███▏      | 124/391 [1:12:58<3:04:38, 41.49s/it, lr=5e-5, step_loss=0.0359]Steps:  32%|███▏      | 125/391 [1:13:10<3:06:51, 42.15s/it, lr=5e-5, step_loss=0.0359]Steps:  32%|███▏      | 125/391 [1:13:10<3:06:51, 42.15s/it, lr=5e-5, step_loss=0.0532]Steps:  32%|███▏      | 125/391 [1:13:23<3:06:51, 42.15s/it, lr=5e-5, step_loss=0.0592]Steps:  32%|███▏      | 125/391 [1:13:33<3:06:51, 42.15s/it, lr=5e-5, step_loss=0.0229]Steps:  32%|███▏      | 125/391 [1:13:43<3:06:51, 42.15s/it, lr=5e-5, step_loss=0.0512]Steps:  32%|███▏      | 126/391 [1:13:56<3:10:46, 43.19s/it, lr=5e-5, step_loss=0.0512]Steps:  32%|███▏      | 126/391 [1:13:56<3:10:46, 43.19s/it, lr=5e-5, step_loss=0.0545]Steps:  32%|███▏      | 126/391 [1:14:07<3:10:46, 43.19s/it, lr=5e-5, step_loss=0.0553]Steps:  32%|███▏      | 126/391 [1:14:18<3:10:46, 43.19s/it, lr=5e-5, step_loss=0.0616]Steps:  32%|███▏      | 126/391 [1:14:29<3:10:46, 43.19s/it, lr=5e-5, step_loss=0.0475]Steps:  32%|███▏      | 127/391 [1:14:40<3:11:12, 43.46s/it, lr=5e-5, step_loss=0.0475]Steps:  32%|███▏      | 127/391 [1:14:40<3:11:12, 43.46s/it, lr=5e-5, step_loss=0.0463]Steps:  32%|███▏      | 127/391 [1:14:52<3:11:12, 43.46s/it, lr=5e-5, step_loss=0.0426]Steps:  32%|███▏      | 127/391 [1:15:00<3:11:12, 43.46s/it, lr=5e-5, step_loss=0.0522]Steps:  32%|███▏      | 127/391 [1:15:08<3:11:12, 43.46s/it, lr=5e-5, step_loss=0.0482]Steps:  33%|███▎      | 128/391 [1:15:18<3:04:17, 42.04s/it, lr=5e-5, step_loss=0.0482]Steps:  33%|███▎      | 128/391 [1:15:18<3:04:17, 42.04s/it, lr=5e-5, step_loss=0.0532]Steps:  33%|███▎      | 128/391 [1:15:29<3:04:17, 42.04s/it, lr=5e-5, step_loss=0.0295]Steps:  33%|███▎      | 128/391 [1:15:40<3:04:17, 42.04s/it, lr=5e-5, step_loss=0.0415]Steps:  33%|███▎      | 128/391 [1:15:49<3:04:17, 42.04s/it, lr=5e-5, step_loss=0.0407]Steps:  33%|███▎      | 129/391 [1:16:00<3:03:20, 41.99s/it, lr=5e-5, step_loss=0.0407]Steps:  33%|███▎      | 129/391 [1:16:00<3:03:20, 41.99s/it, lr=5e-5, step_loss=0.0638]Steps:  33%|███▎      | 129/391 [1:16:12<3:03:20, 41.99s/it, lr=5e-5, step_loss=0.0431]Steps:  33%|███▎      | 129/391 [1:16:23<3:03:20, 41.99s/it, lr=5e-5, step_loss=0.0792]Steps:  33%|███▎      | 129/391 [1:16:34<3:03:20, 41.99s/it, lr=5e-5, step_loss=0.0511]Steps:  33%|███▎      | 130/391 [1:16:47<3:08:51, 43.42s/it, lr=5e-5, step_loss=0.0511]Steps:  33%|███▎      | 130/391 [1:16:47<3:08:51, 43.42s/it, lr=5e-5, step_loss=0.0512]Steps:  33%|███▎      | 130/391 [1:16:59<3:08:51, 43.42s/it, lr=5e-5, step_loss=0.0263]Steps:  33%|███▎      | 130/391 [1:17:10<3:08:51, 43.42s/it, lr=5e-5, step_loss=0.0485]Steps:  33%|███▎      | 130/391 [1:17:21<3:08:51, 43.42s/it, lr=5e-5, step_loss=0.0419]Steps:  34%|███▎      | 131/391 [1:17:30<3:07:52, 43.36s/it, lr=5e-5, step_loss=0.0419]Steps:  34%|███▎      | 131/391 [1:17:30<3:07:52, 43.36s/it, lr=5e-5, step_loss=0.0596]Steps:  34%|███▎      | 131/391 [1:17:40<3:07:52, 43.36s/it, lr=5e-5, step_loss=0.0519]Steps:  34%|███▎      | 131/391 [1:17:48<3:07:52, 43.36s/it, lr=5e-5, step_loss=0.0546]Steps:  34%|███▎      | 131/391 [1:17:56<3:07:52, 43.36s/it, lr=5e-5, step_loss=0.0386]Steps:  34%|███▍      | 132/391 [1:18:05<2:55:41, 40.70s/it, lr=5e-5, step_loss=0.0386]Steps:  34%|███▍      | 132/391 [1:18:05<2:55:41, 40.70s/it, lr=5e-5, step_loss=0.0275]Steps:  34%|███▍      | 132/391 [1:18:12<2:55:41, 40.70s/it, lr=5e-5, step_loss=0.0406]Steps:  34%|███▍      | 132/391 [1:18:20<2:55:41, 40.70s/it, lr=5e-5, step_loss=0.0318]Steps:  34%|███▍      | 132/391 [1:18:30<2:55:41, 40.70s/it, lr=5e-5, step_loss=0.0473]Steps:  34%|███▍      | 133/391 [1:18:40<2:48:22, 39.16s/it, lr=5e-5, step_loss=0.0473]Steps:  34%|███▍      | 133/391 [1:18:40<2:48:22, 39.16s/it, lr=5e-5, step_loss=0.0534]Steps:  34%|███▍      | 133/391 [1:18:51<2:48:22, 39.16s/it, lr=5e-5, step_loss=0.0516]Steps:  34%|███▍      | 133/391 [1:19:02<2:48:22, 39.16s/it, lr=5e-5, step_loss=0.0375]Steps:  34%|███▍      | 133/391 [1:19:13<2:48:22, 39.16s/it, lr=5e-5, step_loss=0.0468]Steps:  34%|███▍      | 134/391 [1:19:24<2:54:05, 40.64s/it, lr=5e-5, step_loss=0.0468]Steps:  34%|███▍      | 134/391 [1:19:24<2:54:05, 40.64s/it, lr=5e-5, step_loss=0.0347]Steps:  34%|███▍      | 134/391 [1:19:34<2:54:05, 40.64s/it, lr=5e-5, step_loss=0.063] Steps:  34%|███▍      | 134/391 [1:19:45<2:54:05, 40.64s/it, lr=5e-5, step_loss=0.0552]Steps:  34%|███▍      | 134/391 [1:19:56<2:54:05, 40.64s/it, lr=5e-5, step_loss=0.0304]Steps:  35%|███▍      | 135/391 [1:20:09<2:58:26, 41.82s/it, lr=5e-5, step_loss=0.0304]Steps:  35%|███▍      | 135/391 [1:20:09<2:58:26, 41.82s/it, lr=5e-5, step_loss=0.0765]Steps:  35%|███▍      | 135/391 [1:20:19<2:58:26, 41.82s/it, lr=5e-5, step_loss=0.0495]Steps:  35%|███▍      | 135/391 [1:20:27<2:58:26, 41.82s/it, lr=5e-5, step_loss=0.0843]Steps:  35%|███▍      | 135/391 [1:20:36<2:58:26, 41.82s/it, lr=5e-5, step_loss=0.0494]Steps:  35%|███▍      | 136/391 [1:20:45<2:50:14, 40.06s/it, lr=5e-5, step_loss=0.0494]Steps:  35%|███▍      | 136/391 [1:20:45<2:50:14, 40.06s/it, lr=5e-5, step_loss=0.0501]Steps:  35%|███▍      | 136/391 [1:20:54<2:50:14, 40.06s/it, lr=5e-5, step_loss=0.0485]Steps:  35%|███▍      | 136/391 [1:21:02<2:50:14, 40.06s/it, lr=5e-5, step_loss=0.0702]Steps:  35%|███▍      | 136/391 [1:21:12<2:50:14, 40.06s/it, lr=5e-5, step_loss=0.0718]Steps:  35%|███▌      | 137/391 [1:21:20<2:42:52, 38.47s/it, lr=5e-5, step_loss=0.0718]Steps:  35%|███▌      | 137/391 [1:21:20<2:42:52, 38.47s/it, lr=5e-5, step_loss=0.0491]Steps:  35%|███▌      | 137/391 [1:21:27<2:42:52, 38.47s/it, lr=5e-5, step_loss=0.038] Steps:  35%|███▌      | 138/391 [1:21:28<2:04:20, 29.49s/it, lr=5e-5, step_loss=0.038]Steps:  35%|███▌      | 138/391 [1:21:28<2:04:20, 29.49s/it, lr=5e-5, step_loss=0.0439]Steps:  35%|███▌      | 138/391 [1:21:50<2:04:20, 29.49s/it, lr=5e-5, step_loss=0.0492]Steps:  35%|███▌      | 138/391 [1:22:00<2:04:20, 29.49s/it, lr=5e-5, step_loss=0.049] Steps:  35%|███▌      | 138/391 [1:22:11<2:04:20, 29.49s/it, lr=5e-5, step_loss=0.0634]Steps:  36%|███▌      | 139/391 [1:22:22<2:33:59, 36.67s/it, lr=5e-5, step_loss=0.0634]Steps:  36%|███▌      | 139/391 [1:22:22<2:33:59, 36.67s/it, lr=5e-5, step_loss=0.0417]Steps:  36%|███▌      | 139/391 [1:22:32<2:33:59, 36.67s/it, lr=5e-5, step_loss=0.0561]Steps:  36%|███▌      | 139/391 [1:22:42<2:33:59, 36.67s/it, lr=5e-5, step_loss=0.0391]Steps:  36%|███▌      | 139/391 [1:22:55<2:33:59, 36.67s/it, lr=5e-5, step_loss=0.0385]Steps:  36%|███▌      | 140/391 [1:23:07<2:43:56, 39.19s/it, lr=5e-5, step_loss=0.0385]Steps:  36%|███▌      | 140/391 [1:23:07<2:43:56, 39.19s/it, lr=5e-5, step_loss=0.039] Steps:  36%|███▌      | 140/391 [1:23:19<2:43:56, 39.19s/it, lr=5e-5, step_loss=0.061]Steps:  36%|███▌      | 140/391 [1:23:29<2:43:56, 39.19s/it, lr=5e-5, step_loss=0.0534]Steps:  36%|███▌      | 140/391 [1:23:40<2:43:56, 39.19s/it, lr=5e-5, step_loss=0.0718]Steps:  36%|███▌      | 141/391 [1:23:50<2:47:53, 40.30s/it, lr=5e-5, step_loss=0.0718]Steps:  36%|███▌      | 141/391 [1:23:50<2:47:53, 40.30s/it, lr=5e-5, step_loss=0.0395]Steps:  36%|███▌      | 141/391 [1:24:00<2:47:53, 40.30s/it, lr=5e-5, step_loss=0.0464]Steps:  36%|███▌      | 141/391 [1:24:10<2:47:53, 40.30s/it, lr=5e-5, step_loss=0.0445]Steps:  36%|███▌      | 141/391 [1:24:21<2:47:53, 40.30s/it, lr=5e-5, step_loss=0.0426]Steps:  36%|███▋      | 142/391 [1:24:32<2:49:56, 40.95s/it, lr=5e-5, step_loss=0.0426]Steps:  36%|███▋      | 142/391 [1:24:32<2:49:56, 40.95s/it, lr=5e-5, step_loss=0.0406]Steps:  36%|███▋      | 142/391 [1:24:45<2:49:56, 40.95s/it, lr=5e-5, step_loss=0.0411]Steps:  36%|███▋      | 142/391 [1:24:57<2:49:56, 40.95s/it, lr=5e-5, step_loss=0.0504]Steps:  36%|███▋      | 142/391 [1:25:07<2:49:56, 40.95s/it, lr=5e-5, step_loss=0.0316]Steps:  37%|███▋      | 143/391 [1:25:19<2:56:06, 42.61s/it, lr=5e-5, step_loss=0.0316]Steps:  37%|███▋      | 143/391 [1:25:19<2:56:06, 42.61s/it, lr=5e-5, step_loss=0.0669]Steps:  37%|███▋      | 143/391 [1:25:31<2:56:06, 42.61s/it, lr=5e-5, step_loss=0.0389]Steps:  37%|███▋      | 143/391 [1:25:41<2:56:06, 42.61s/it, lr=5e-5, step_loss=0.0566]Steps:  37%|███▋      | 143/391 [1:25:52<2:56:06, 42.61s/it, lr=5e-5, step_loss=0.0531]Steps:  37%|███▋      | 144/391 [1:26:04<2:58:39, 43.40s/it, lr=5e-5, step_loss=0.0531]Steps:  37%|███▋      | 144/391 [1:26:04<2:58:39, 43.40s/it, lr=5e-5, step_loss=0.0273]Steps:  37%|███▋      | 144/391 [1:26:13<2:58:39, 43.40s/it, lr=5e-5, step_loss=0.0521]Steps:  37%|███▋      | 144/391 [1:26:22<2:58:39, 43.40s/it, lr=5e-5, step_loss=0.0455]Steps:  37%|███▋      | 144/391 [1:26:29<2:58:39, 43.40s/it, lr=5e-5, step_loss=0.0565]Steps:  37%|███▋      | 145/391 [1:26:38<2:47:08, 40.77s/it, lr=5e-5, step_loss=0.0565]Steps:  37%|███▋      | 145/391 [1:26:38<2:47:08, 40.77s/it, lr=5e-5, step_loss=0.0414]Steps:  37%|███▋      | 145/391 [1:26:50<2:47:08, 40.77s/it, lr=5e-5, step_loss=0.0626]Steps:  37%|███▋      | 145/391 [1:26:57<2:47:08, 40.77s/it, lr=5e-5, step_loss=0.0498]Steps:  37%|███▋      | 145/391 [1:27:06<2:47:08, 40.77s/it, lr=5e-5, step_loss=0.0499]Steps:  37%|███▋      | 146/391 [1:27:15<2:40:58, 39.42s/it, lr=5e-5, step_loss=0.0499]Steps:  37%|███▋      | 146/391 [1:27:15<2:40:58, 39.42s/it, lr=5e-5, step_loss=0.0461]Steps:  37%|███▋      | 146/391 [1:27:24<2:40:58, 39.42s/it, lr=5e-5, step_loss=0.0472]Steps:  37%|███▋      | 146/391 [1:27:32<2:40:58, 39.42s/it, lr=5e-5, step_loss=0.0442]Steps:  37%|███▋      | 146/391 [1:27:41<2:40:58, 39.42s/it, lr=5e-5, step_loss=0.0331]Steps:  38%|███▊      | 147/391 [1:27:50<2:34:37, 38.02s/it, lr=5e-5, step_loss=0.0331]Steps:  38%|███▊      | 147/391 [1:27:50<2:34:37, 38.02s/it, lr=5e-5, step_loss=0.0258]Steps:  38%|███▊      | 147/391 [1:27:57<2:34:37, 38.02s/it, lr=5e-5, step_loss=0.0303]Steps:  38%|███▊      | 147/391 [1:28:05<2:34:37, 38.02s/it, lr=5e-5, step_loss=0.061] Steps:  38%|███▊      | 147/391 [1:28:14<2:34:37, 38.02s/it, lr=5e-5, step_loss=0.0366]Steps:  38%|███▊      | 148/391 [1:28:22<2:27:34, 36.44s/it, lr=5e-5, step_loss=0.0366]Steps:  38%|███▊      | 148/391 [1:28:22<2:27:34, 36.44s/it, lr=5e-5, step_loss=0.0677]Steps:  38%|███▊      | 148/391 [1:28:31<2:27:34, 36.44s/it, lr=5e-5, step_loss=0.0524]Steps:  38%|███▊      | 148/391 [1:28:39<2:27:34, 36.44s/it, lr=5e-5, step_loss=0.0552]Steps:  38%|███▊      | 148/391 [1:28:48<2:27:34, 36.44s/it, lr=5e-5, step_loss=0.0578]Steps:  38%|███▊      | 149/391 [1:28:57<2:24:17, 35.78s/it, lr=5e-5, step_loss=0.0578]Steps:  38%|███▊      | 149/391 [1:28:57<2:24:17, 35.78s/it, lr=5e-5, step_loss=0.0279]Steps:  38%|███▊      | 149/391 [1:29:04<2:24:17, 35.78s/it, lr=5e-5, step_loss=0.063] Steps:  38%|███▊      | 149/391 [1:29:13<2:24:17, 35.78s/it, lr=5e-5, step_loss=0.0723]Steps:  38%|███▊      | 149/391 [1:29:22<2:24:17, 35.78s/it, lr=5e-5, step_loss=0.0519]Steps:  38%|███▊      | 150/391 [1:29:30<2:20:49, 35.06s/it, lr=5e-5, step_loss=0.0519]Steps:  38%|███▊      | 150/391 [1:29:30<2:20:49, 35.06s/it, lr=5e-5, step_loss=0.0371]Steps:  38%|███▊      | 150/391 [1:29:38<2:20:49, 35.06s/it, lr=5e-5, step_loss=0.0359]Steps:  38%|███▊      | 150/391 [1:29:47<2:20:49, 35.06s/it, lr=5e-5, step_loss=0.0585]Steps:  38%|███▊      | 150/391 [1:29:55<2:20:49, 35.06s/it, lr=5e-5, step_loss=0.0389]Steps:  39%|███▊      | 151/391 [1:30:02<2:17:07, 34.28s/it, lr=5e-5, step_loss=0.0389]Steps:  39%|███▊      | 151/391 [1:30:02<2:17:07, 34.28s/it, lr=5e-5, step_loss=0.0691]Steps:  39%|███▊      | 151/391 [1:30:11<2:17:07, 34.28s/it, lr=5e-5, step_loss=0.0634]Steps:  39%|███▊      | 151/391 [1:30:19<2:17:07, 34.28s/it, lr=5e-5, step_loss=0.0315]Steps:  39%|███▊      | 151/391 [1:30:27<2:17:07, 34.28s/it, lr=5e-5, step_loss=0.0472]Steps:  39%|███▉      | 152/391 [1:30:36<2:15:28, 34.01s/it, lr=5e-5, step_loss=0.0472]Steps:  39%|███▉      | 152/391 [1:30:36<2:15:28, 34.01s/it, lr=5e-5, step_loss=0.0463]Steps:  39%|███▉      | 152/391 [1:30:43<2:15:28, 34.01s/it, lr=5e-5, step_loss=0.0379]Steps:  39%|███▉      | 152/391 [1:30:51<2:15:28, 34.01s/it, lr=5e-5, step_loss=0.0423]Steps:  39%|███▉      | 152/391 [1:31:01<2:15:28, 34.01s/it, lr=5e-5, step_loss=0.0513]Steps:  39%|███▉      | 153/391 [1:31:12<2:17:18, 34.61s/it, lr=5e-5, step_loss=0.0513]Steps:  39%|███▉      | 153/391 [1:31:12<2:17:18, 34.61s/it, lr=5e-5, step_loss=0.0462]Steps:  39%|███▉      | 153/391 [1:31:22<2:17:18, 34.61s/it, lr=5e-5, step_loss=0.0639]Steps:  39%|███▉      | 153/391 [1:31:30<2:17:18, 34.61s/it, lr=5e-5, step_loss=0.0671]Steps:  39%|███▉      | 153/391 [1:31:38<2:17:18, 34.61s/it, lr=5e-5, step_loss=0.0365]Steps:  39%|███▉      | 154/391 [1:31:46<2:15:50, 34.39s/it, lr=5e-5, step_loss=0.0365]Steps:  39%|███▉      | 154/391 [1:31:46<2:15:50, 34.39s/it, lr=5e-5, step_loss=0.0615]Steps:  39%|███▉      | 154/391 [1:31:53<2:15:50, 34.39s/it, lr=5e-5, step_loss=0.0286]Steps:  39%|███▉      | 154/391 [1:32:01<2:15:50, 34.39s/it, lr=5e-5, step_loss=0.0542]Steps:  39%|███▉      | 154/391 [1:32:09<2:15:50, 34.39s/it, lr=5e-5, step_loss=0.0791]Steps:  40%|███▉      | 155/391 [1:32:18<2:12:30, 33.69s/it, lr=5e-5, step_loss=0.0791]Steps:  40%|███▉      | 155/391 [1:32:18<2:12:30, 33.69s/it, lr=5e-5, step_loss=0.0489]Steps:  40%|███▉      | 155/391 [1:32:27<2:12:30, 33.69s/it, lr=5e-5, step_loss=0.0489]Steps:  40%|███▉      | 155/391 [1:32:35<2:12:30, 33.69s/it, lr=5e-5, step_loss=0.0566]Steps:  40%|███▉      | 155/391 [1:32:44<2:12:30, 33.69s/it, lr=5e-5, step_loss=0.042] Steps:  40%|███▉      | 156/391 [1:32:53<2:13:31, 34.09s/it, lr=5e-5, step_loss=0.042]Steps:  40%|███▉      | 156/391 [1:32:53<2:13:31, 34.09s/it, lr=5e-5, step_loss=0.0535]Steps:  40%|███▉      | 156/391 [1:33:01<2:13:31, 34.09s/it, lr=5e-5, step_loss=0.0385]Steps:  40%|███▉      | 156/391 [1:33:09<2:13:31, 34.09s/it, lr=5e-5, step_loss=0.0403]Steps:  40%|███▉      | 156/391 [1:33:18<2:13:31, 34.09s/it, lr=5e-5, step_loss=0.0614]Steps:  40%|████      | 157/391 [1:33:25<2:11:00, 33.59s/it, lr=5e-5, step_loss=0.0614]Steps:  40%|████      | 157/391 [1:33:25<2:11:00, 33.59s/it, lr=5e-5, step_loss=0.0829]Steps:  40%|████      | 157/391 [1:33:33<2:11:00, 33.59s/it, lr=5e-5, step_loss=0.0609]Steps:  40%|████      | 157/391 [1:33:41<2:11:00, 33.59s/it, lr=5e-5, step_loss=0.0293]Steps:  40%|████      | 157/391 [1:33:48<2:11:00, 33.59s/it, lr=5e-5, step_loss=0.0446]Steps:  40%|████      | 158/391 [1:33:56<2:07:41, 32.88s/it, lr=5e-5, step_loss=0.0446]Steps:  40%|████      | 158/391 [1:33:56<2:07:41, 32.88s/it, lr=5e-5, step_loss=0.0501]Steps:  40%|████      | 158/391 [1:34:05<2:07:41, 32.88s/it, lr=5e-5, step_loss=0.0383]Steps:  40%|████      | 158/391 [1:34:13<2:07:41, 32.88s/it, lr=5e-5, step_loss=0.0539]Steps:  40%|████      | 158/391 [1:34:21<2:07:41, 32.88s/it, lr=5e-5, step_loss=0.0381]Steps:  41%|████      | 159/391 [1:34:30<2:08:28, 33.22s/it, lr=5e-5, step_loss=0.0381]Steps:  41%|████      | 159/391 [1:34:30<2:08:28, 33.22s/it, lr=5e-5, step_loss=0.0575]Steps:  41%|████      | 159/391 [1:34:39<2:08:28, 33.22s/it, lr=5e-5, step_loss=0.0584]Steps:  41%|████      | 159/391 [1:34:47<2:08:28, 33.22s/it, lr=5e-5, step_loss=0.0491]Steps:  41%|████      | 159/391 [1:34:57<2:08:28, 33.22s/it, lr=5e-5, step_loss=0.0501]Steps:  41%|████      | 160/391 [1:35:06<2:10:44, 33.96s/it, lr=5e-5, step_loss=0.0501]Steps:  41%|████      | 160/391 [1:35:06<2:10:44, 33.96s/it, lr=5e-5, step_loss=0.035] Steps:  41%|████      | 160/391 [1:35:13<2:10:44, 33.96s/it, lr=5e-5, step_loss=0.0393]Steps:  41%|████      | 161/391 [1:35:14<1:40:22, 26.18s/it, lr=5e-5, step_loss=0.0393]Steps:  41%|████      | 161/391 [1:35:14<1:40:22, 26.18s/it, lr=5e-5, step_loss=0.0394]Steps:  41%|████      | 161/391 [1:35:31<1:40:22, 26.18s/it, lr=5e-5, step_loss=0.0437]Steps:  41%|████      | 161/391 [1:35:40<1:40:22, 26.18s/it, lr=5e-5, step_loss=0.0633]Steps:  41%|████      | 161/391 [1:35:49<1:40:22, 26.18s/it, lr=5e-5, step_loss=0.0615]Steps:  41%|████▏     | 162/391 [1:35:57<1:59:34, 31.33s/it, lr=5e-5, step_loss=0.0615]Steps:  41%|████▏     | 162/391 [1:35:57<1:59:34, 31.33s/it, lr=5e-5, step_loss=0.0442]Steps:  41%|████▏     | 162/391 [1:36:05<1:59:34, 31.33s/it, lr=5e-5, step_loss=0.0489]Steps:  41%|████▏     | 162/391 [1:36:13<1:59:34, 31.33s/it, lr=5e-5, step_loss=0.046] Steps:  41%|████▏     | 162/391 [1:36:22<1:59:34, 31.33s/it, lr=5e-5, step_loss=0.062]Steps:  42%|████▏     | 163/391 [1:36:30<1:59:58, 31.57s/it, lr=5e-5, step_loss=0.062]Steps:  42%|████▏     | 163/391 [1:36:30<1:59:58, 31.57s/it, lr=5e-5, step_loss=0.056]Steps:  42%|████▏     | 163/391 [1:36:39<1:59:58, 31.57s/it, lr=5e-5, step_loss=0.0331]Steps:  42%|████▏     | 163/391 [1:36:47<1:59:58, 31.57s/it, lr=5e-5, step_loss=0.0532]Steps:  42%|████▏     | 163/391 [1:36:55<1:59:58, 31.57s/it, lr=5e-5, step_loss=0.0501]Steps:  42%|████▏     | 164/391 [1:37:03<2:01:50, 32.20s/it, lr=5e-5, step_loss=0.0501]Steps:  42%|████▏     | 164/391 [1:37:03<2:01:50, 32.20s/it, lr=5e-5, step_loss=0.0498]Steps:  42%|████▏     | 164/391 [1:37:10<2:01:50, 32.20s/it, lr=5e-5, step_loss=0.05]  Steps:  42%|████▏     | 164/391 [1:37:19<2:01:50, 32.20s/it, lr=5e-5, step_loss=0.0584]Steps:  42%|████▏     | 164/391 [1:37:27<2:01:50, 32.20s/it, lr=5e-5, step_loss=0.058] Steps:  42%|████▏     | 165/391 [1:37:35<2:01:14, 32.19s/it, lr=5e-5, step_loss=0.058]Steps:  42%|████▏     | 165/391 [1:37:35<2:01:14, 32.19s/it, lr=5e-5, step_loss=0.0428]Steps:  42%|████▏     | 165/391 [1:37:43<2:01:14, 32.19s/it, lr=5e-5, step_loss=0.0277]Steps:  42%|████▏     | 165/391 [1:37:51<2:01:14, 32.19s/it, lr=5e-5, step_loss=0.0349]Steps:  42%|████▏     | 165/391 [1:38:00<2:01:14, 32.19s/it, lr=5e-5, step_loss=0.0679]Steps:  42%|████▏     | 166/391 [1:38:08<2:01:40, 32.44s/it, lr=5e-5, step_loss=0.0679]Steps:  42%|████▏     | 166/391 [1:38:08<2:01:40, 32.44s/it, lr=5e-5, step_loss=0.0486]Steps:  42%|████▏     | 166/391 [1:38:17<2:01:40, 32.44s/it, lr=5e-5, step_loss=0.0403]Steps:  42%|████▏     | 166/391 [1:38:26<2:01:40, 32.44s/it, lr=5e-5, step_loss=0.0395]Steps:  42%|████▏     | 166/391 [1:38:34<2:01:40, 32.44s/it, lr=5e-5, step_loss=0.0578]Steps:  43%|████▎     | 167/391 [1:38:42<2:02:05, 32.70s/it, lr=5e-5, step_loss=0.0578]Steps:  43%|████▎     | 167/391 [1:38:42<2:02:05, 32.70s/it, lr=5e-5, step_loss=0.0589]Steps:  43%|████▎     | 167/391 [1:38:50<2:02:05, 32.70s/it, lr=5e-5, step_loss=0.047] Steps:  43%|████▎     | 167/391 [1:38:58<2:02:05, 32.70s/it, lr=5e-5, step_loss=0.0329]Steps:  43%|████▎     | 167/391 [1:39:06<2:02:05, 32.70s/it, lr=5e-5, step_loss=0.0464]Steps:  43%|████▎     | 168/391 [1:39:15<2:01:53, 32.80s/it, lr=5e-5, step_loss=0.0464]Steps:  43%|████▎     | 168/391 [1:39:15<2:01:53, 32.80s/it, lr=5e-5, step_loss=0.0482]Steps:  43%|████▎     | 168/391 [1:39:23<2:01:53, 32.80s/it, lr=5e-5, step_loss=0.0313]Steps:  43%|████▎     | 168/391 [1:39:31<2:01:53, 32.80s/it, lr=5e-5, step_loss=0.052] Steps:  43%|████▎     | 168/391 [1:39:38<2:01:53, 32.80s/it, lr=5e-5, step_loss=0.0516]Steps:  43%|████▎     | 169/391 [1:39:46<1:59:34, 32.32s/it, lr=5e-5, step_loss=0.0516]Steps:  43%|████▎     | 169/391 [1:39:46<1:59:34, 32.32s/it, lr=5e-5, step_loss=0.0491]Steps:  43%|████▎     | 169/391 [1:39:55<1:59:34, 32.32s/it, lr=5e-5, step_loss=0.0502]Steps:  43%|████▎     | 169/391 [1:40:03<1:59:34, 32.32s/it, lr=5e-5, step_loss=0.0448]Steps:  43%|████▎     | 169/391 [1:40:12<1:59:34, 32.32s/it, lr=5e-5, step_loss=0.0464]Steps:  43%|████▎     | 170/391 [1:40:20<2:01:24, 32.96s/it, lr=5e-5, step_loss=0.0464]Steps:  43%|████▎     | 170/391 [1:40:20<2:01:24, 32.96s/it, lr=5e-5, step_loss=0.0504]Steps:  43%|████▎     | 170/391 [1:40:29<2:01:24, 32.96s/it, lr=5e-5, step_loss=0.041] Steps:  43%|████▎     | 170/391 [1:40:36<2:01:24, 32.96s/it, lr=5e-5, step_loss=0.048]Steps:  43%|████▎     | 170/391 [1:40:45<2:01:24, 32.96s/it, lr=5e-5, step_loss=0.0439]Steps:  44%|████▎     | 171/391 [1:40:53<2:00:49, 32.95s/it, lr=5e-5, step_loss=0.0439]Steps:  44%|████▎     | 171/391 [1:40:53<2:00:49, 32.95s/it, lr=5e-5, step_loss=0.0421]Steps:  44%|████▎     | 171/391 [1:41:03<2:00:49, 32.95s/it, lr=5e-5, step_loss=0.0651]Steps:  44%|████▎     | 171/391 [1:41:11<2:00:49, 32.95s/it, lr=5e-5, step_loss=0.0348]Steps:  44%|████▎     | 171/391 [1:41:19<2:00:49, 32.95s/it, lr=5e-5, step_loss=0.0319]Steps:  44%|████▍     | 172/391 [1:41:28<2:02:03, 33.44s/it, lr=5e-5, step_loss=0.0319]Steps:  44%|████▍     | 172/391 [1:41:28<2:02:03, 33.44s/it, lr=5e-5, step_loss=0.0475]Steps:  44%|████▍     | 172/391 [1:41:36<2:02:03, 33.44s/it, lr=5e-5, step_loss=0.0428]Steps:  44%|████▍     | 172/391 [1:41:44<2:02:03, 33.44s/it, lr=5e-5, step_loss=0.0607]Steps:  44%|████▍     | 172/391 [1:41:52<2:02:03, 33.44s/it, lr=5e-5, step_loss=0.0351]Steps:  44%|████▍     | 173/391 [1:42:00<2:00:30, 33.17s/it, lr=5e-5, step_loss=0.0351]Steps:  44%|████▍     | 173/391 [1:42:00<2:00:30, 33.17s/it, lr=5e-5, step_loss=0.0454]Steps:  44%|████▍     | 173/391 [1:42:09<2:00:30, 33.17s/it, lr=5e-5, step_loss=0.0624]Steps:  44%|████▍     | 173/391 [1:42:17<2:00:30, 33.17s/it, lr=5e-5, step_loss=0.0545]Steps:  44%|████▍     | 173/391 [1:42:27<2:00:30, 33.17s/it, lr=5e-5, step_loss=0.0409]Steps:  45%|████▍     | 174/391 [1:42:35<2:01:27, 33.58s/it, lr=5e-5, step_loss=0.0409]Steps:  45%|████▍     | 174/391 [1:42:35<2:01:27, 33.58s/it, lr=5e-5, step_loss=0.0464]Steps:  45%|████▍     | 174/391 [1:42:43<2:01:27, 33.58s/it, lr=5e-5, step_loss=0.052] Steps:  45%|████▍     | 174/391 [1:42:51<2:01:27, 33.58s/it, lr=5e-5, step_loss=0.0487]Steps:  45%|████▍     | 174/391 [1:43:00<2:01:27, 33.58s/it, lr=5e-5, step_loss=0.055] Steps:  45%|████▍     | 175/391 [1:43:07<1:59:25, 33.17s/it, lr=5e-5, step_loss=0.055]Steps:  45%|████▍     | 175/391 [1:43:07<1:59:25, 33.17s/it, lr=5e-5, step_loss=0.0389]Steps:  45%|████▍     | 175/391 [1:43:16<1:59:25, 33.17s/it, lr=5e-5, step_loss=0.041] Steps:  45%|████▍     | 175/391 [1:43:25<1:59:25, 33.17s/it, lr=5e-5, step_loss=0.0398]Steps:  45%|████▍     | 175/391 [1:43:33<1:59:25, 33.17s/it, lr=5e-5, step_loss=0.0383]Steps:  45%|████▌     | 176/391 [1:43:42<2:00:07, 33.52s/it, lr=5e-5, step_loss=0.0383]Steps:  45%|████▌     | 176/391 [1:43:42<2:00:07, 33.52s/it, lr=5e-5, step_loss=0.0358]Steps:  45%|████▌     | 176/391 [1:43:50<2:00:07, 33.52s/it, lr=5e-5, step_loss=0.0379]Steps:  45%|████▌     | 176/391 [1:43:58<2:00:07, 33.52s/it, lr=5e-5, step_loss=0.0396]Steps:  45%|████▌     | 176/391 [1:44:07<2:00:07, 33.52s/it, lr=5e-5, step_loss=0.0388]Steps:  45%|████▌     | 177/391 [1:44:18<2:02:51, 34.45s/it, lr=5e-5, step_loss=0.0388]Steps:  45%|████▌     | 177/391 [1:44:18<2:02:51, 34.45s/it, lr=5e-5, step_loss=0.0534]Steps:  45%|████▌     | 177/391 [1:44:28<2:02:51, 34.45s/it, lr=5e-5, step_loss=0.0382]Steps:  45%|████▌     | 177/391 [1:44:40<2:02:51, 34.45s/it, lr=5e-5, step_loss=0.0479]Steps:  45%|████▌     | 177/391 [1:44:50<2:02:51, 34.45s/it, lr=5e-5, step_loss=0.0472]Steps:  46%|████▌     | 178/391 [1:45:00<2:10:09, 36.67s/it, lr=5e-5, step_loss=0.0472]Steps:  46%|████▌     | 178/391 [1:45:00<2:10:09, 36.67s/it, lr=5e-5, step_loss=0.0364]Steps:  46%|████▌     | 178/391 [1:45:10<2:10:09, 36.67s/it, lr=5e-5, step_loss=0.0459]Steps:  46%|████▌     | 178/391 [1:45:21<2:10:09, 36.67s/it, lr=5e-5, step_loss=0.0536]Steps:  46%|████▌     | 178/391 [1:45:29<2:10:09, 36.67s/it, lr=5e-5, step_loss=0.0399]Steps:  46%|████▌     | 179/391 [1:45:37<2:10:04, 36.81s/it, lr=5e-5, step_loss=0.0399]Steps:  46%|████▌     | 179/391 [1:45:37<2:10:04, 36.81s/it, lr=5e-5, step_loss=0.055] Steps:  46%|████▌     | 179/391 [1:45:46<2:10:04, 36.81s/it, lr=5e-5, step_loss=0.0501]Steps:  46%|████▌     | 179/391 [1:45:55<2:10:04, 36.81s/it, lr=5e-5, step_loss=0.0577]Steps:  46%|████▌     | 179/391 [1:46:04<2:10:04, 36.81s/it, lr=5e-5, step_loss=0.0266]Steps:  46%|████▌     | 180/391 [1:46:13<2:08:21, 36.50s/it, lr=5e-5, step_loss=0.0266]Steps:  46%|████▌     | 180/391 [1:46:13<2:08:21, 36.50s/it, lr=5e-5, step_loss=0.0354]Steps:  46%|████▌     | 180/391 [1:46:22<2:08:21, 36.50s/it, lr=5e-5, step_loss=0.0447]Steps:  46%|████▌     | 180/391 [1:46:32<2:08:21, 36.50s/it, lr=5e-5, step_loss=0.0467]Steps:  46%|████▌     | 180/391 [1:46:40<2:08:21, 36.50s/it, lr=5e-5, step_loss=0.047] Steps:  46%|████▋     | 181/391 [1:46:49<2:07:43, 36.50s/it, lr=5e-5, step_loss=0.047]Steps:  46%|████▋     | 181/391 [1:46:49<2:07:43, 36.50s/it, lr=5e-5, step_loss=0.036]Steps:  46%|████▋     | 181/391 [1:46:57<2:07:43, 36.50s/it, lr=5e-5, step_loss=0.0673]Steps:  46%|████▋     | 181/391 [1:47:06<2:07:43, 36.50s/it, lr=5e-5, step_loss=0.0437]Steps:  46%|████▋     | 181/391 [1:47:15<2:07:43, 36.50s/it, lr=5e-5, step_loss=0.0403]Steps:  47%|████▋     | 182/391 [1:47:23<2:04:09, 35.64s/it, lr=5e-5, step_loss=0.0403]Steps:  47%|████▋     | 182/391 [1:47:23<2:04:09, 35.64s/it, lr=5e-5, step_loss=0.0333]Steps:  47%|████▋     | 182/391 [1:47:31<2:04:09, 35.64s/it, lr=5e-5, step_loss=0.0307]Steps:  47%|████▋     | 182/391 [1:47:39<2:04:09, 35.64s/it, lr=5e-5, step_loss=0.0577]Steps:  47%|████▋     | 182/391 [1:47:48<2:04:09, 35.64s/it, lr=5e-5, step_loss=0.0457]Steps:  47%|████▋     | 183/391 [1:47:56<2:00:57, 34.89s/it, lr=5e-5, step_loss=0.0457]Steps:  47%|████▋     | 183/391 [1:47:56<2:00:57, 34.89s/it, lr=5e-5, step_loss=0.0401]Steps:  47%|████▋     | 183/391 [1:48:04<2:00:57, 34.89s/it, lr=5e-5, step_loss=0.037] Steps:  47%|████▋     | 184/391 [1:48:05<1:33:17, 27.04s/it, lr=5e-5, step_loss=0.037]Steps:  47%|████▋     | 184/391 [1:48:05<1:33:17, 27.04s/it, lr=5e-5, step_loss=0.0589]Steps:  47%|████▋     | 184/391 [1:48:20<1:33:17, 27.04s/it, lr=5e-5, step_loss=0.0417]Steps:  47%|████▋     | 184/391 [1:48:29<1:33:17, 27.04s/it, lr=5e-5, step_loss=0.0345]Steps:  47%|████▋     | 184/391 [1:48:38<1:33:17, 27.04s/it, lr=5e-5, step_loss=0.0426]Steps:  47%|████▋     | 185/391 [1:48:46<1:46:53, 31.13s/it, lr=5e-5, step_loss=0.0426]Steps:  47%|████▋     | 185/391 [1:48:46<1:46:53, 31.13s/it, lr=5e-5, step_loss=0.0382]Steps:  47%|████▋     | 185/391 [1:48:53<1:46:53, 31.13s/it, lr=5e-5, step_loss=0.0842]Steps:  47%|████▋     | 185/391 [1:49:02<1:46:53, 31.13s/it, lr=5e-5, step_loss=0.0528]Steps:  47%|████▋     | 185/391 [1:49:11<1:46:53, 31.13s/it, lr=5e-5, step_loss=0.0505]Steps:  48%|████▊     | 186/391 [1:49:20<1:49:20, 32.00s/it, lr=5e-5, step_loss=0.0505]Steps:  48%|████▊     | 186/391 [1:49:20<1:49:20, 32.00s/it, lr=5e-5, step_loss=0.0422]Steps:  48%|████▊     | 186/391 [1:49:29<1:49:20, 32.00s/it, lr=5e-5, step_loss=0.0472]Steps:  48%|████▊     | 186/391 [1:49:36<1:49:20, 32.00s/it, lr=5e-5, step_loss=0.0469]Steps:  48%|████▊     | 186/391 [1:49:45<1:49:20, 32.00s/it, lr=5e-5, step_loss=0.0645]Steps:  48%|████▊     | 187/391 [1:49:53<1:50:37, 32.54s/it, lr=5e-5, step_loss=0.0645]Steps:  48%|████▊     | 187/391 [1:49:53<1:50:37, 32.54s/it, lr=5e-5, step_loss=0.0413]Steps:  48%|████▊     | 187/391 [1:50:03<1:50:37, 32.54s/it, lr=5e-5, step_loss=0.0649]Steps:  48%|████▊     | 187/391 [1:50:11<1:50:37, 32.54s/it, lr=5e-5, step_loss=0.0483]Steps:  48%|████▊     | 187/391 [1:50:20<1:50:37, 32.54s/it, lr=5e-5, step_loss=0.0548]Steps:  48%|████▊     | 188/391 [1:50:28<1:51:49, 33.05s/it, lr=5e-5, step_loss=0.0548]Steps:  48%|████▊     | 188/391 [1:50:28<1:51:49, 33.05s/it, lr=5e-5, step_loss=0.0531]Steps:  48%|████▊     | 188/391 [1:50:36<1:51:49, 33.05s/it, lr=5e-5, step_loss=0.0363]Steps:  48%|████▊     | 188/391 [1:50:44<1:51:49, 33.05s/it, lr=5e-5, step_loss=0.0419]Steps:  48%|████▊     | 188/391 [1:50:52<1:51:49, 33.05s/it, lr=5e-5, step_loss=0.0569]Steps:  48%|████▊     | 189/391 [1:51:00<1:50:56, 32.96s/it, lr=5e-5, step_loss=0.0569]Steps:  48%|████▊     | 189/391 [1:51:00<1:50:56, 32.96s/it, lr=5e-5, step_loss=0.0628]Steps:  48%|████▊     | 189/391 [1:51:09<1:50:56, 32.96s/it, lr=5e-5, step_loss=0.0457]Steps:  48%|████▊     | 189/391 [1:51:20<1:50:56, 32.96s/it, lr=5e-5, step_loss=0.0457]Steps:  48%|████▊     | 189/391 [1:51:31<1:50:56, 32.96s/it, lr=5e-5, step_loss=0.0429]Steps:  49%|████▊     | 190/391 [1:51:43<1:59:39, 35.72s/it, lr=5e-5, step_loss=0.0429]Steps:  49%|████▊     | 190/391 [1:51:43<1:59:39, 35.72s/it, lr=5e-5, step_loss=0.0452]Steps:  49%|████▊     | 190/391 [1:51:54<1:59:39, 35.72s/it, lr=5e-5, step_loss=0.0482]Steps:  49%|████▊     | 190/391 [1:52:05<1:59:39, 35.72s/it, lr=5e-5, step_loss=0.0349]Steps:  49%|████▊     | 190/391 [1:52:16<1:59:39, 35.72s/it, lr=5e-5, step_loss=0.0435]Steps:  49%|████▉     | 191/391 [1:52:29<2:09:30, 38.85s/it, lr=5e-5, step_loss=0.0435]Steps:  49%|████▉     | 191/391 [1:52:29<2:09:30, 38.85s/it, lr=5e-5, step_loss=0.0417]Steps:  49%|████▉     | 191/391 [1:52:41<2:09:30, 38.85s/it, lr=5e-5, step_loss=0.0358]Steps:  49%|████▉     | 191/391 [1:52:54<2:09:30, 38.85s/it, lr=5e-5, step_loss=0.0635]Steps:  49%|████▉     | 191/391 [1:53:05<2:09:30, 38.85s/it, lr=5e-5, step_loss=0.0395]Steps:  49%|████▉     | 192/391 [1:53:16<2:17:08, 41.35s/it, lr=5e-5, step_loss=0.0395]Steps:  49%|████▉     | 192/391 [1:53:16<2:17:08, 41.35s/it, lr=5e-5, step_loss=0.0769]Steps:  49%|████▉     | 192/391 [1:53:26<2:17:08, 41.35s/it, lr=5e-5, step_loss=0.03]  Steps:  49%|████▉     | 192/391 [1:53:37<2:17:08, 41.35s/it, lr=5e-5, step_loss=0.0825]Steps:  49%|████▉     | 192/391 [1:53:48<2:17:08, 41.35s/it, lr=5e-5, step_loss=0.0628]Steps:  49%|████▉     | 193/391 [1:53:58<2:17:28, 41.66s/it, lr=5e-5, step_loss=0.0628]Steps:  49%|████▉     | 193/391 [1:53:58<2:17:28, 41.66s/it, lr=5e-5, step_loss=0.0587]Steps:  49%|████▉     | 193/391 [1:54:08<2:17:28, 41.66s/it, lr=5e-5, step_loss=0.051] Steps:  49%|████▉     | 193/391 [1:54:19<2:17:28, 41.66s/it, lr=5e-5, step_loss=0.0477]Steps:  49%|████▉     | 193/391 [1:54:30<2:17:28, 41.66s/it, lr=5e-5, step_loss=0.0423]Steps:  50%|████▉     | 194/391 [1:54:41<2:17:42, 41.94s/it, lr=5e-5, step_loss=0.0423]Steps:  50%|████▉     | 194/391 [1:54:41<2:17:42, 41.94s/it, lr=5e-5, step_loss=0.056] Steps:  50%|████▉     | 194/391 [1:54:51<2:17:42, 41.94s/it, lr=5e-5, step_loss=0.0545]Steps:  50%|████▉     | 194/391 [1:55:01<2:17:42, 41.94s/it, lr=5e-5, step_loss=0.0477]Steps:  50%|████▉     | 194/391 [1:55:14<2:17:42, 41.94s/it, lr=5e-5, step_loss=0.0351]Steps:  50%|████▉     | 195/391 [1:55:24<2:17:43, 42.16s/it, lr=5e-5, step_loss=0.0351]Steps:  50%|████▉     | 195/391 [1:55:24<2:17:43, 42.16s/it, lr=5e-5, step_loss=0.0468]Steps:  50%|████▉     | 195/391 [1:55:33<2:17:43, 42.16s/it, lr=5e-5, step_loss=0.0502]Steps:  50%|████▉     | 195/391 [1:55:42<2:17:43, 42.16s/it, lr=5e-5, step_loss=0.0508]Steps:  50%|████▉     | 195/391 [1:55:52<2:17:43, 42.16s/it, lr=5e-5, step_loss=0.0517]Steps:  50%|█████     | 196/391 [1:56:03<2:14:44, 41.46s/it, lr=5e-5, step_loss=0.0517]Steps:  50%|█████     | 196/391 [1:56:03<2:14:44, 41.46s/it, lr=5e-5, step_loss=0.0487]Steps:  50%|█████     | 196/391 [1:56:15<2:14:44, 41.46s/it, lr=5e-5, step_loss=0.0592]Steps:  50%|█████     | 196/391 [1:56:22<2:14:44, 41.46s/it, lr=5e-5, step_loss=0.0566]Steps:  50%|█████     | 196/391 [1:56:31<2:14:44, 41.46s/it, lr=5e-5, step_loss=0.0385]Steps:  50%|█████     | 197/391 [1:56:40<2:09:03, 39.91s/it, lr=5e-5, step_loss=0.0385]Steps:  50%|█████     | 197/391 [1:56:40<2:09:03, 39.91s/it, lr=5e-5, step_loss=0.0716]Steps:  50%|█████     | 197/391 [1:56:49<2:09:03, 39.91s/it, lr=5e-5, step_loss=0.0454]Steps:  50%|█████     | 197/391 [1:56:57<2:09:03, 39.91s/it, lr=5e-5, step_loss=0.0469]Steps:  50%|█████     | 197/391 [1:57:05<2:09:03, 39.91s/it, lr=5e-5, step_loss=0.0396]Steps:  51%|█████     | 198/391 [1:57:13<2:02:25, 38.06s/it, lr=5e-5, step_loss=0.0396]Steps:  51%|█████     | 198/391 [1:57:13<2:02:25, 38.06s/it, lr=5e-5, step_loss=0.0477]Steps:  51%|█████     | 198/391 [1:57:22<2:02:25, 38.06s/it, lr=5e-5, step_loss=0.04]  Steps:  51%|█████     | 198/391 [1:57:29<2:02:25, 38.06s/it, lr=5e-5, step_loss=0.0596]Steps:  51%|█████     | 198/391 [1:57:37<2:02:25, 38.06s/it, lr=5e-5, step_loss=0.0444]Steps:  51%|█████     | 199/391 [1:57:44<1:54:40, 35.83s/it, lr=5e-5, step_loss=0.0444]Steps:  51%|█████     | 199/391 [1:57:44<1:54:40, 35.83s/it, lr=5e-5, step_loss=0.0483]Steps:  51%|█████     | 199/391 [1:57:52<1:54:40, 35.83s/it, lr=5e-5, step_loss=0.0563]Steps:  51%|█████     | 199/391 [1:58:01<1:54:40, 35.83s/it, lr=5e-5, step_loss=0.0506]Steps:  51%|█████     | 199/391 [1:58:10<1:54:40, 35.83s/it, lr=5e-5, step_loss=0.0538]Steps:  51%|█████     | 200/391 [1:58:19<1:52:45, 35.42s/it, lr=5e-5, step_loss=0.0538]06/08/2025 11:26:55 - INFO - __main__ - 1 checkpoints already exist, removing 1 checkpoints
06/08/2025 11:26:55 - INFO - __main__ - removing checkpoints: checkpoint-100
06/08/2025 11:26:55 - INFO - accelerate.accelerator - Saving current state to finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-200
Configuration saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-200/unet_ema/config.json
Model weights saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-200/unet_ema/diffusion_pytorch_model.safetensors
Configuration saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-200/unet/config.json
Model weights saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-200/unet/diffusion_pytorch_model.safetensors
06/08/2025 11:27:18 - INFO - accelerate.checkpointing - Optimizer state saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-200/optimizer.bin
06/08/2025 11:27:18 - INFO - accelerate.checkpointing - Scheduler state saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-200/scheduler.bin
06/08/2025 11:27:18 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-200/sampler.bin
06/08/2025 11:27:18 - INFO - accelerate.checkpointing - Gradient scaler state saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-200/scaler.pt
06/08/2025 11:27:18 - INFO - accelerate.checkpointing - Random states saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-200/random_states_0.pkl
06/08/2025 11:27:18 - INFO - __main__ - Saved state to finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-200
Steps:  51%|█████     | 200/391 [1:58:42<1:52:45, 35.42s/it, lr=5e-5, step_loss=0.0378]Steps:  51%|█████     | 200/391 [1:58:50<1:52:45, 35.42s/it, lr=5e-5, step_loss=0.0253]Steps:  51%|█████     | 200/391 [1:58:58<1:52:45, 35.42s/it, lr=5e-5, step_loss=0.0526]Steps:  51%|█████     | 200/391 [1:59:06<1:52:45, 35.42s/it, lr=5e-5, step_loss=0.0367]Steps:  51%|█████▏    | 201/391 [1:59:15<2:12:11, 41.75s/it, lr=5e-5, step_loss=0.0367]Steps:  51%|█████▏    | 201/391 [1:59:15<2:12:11, 41.75s/it, lr=5e-5, step_loss=0.0514]Steps:  51%|█████▏    | 201/391 [1:59:24<2:12:11, 41.75s/it, lr=5e-5, step_loss=0.0524]Steps:  51%|█████▏    | 201/391 [1:59:33<2:12:11, 41.75s/it, lr=5e-5, step_loss=0.0288]Steps:  51%|█████▏    | 201/391 [1:59:41<2:12:11, 41.75s/it, lr=5e-5, step_loss=0.0376]Steps:  52%|█████▏    | 202/391 [1:59:48<2:03:31, 39.22s/it, lr=5e-5, step_loss=0.0376]Steps:  52%|█████▏    | 202/391 [1:59:48<2:03:31, 39.22s/it, lr=5e-5, step_loss=0.0522]Steps:  52%|█████▏    | 202/391 [1:59:57<2:03:31, 39.22s/it, lr=5e-5, step_loss=0.0435]Steps:  52%|█████▏    | 202/391 [2:00:06<2:03:31, 39.22s/it, lr=5e-5, step_loss=0.0422]Steps:  52%|█████▏    | 202/391 [2:00:14<2:03:31, 39.22s/it, lr=5e-5, step_loss=0.031] Steps:  52%|█████▏    | 203/391 [2:00:23<1:58:39, 37.87s/it, lr=5e-5, step_loss=0.031]Steps:  52%|█████▏    | 203/391 [2:00:23<1:58:39, 37.87s/it, lr=5e-5, step_loss=0.0492]Steps:  52%|█████▏    | 203/391 [2:00:32<1:58:39, 37.87s/it, lr=5e-5, step_loss=0.0334]Steps:  52%|█████▏    | 203/391 [2:00:40<1:58:39, 37.87s/it, lr=5e-5, step_loss=0.0421]Steps:  52%|█████▏    | 203/391 [2:00:47<1:58:39, 37.87s/it, lr=5e-5, step_loss=0.0373]Steps:  52%|█████▏    | 204/391 [2:00:55<1:52:52, 36.22s/it, lr=5e-5, step_loss=0.0373]Steps:  52%|█████▏    | 204/391 [2:00:55<1:52:52, 36.22s/it, lr=5e-5, step_loss=0.0295]Steps:  52%|█████▏    | 204/391 [2:01:04<1:52:52, 36.22s/it, lr=5e-5, step_loss=0.0508]Steps:  52%|█████▏    | 204/391 [2:01:11<1:52:52, 36.22s/it, lr=5e-5, step_loss=0.0521]Steps:  52%|█████▏    | 204/391 [2:01:20<1:52:52, 36.22s/it, lr=5e-5, step_loss=0.0555]Steps:  52%|█████▏    | 205/391 [2:01:29<1:49:41, 35.38s/it, lr=5e-5, step_loss=0.0555]Steps:  52%|█████▏    | 205/391 [2:01:29<1:49:41, 35.38s/it, lr=5e-5, step_loss=0.0371]Steps:  52%|█████▏    | 205/391 [2:01:37<1:49:41, 35.38s/it, lr=5e-5, step_loss=0.0467]Steps:  52%|█████▏    | 205/391 [2:01:45<1:49:41, 35.38s/it, lr=5e-5, step_loss=0.0476]Steps:  52%|█████▏    | 205/391 [2:01:53<1:49:41, 35.38s/it, lr=5e-5, step_loss=0.0373]Steps:  53%|█████▎    | 206/391 [2:02:02<1:47:19, 34.81s/it, lr=5e-5, step_loss=0.0373]Steps:  53%|█████▎    | 206/391 [2:02:02<1:47:19, 34.81s/it, lr=5e-5, step_loss=0.0456]Steps:  53%|█████▎    | 206/391 [2:02:10<1:47:19, 34.81s/it, lr=5e-5, step_loss=0.0731]Steps:  53%|█████▎    | 207/391 [2:02:11<1:22:41, 26.96s/it, lr=5e-5, step_loss=0.0731]Steps:  53%|█████▎    | 207/391 [2:02:11<1:22:41, 26.96s/it, lr=5e-5, step_loss=0.0505]Steps:  53%|█████▎    | 207/391 [2:02:32<1:22:41, 26.96s/it, lr=5e-5, step_loss=0.0468]Steps:  53%|█████▎    | 207/391 [2:02:44<1:22:41, 26.96s/it, lr=5e-5, step_loss=0.0235]Steps:  53%|█████▎    | 207/391 [2:02:55<1:22:41, 26.96s/it, lr=5e-5, step_loss=0.0404]Steps:  53%|█████▎    | 208/391 [2:03:05<1:47:19, 35.19s/it, lr=5e-5, step_loss=0.0404]Steps:  53%|█████▎    | 208/391 [2:03:05<1:47:19, 35.19s/it, lr=5e-5, step_loss=0.0519]Steps:  53%|█████▎    | 208/391 [2:03:17<1:47:19, 35.19s/it, lr=5e-5, step_loss=0.0461]Steps:  53%|█████▎    | 208/391 [2:03:28<1:47:19, 35.19s/it, lr=5e-5, step_loss=0.0351]Steps:  53%|█████▎    | 208/391 [2:03:38<1:47:19, 35.19s/it, lr=5e-5, step_loss=0.032] Steps:  53%|█████▎    | 209/391 [2:03:48<1:53:55, 37.56s/it, lr=5e-5, step_loss=0.032]Steps:  53%|█████▎    | 209/391 [2:03:48<1:53:55, 37.56s/it, lr=5e-5, step_loss=0.0354]Steps:  53%|█████▎    | 209/391 [2:04:00<1:53:55, 37.56s/it, lr=5e-5, step_loss=0.0381]Steps:  53%|█████▎    | 209/391 [2:04:08<1:53:55, 37.56s/it, lr=5e-5, step_loss=0.0529]Steps:  53%|█████▎    | 209/391 [2:04:17<1:53:55, 37.56s/it, lr=5e-5, step_loss=0.0394]Steps:  54%|█████▎    | 210/391 [2:04:25<1:52:40, 37.35s/it, lr=5e-5, step_loss=0.0394]Steps:  54%|█████▎    | 210/391 [2:04:25<1:52:40, 37.35s/it, lr=5e-5, step_loss=0.0573]Steps:  54%|█████▎    | 210/391 [2:04:34<1:52:40, 37.35s/it, lr=5e-5, step_loss=0.0471]Steps:  54%|█████▎    | 210/391 [2:04:42<1:52:40, 37.35s/it, lr=5e-5, step_loss=0.0428]Steps:  54%|█████▎    | 210/391 [2:04:51<1:52:40, 37.35s/it, lr=5e-5, step_loss=0.0444]Steps:  54%|█████▍    | 211/391 [2:05:00<1:49:23, 36.46s/it, lr=5e-5, step_loss=0.0444]Steps:  54%|█████▍    | 211/391 [2:05:00<1:49:23, 36.46s/it, lr=5e-5, step_loss=0.043] Steps:  54%|█████▍    | 211/391 [2:05:08<1:49:23, 36.46s/it, lr=5e-5, step_loss=0.0408]Steps:  54%|█████▍    | 211/391 [2:05:17<1:49:23, 36.46s/it, lr=5e-5, step_loss=0.0477]Steps:  54%|█████▍    | 211/391 [2:05:26<1:49:23, 36.46s/it, lr=5e-5, step_loss=0.0446]Steps:  54%|█████▍    | 212/391 [2:05:35<1:47:24, 36.00s/it, lr=5e-5, step_loss=0.0446]Steps:  54%|█████▍    | 212/391 [2:05:35<1:47:24, 36.00s/it, lr=5e-5, step_loss=0.0419]Steps:  54%|█████▍    | 212/391 [2:05:43<1:47:24, 36.00s/it, lr=5e-5, step_loss=0.0592]Steps:  54%|█████▍    | 212/391 [2:05:51<1:47:24, 36.00s/it, lr=5e-5, step_loss=0.0395]Steps:  54%|█████▍    | 212/391 [2:05:59<1:47:24, 36.00s/it, lr=5e-5, step_loss=0.0597]Steps:  54%|█████▍    | 213/391 [2:06:07<1:43:22, 34.84s/it, lr=5e-5, step_loss=0.0597]Steps:  54%|█████▍    | 213/391 [2:06:07<1:43:22, 34.84s/it, lr=5e-5, step_loss=0.069] Steps:  54%|█████▍    | 213/391 [2:06:15<1:43:22, 34.84s/it, lr=5e-5, step_loss=0.0477]Steps:  54%|█████▍    | 213/391 [2:06:22<1:43:22, 34.84s/it, lr=5e-5, step_loss=0.0596]Steps:  54%|█████▍    | 213/391 [2:06:30<1:43:22, 34.84s/it, lr=5e-5, step_loss=0.0404]Steps:  55%|█████▍    | 214/391 [2:06:38<1:39:17, 33.66s/it, lr=5e-5, step_loss=0.0404]Steps:  55%|█████▍    | 214/391 [2:06:38<1:39:17, 33.66s/it, lr=5e-5, step_loss=0.0367]Steps:  55%|█████▍    | 214/391 [2:06:46<1:39:17, 33.66s/it, lr=5e-5, step_loss=0.0541]Steps:  55%|█████▍    | 214/391 [2:06:54<1:39:17, 33.66s/it, lr=5e-5, step_loss=0.0549]Steps:  55%|█████▍    | 214/391 [2:07:01<1:39:17, 33.66s/it, lr=5e-5, step_loss=0.0604]Steps:  55%|█████▍    | 215/391 [2:07:09<1:36:18, 32.83s/it, lr=5e-5, step_loss=0.0604]Steps:  55%|█████▍    | 215/391 [2:07:09<1:36:18, 32.83s/it, lr=5e-5, step_loss=0.0422]Steps:  55%|█████▍    | 215/391 [2:07:17<1:36:18, 32.83s/it, lr=5e-5, step_loss=0.0423]Steps:  55%|█████▍    | 215/391 [2:07:25<1:36:18, 32.83s/it, lr=5e-5, step_loss=0.0355]Steps:  55%|█████▍    | 215/391 [2:07:34<1:36:18, 32.83s/it, lr=5e-5, step_loss=0.0352]Steps:  55%|█████▌    | 216/391 [2:07:42<1:36:20, 33.03s/it, lr=5e-5, step_loss=0.0352]Steps:  55%|█████▌    | 216/391 [2:07:42<1:36:20, 33.03s/it, lr=5e-5, step_loss=0.0501]Steps:  55%|█████▌    | 216/391 [2:07:50<1:36:20, 33.03s/it, lr=5e-5, step_loss=0.0415]Steps:  55%|█████▌    | 216/391 [2:07:59<1:36:20, 33.03s/it, lr=5e-5, step_loss=0.0492]Steps:  55%|█████▌    | 216/391 [2:08:07<1:36:20, 33.03s/it, lr=5e-5, step_loss=0.033] Steps:  55%|█████▌    | 217/391 [2:08:16<1:36:21, 33.22s/it, lr=5e-5, step_loss=0.033]Steps:  55%|█████▌    | 217/391 [2:08:16<1:36:21, 33.22s/it, lr=5e-5, step_loss=0.0475]Steps:  55%|█████▌    | 217/391 [2:08:24<1:36:21, 33.22s/it, lr=5e-5, step_loss=0.0357]Steps:  55%|█████▌    | 217/391 [2:08:31<1:36:21, 33.22s/it, lr=5e-5, step_loss=0.0641]Steps:  55%|█████▌    | 217/391 [2:08:40<1:36:21, 33.22s/it, lr=5e-5, step_loss=0.0568]Steps:  56%|█████▌    | 218/391 [2:08:48<1:35:06, 32.98s/it, lr=5e-5, step_loss=0.0568]Steps:  56%|█████▌    | 218/391 [2:08:48<1:35:06, 32.98s/it, lr=5e-5, step_loss=0.049] Steps:  56%|█████▌    | 218/391 [2:08:58<1:35:06, 32.98s/it, lr=5e-5, step_loss=0.054]Steps:  56%|█████▌    | 218/391 [2:09:05<1:35:06, 32.98s/it, lr=5e-5, step_loss=0.0515]Steps:  56%|█████▌    | 218/391 [2:09:13<1:35:06, 32.98s/it, lr=5e-5, step_loss=0.0317]Steps:  56%|█████▌    | 219/391 [2:09:22<1:35:06, 33.17s/it, lr=5e-5, step_loss=0.0317]Steps:  56%|█████▌    | 219/391 [2:09:22<1:35:06, 33.17s/it, lr=5e-5, step_loss=0.0599]Steps:  56%|█████▌    | 219/391 [2:09:30<1:35:06, 33.17s/it, lr=5e-5, step_loss=0.0607]Steps:  56%|█████▌    | 219/391 [2:09:38<1:35:06, 33.17s/it, lr=5e-5, step_loss=0.0327]Steps:  56%|█████▌    | 219/391 [2:09:47<1:35:06, 33.17s/it, lr=5e-5, step_loss=0.0483]Steps:  56%|█████▋    | 220/391 [2:09:54<1:33:20, 32.75s/it, lr=5e-5, step_loss=0.0483]Steps:  56%|█████▋    | 220/391 [2:09:54<1:33:20, 32.75s/it, lr=5e-5, step_loss=0.0456]Steps:  56%|█████▋    | 220/391 [2:10:03<1:33:20, 32.75s/it, lr=5e-5, step_loss=0.0396]Steps:  56%|█████▋    | 220/391 [2:10:11<1:33:20, 32.75s/it, lr=5e-5, step_loss=0.0438]Steps:  56%|█████▋    | 220/391 [2:10:20<1:33:20, 32.75s/it, lr=5e-5, step_loss=0.041] Steps:  57%|█████▋    | 221/391 [2:10:28<1:34:27, 33.34s/it, lr=5e-5, step_loss=0.041]Steps:  57%|█████▋    | 221/391 [2:10:28<1:34:27, 33.34s/it, lr=5e-5, step_loss=0.0301]Steps:  57%|█████▋    | 221/391 [2:10:37<1:34:27, 33.34s/it, lr=5e-5, step_loss=0.0594]Steps:  57%|█████▋    | 221/391 [2:10:45<1:34:27, 33.34s/it, lr=5e-5, step_loss=0.0612]Steps:  57%|█████▋    | 221/391 [2:10:54<1:34:27, 33.34s/it, lr=5e-5, step_loss=0.0444]Steps:  57%|█████▋    | 222/391 [2:11:02<1:34:02, 33.39s/it, lr=5e-5, step_loss=0.0444]Steps:  57%|█████▋    | 222/391 [2:11:02<1:34:02, 33.39s/it, lr=5e-5, step_loss=0.0519]Steps:  57%|█████▋    | 222/391 [2:11:11<1:34:02, 33.39s/it, lr=5e-5, step_loss=0.0325]Steps:  57%|█████▋    | 222/391 [2:11:17<1:34:02, 33.39s/it, lr=5e-5, step_loss=0.0543]Steps:  57%|█████▋    | 222/391 [2:11:26<1:34:02, 33.39s/it, lr=5e-5, step_loss=0.0518]Steps:  57%|█████▋    | 223/391 [2:11:34<1:32:49, 33.15s/it, lr=5e-5, step_loss=0.0518]Steps:  57%|█████▋    | 223/391 [2:11:34<1:32:49, 33.15s/it, lr=5e-5, step_loss=0.0493]Steps:  57%|█████▋    | 223/391 [2:11:44<1:32:49, 33.15s/it, lr=5e-5, step_loss=0.0494]Steps:  57%|█████▋    | 223/391 [2:11:53<1:32:49, 33.15s/it, lr=5e-5, step_loss=0.0399]Steps:  57%|█████▋    | 223/391 [2:12:02<1:32:49, 33.15s/it, lr=5e-5, step_loss=0.0407]Steps:  57%|█████▋    | 224/391 [2:12:10<1:34:01, 33.78s/it, lr=5e-5, step_loss=0.0407]Steps:  57%|█████▋    | 224/391 [2:12:10<1:34:01, 33.78s/it, lr=5e-5, step_loss=0.0544]Steps:  57%|█████▋    | 224/391 [2:12:18<1:34:01, 33.78s/it, lr=5e-5, step_loss=0.0546]Steps:  57%|█████▋    | 224/391 [2:12:25<1:34:01, 33.78s/it, lr=5e-5, step_loss=0.038] Steps:  57%|█████▋    | 224/391 [2:12:34<1:34:01, 33.78s/it, lr=5e-5, step_loss=0.0438]Steps:  58%|█████▊    | 225/391 [2:12:42<1:32:06, 33.29s/it, lr=5e-5, step_loss=0.0438]Steps:  58%|█████▊    | 225/391 [2:12:42<1:32:06, 33.29s/it, lr=5e-5, step_loss=0.0604]Steps:  58%|█████▊    | 225/391 [2:12:50<1:32:06, 33.29s/it, lr=5e-5, step_loss=0.0436]Steps:  58%|█████▊    | 225/391 [2:12:58<1:32:06, 33.29s/it, lr=5e-5, step_loss=0.0397]Steps:  58%|█████▊    | 225/391 [2:13:06<1:32:06, 33.29s/it, lr=5e-5, step_loss=0.0447]Steps:  58%|█████▊    | 226/391 [2:13:14<1:30:22, 32.86s/it, lr=5e-5, step_loss=0.0447]Steps:  58%|█████▊    | 226/391 [2:13:14<1:30:22, 32.86s/it, lr=5e-5, step_loss=0.0489]Steps:  58%|█████▊    | 226/391 [2:13:23<1:30:22, 32.86s/it, lr=5e-5, step_loss=0.0413]Steps:  58%|█████▊    | 226/391 [2:13:32<1:30:22, 32.86s/it, lr=5e-5, step_loss=0.0422]Steps:  58%|█████▊    | 226/391 [2:13:40<1:30:22, 32.86s/it, lr=5e-5, step_loss=0.0442]Steps:  58%|█████▊    | 227/391 [2:13:49<1:31:26, 33.46s/it, lr=5e-5, step_loss=0.0442]Steps:  58%|█████▊    | 227/391 [2:13:49<1:31:26, 33.46s/it, lr=5e-5, step_loss=0.0563]Steps:  58%|█████▊    | 227/391 [2:13:57<1:31:26, 33.46s/it, lr=5e-5, step_loss=0.054] Steps:  58%|█████▊    | 227/391 [2:14:05<1:31:26, 33.46s/it, lr=5e-5, step_loss=0.045]Steps:  58%|█████▊    | 227/391 [2:14:13<1:31:26, 33.46s/it, lr=5e-5, step_loss=0.0718]Steps:  58%|█████▊    | 228/391 [2:14:21<1:30:00, 33.13s/it, lr=5e-5, step_loss=0.0718]Steps:  58%|█████▊    | 228/391 [2:14:21<1:30:00, 33.13s/it, lr=5e-5, step_loss=0.0625]Steps:  58%|█████▊    | 228/391 [2:14:29<1:30:00, 33.13s/it, lr=5e-5, step_loss=0.0357]Steps:  58%|█████▊    | 228/391 [2:14:38<1:30:00, 33.13s/it, lr=5e-5, step_loss=0.0562]Steps:  58%|█████▊    | 228/391 [2:14:47<1:30:00, 33.13s/it, lr=5e-5, step_loss=0.0342]Steps:  59%|█████▊    | 229/391 [2:14:55<1:30:39, 33.58s/it, lr=5e-5, step_loss=0.0342]Steps:  59%|█████▊    | 229/391 [2:14:55<1:30:39, 33.58s/it, lr=5e-5, step_loss=0.0374]Steps:  59%|█████▊    | 229/391 [2:15:03<1:30:39, 33.58s/it, lr=5e-5, step_loss=0.0553]Steps:  59%|█████▉    | 230/391 [2:15:04<1:09:37, 25.95s/it, lr=5e-5, step_loss=0.0553]Steps:  59%|█████▉    | 230/391 [2:15:04<1:09:37, 25.95s/it, lr=5e-5, step_loss=0.0347]Steps:  59%|█████▉    | 230/391 [2:15:19<1:09:37, 25.95s/it, lr=5e-5, step_loss=0.0378]Steps:  59%|█████▉    | 230/391 [2:15:27<1:09:37, 25.95s/it, lr=5e-5, step_loss=0.0535]Steps:  59%|█████▉    | 230/391 [2:15:35<1:09:37, 25.95s/it, lr=5e-5, step_loss=0.0377]Steps:  59%|█████▉    | 231/391 [2:15:43<1:19:37, 29.86s/it, lr=5e-5, step_loss=0.0377]Steps:  59%|█████▉    | 231/391 [2:15:43<1:19:37, 29.86s/it, lr=5e-5, step_loss=0.0433]Steps:  59%|█████▉    | 231/391 [2:15:51<1:19:37, 29.86s/it, lr=5e-5, step_loss=0.0723]Steps:  59%|█████▉    | 231/391 [2:15:59<1:19:37, 29.86s/it, lr=5e-5, step_loss=0.0656]Steps:  59%|█████▉    | 231/391 [2:16:08<1:19:37, 29.86s/it, lr=5e-5, step_loss=0.0495]Steps:  59%|█████▉    | 232/391 [2:16:16<1:21:41, 30.82s/it, lr=5e-5, step_loss=0.0495]Steps:  59%|█████▉    | 232/391 [2:16:16<1:21:41, 30.82s/it, lr=5e-5, step_loss=0.0479]Steps:  59%|█████▉    | 232/391 [2:16:23<1:21:41, 30.82s/it, lr=5e-5, step_loss=0.0393]Steps:  59%|█████▉    | 232/391 [2:16:31<1:21:41, 30.82s/it, lr=5e-5, step_loss=0.0431]Steps:  59%|█████▉    | 232/391 [2:16:40<1:21:41, 30.82s/it, lr=5e-5, step_loss=0.0377]Steps:  60%|█████▉    | 233/391 [2:16:48<1:22:05, 31.17s/it, lr=5e-5, step_loss=0.0377]Steps:  60%|█████▉    | 233/391 [2:16:48<1:22:05, 31.17s/it, lr=5e-5, step_loss=0.0599]Steps:  60%|█████▉    | 233/391 [2:16:57<1:22:05, 31.17s/it, lr=5e-5, step_loss=0.053] Steps:  60%|█████▉    | 233/391 [2:17:05<1:22:05, 31.17s/it, lr=5e-5, step_loss=0.0588]Steps:  60%|█████▉    | 233/391 [2:17:13<1:22:05, 31.17s/it, lr=5e-5, step_loss=0.0801]Steps:  60%|█████▉    | 234/391 [2:17:22<1:24:02, 32.12s/it, lr=5e-5, step_loss=0.0801]Steps:  60%|█████▉    | 234/391 [2:17:22<1:24:02, 32.12s/it, lr=5e-5, step_loss=0.0564]Steps:  60%|█████▉    | 234/391 [2:17:30<1:24:02, 32.12s/it, lr=5e-5, step_loss=0.0279]Steps:  60%|█████▉    | 234/391 [2:17:39<1:24:02, 32.12s/it, lr=5e-5, step_loss=0.0323]Steps:  60%|█████▉    | 234/391 [2:17:48<1:24:02, 32.12s/it, lr=5e-5, step_loss=0.0483]Steps:  60%|██████    | 235/391 [2:17:56<1:25:21, 32.83s/it, lr=5e-5, step_loss=0.0483]Steps:  60%|██████    | 235/391 [2:17:57<1:25:21, 32.83s/it, lr=5e-5, step_loss=0.0452]Steps:  60%|██████    | 235/391 [2:18:05<1:25:21, 32.83s/it, lr=5e-5, step_loss=0.0415]Steps:  60%|██████    | 235/391 [2:18:12<1:25:21, 32.83s/it, lr=5e-5, step_loss=0.0518]Steps:  60%|██████    | 235/391 [2:18:20<1:25:21, 32.83s/it, lr=5e-5, step_loss=0.0641]Steps:  60%|██████    | 236/391 [2:18:27<1:23:19, 32.26s/it, lr=5e-5, step_loss=0.0641]Steps:  60%|██████    | 236/391 [2:18:27<1:23:19, 32.26s/it, lr=5e-5, step_loss=0.0689]Steps:  60%|██████    | 236/391 [2:18:35<1:23:19, 32.26s/it, lr=5e-5, step_loss=0.0579]Steps:  60%|██████    | 236/391 [2:18:44<1:23:19, 32.26s/it, lr=5e-5, step_loss=0.0228]Steps:  60%|██████    | 236/391 [2:18:51<1:23:19, 32.26s/it, lr=5e-5, step_loss=0.0458]Steps:  61%|██████    | 237/391 [2:19:00<1:23:00, 32.34s/it, lr=5e-5, step_loss=0.0458]Steps:  61%|██████    | 237/391 [2:19:00<1:23:00, 32.34s/it, lr=5e-5, step_loss=0.0536]Steps:  61%|██████    | 237/391 [2:19:08<1:23:00, 32.34s/it, lr=5e-5, step_loss=0.0328]Steps:  61%|██████    | 237/391 [2:19:16<1:23:00, 32.34s/it, lr=5e-5, step_loss=0.0518]Steps:  61%|██████    | 237/391 [2:19:23<1:23:00, 32.34s/it, lr=5e-5, step_loss=0.031] Steps:  61%|██████    | 238/391 [2:19:32<1:21:56, 32.13s/it, lr=5e-5, step_loss=0.031]Steps:  61%|██████    | 238/391 [2:19:32<1:21:56, 32.13s/it, lr=5e-5, step_loss=0.0495]Steps:  61%|██████    | 238/391 [2:19:39<1:21:56, 32.13s/it, lr=5e-5, step_loss=0.0542]Steps:  61%|██████    | 238/391 [2:19:48<1:21:56, 32.13s/it, lr=5e-5, step_loss=0.0593]Steps:  61%|██████    | 238/391 [2:19:56<1:21:56, 32.13s/it, lr=5e-5, step_loss=0.0286]Steps:  61%|██████    | 239/391 [2:20:04<1:21:51, 32.31s/it, lr=5e-5, step_loss=0.0286]Steps:  61%|██████    | 239/391 [2:20:04<1:21:51, 32.31s/it, lr=5e-5, step_loss=0.0423]Steps:  61%|██████    | 239/391 [2:20:13<1:21:51, 32.31s/it, lr=5e-5, step_loss=0.0687]Steps:  61%|██████    | 239/391 [2:20:21<1:21:51, 32.31s/it, lr=5e-5, step_loss=0.0358]Steps:  61%|██████    | 239/391 [2:20:29<1:21:51, 32.31s/it, lr=5e-5, step_loss=0.0691]Steps:  61%|██████▏   | 240/391 [2:20:37<1:21:45, 32.49s/it, lr=5e-5, step_loss=0.0691]Steps:  61%|██████▏   | 240/391 [2:20:37<1:21:45, 32.49s/it, lr=5e-5, step_loss=0.0646]Steps:  61%|██████▏   | 240/391 [2:20:44<1:21:45, 32.49s/it, lr=5e-5, step_loss=0.0504]Steps:  61%|██████▏   | 240/391 [2:20:52<1:21:45, 32.49s/it, lr=5e-5, step_loss=0.059] Steps:  61%|██████▏   | 240/391 [2:21:01<1:21:45, 32.49s/it, lr=5e-5, step_loss=0.0406]Steps:  62%|██████▏   | 241/391 [2:21:09<1:21:03, 32.42s/it, lr=5e-5, step_loss=0.0406]Steps:  62%|██████▏   | 241/391 [2:21:10<1:21:03, 32.42s/it, lr=5e-5, step_loss=0.0421]Steps:  62%|██████▏   | 241/391 [2:21:18<1:21:03, 32.42s/it, lr=5e-5, step_loss=0.059] Steps:  62%|██████▏   | 241/391 [2:21:28<1:21:03, 32.42s/it, lr=5e-5, step_loss=0.0641]Steps:  62%|██████▏   | 241/391 [2:21:37<1:21:03, 32.42s/it, lr=5e-5, step_loss=0.0494]Steps:  62%|██████▏   | 242/391 [2:21:47<1:24:27, 34.01s/it, lr=5e-5, step_loss=0.0494]Steps:  62%|██████▏   | 242/391 [2:21:47<1:24:27, 34.01s/it, lr=5e-5, step_loss=0.039] Steps:  62%|██████▏   | 242/391 [2:21:57<1:24:27, 34.01s/it, lr=5e-5, step_loss=0.0815]Steps:  62%|██████▏   | 242/391 [2:22:06<1:24:27, 34.01s/it, lr=5e-5, step_loss=0.0298]Steps:  62%|██████▏   | 242/391 [2:22:13<1:24:27, 34.01s/it, lr=5e-5, step_loss=0.0419]Steps:  62%|██████▏   | 243/391 [2:22:23<1:25:07, 34.51s/it, lr=5e-5, step_loss=0.0419]Steps:  62%|██████▏   | 243/391 [2:22:23<1:25:07, 34.51s/it, lr=5e-5, step_loss=0.0288]Steps:  62%|██████▏   | 243/391 [2:22:31<1:25:07, 34.51s/it, lr=5e-5, step_loss=0.0409]Steps:  62%|██████▏   | 243/391 [2:22:41<1:25:07, 34.51s/it, lr=5e-5, step_loss=0.0357]Steps:  62%|██████▏   | 243/391 [2:22:49<1:25:07, 34.51s/it, lr=5e-5, step_loss=0.0481]Steps:  62%|██████▏   | 244/391 [2:22:58<1:24:59, 34.69s/it, lr=5e-5, step_loss=0.0481]Steps:  62%|██████▏   | 244/391 [2:22:58<1:24:59, 34.69s/it, lr=5e-5, step_loss=0.0373]Steps:  62%|██████▏   | 244/391 [2:23:07<1:24:59, 34.69s/it, lr=5e-5, step_loss=0.0549]Steps:  62%|██████▏   | 244/391 [2:23:15<1:24:59, 34.69s/it, lr=5e-5, step_loss=0.0547]Steps:  62%|██████▏   | 244/391 [2:23:24<1:24:59, 34.69s/it, lr=5e-5, step_loss=0.0507]Steps:  63%|██████▎   | 245/391 [2:23:33<1:24:31, 34.73s/it, lr=5e-5, step_loss=0.0507]Steps:  63%|██████▎   | 245/391 [2:23:33<1:24:31, 34.73s/it, lr=5e-5, step_loss=0.0303]Steps:  63%|██████▎   | 245/391 [2:23:42<1:24:31, 34.73s/it, lr=5e-5, step_loss=0.0337]Steps:  63%|██████▎   | 245/391 [2:23:51<1:24:31, 34.73s/it, lr=5e-5, step_loss=0.0522]Steps:  63%|██████▎   | 245/391 [2:24:00<1:24:31, 34.73s/it, lr=5e-5, step_loss=0.0454]Steps:  63%|██████▎   | 246/391 [2:24:09<1:24:39, 35.03s/it, lr=5e-5, step_loss=0.0454]Steps:  63%|██████▎   | 246/391 [2:24:09<1:24:39, 35.03s/it, lr=5e-5, step_loss=0.0519]Steps:  63%|██████▎   | 246/391 [2:24:18<1:24:39, 35.03s/it, lr=5e-5, step_loss=0.0407]Steps:  63%|██████▎   | 246/391 [2:24:27<1:24:39, 35.03s/it, lr=5e-5, step_loss=0.0396]Steps:  63%|██████▎   | 246/391 [2:24:35<1:24:39, 35.03s/it, lr=5e-5, step_loss=0.0499]Steps:  63%|██████▎   | 247/391 [2:24:43<1:23:47, 34.92s/it, lr=5e-5, step_loss=0.0499]Steps:  63%|██████▎   | 247/391 [2:24:43<1:23:47, 34.92s/it, lr=5e-5, step_loss=0.062] Steps:  63%|██████▎   | 247/391 [2:24:52<1:23:47, 34.92s/it, lr=5e-5, step_loss=0.0595]Steps:  63%|██████▎   | 247/391 [2:25:01<1:23:47, 34.92s/it, lr=5e-5, step_loss=0.0417]Steps:  63%|██████▎   | 247/391 [2:25:10<1:23:47, 34.92s/it, lr=5e-5, step_loss=0.0573]Steps:  63%|██████▎   | 248/391 [2:25:19<1:23:58, 35.23s/it, lr=5e-5, step_loss=0.0573]Steps:  63%|██████▎   | 248/391 [2:25:19<1:23:58, 35.23s/it, lr=5e-5, step_loss=0.0669]Steps:  63%|██████▎   | 248/391 [2:25:27<1:23:58, 35.23s/it, lr=5e-5, step_loss=0.0466]Steps:  63%|██████▎   | 248/391 [2:25:36<1:23:58, 35.23s/it, lr=5e-5, step_loss=0.0489]Steps:  63%|██████▎   | 248/391 [2:25:43<1:23:58, 35.23s/it, lr=5e-5, step_loss=0.0532]Steps:  64%|██████▎   | 249/391 [2:25:51<1:20:46, 34.13s/it, lr=5e-5, step_loss=0.0532]Steps:  64%|██████▎   | 249/391 [2:25:51<1:20:46, 34.13s/it, lr=5e-5, step_loss=0.0557]Steps:  64%|██████▎   | 249/391 [2:25:59<1:20:46, 34.13s/it, lr=5e-5, step_loss=0.0502]Steps:  64%|██████▎   | 249/391 [2:26:08<1:20:46, 34.13s/it, lr=5e-5, step_loss=0.0492]Steps:  64%|██████▎   | 249/391 [2:26:15<1:20:46, 34.13s/it, lr=5e-5, step_loss=0.0396]Steps:  64%|██████▍   | 250/391 [2:26:24<1:19:27, 33.81s/it, lr=5e-5, step_loss=0.0396]Steps:  64%|██████▍   | 250/391 [2:26:24<1:19:27, 33.81s/it, lr=5e-5, step_loss=0.063] Steps:  64%|██████▍   | 250/391 [2:26:32<1:19:27, 33.81s/it, lr=5e-5, step_loss=0.0395]Steps:  64%|██████▍   | 250/391 [2:26:39<1:19:27, 33.81s/it, lr=5e-5, step_loss=0.0423]Steps:  64%|██████▍   | 250/391 [2:26:47<1:19:27, 33.81s/it, lr=5e-5, step_loss=0.0532]Steps:  64%|██████▍   | 251/391 [2:26:55<1:17:16, 33.12s/it, lr=5e-5, step_loss=0.0532]Steps:  64%|██████▍   | 251/391 [2:26:55<1:17:16, 33.12s/it, lr=5e-5, step_loss=0.0516]Steps:  64%|██████▍   | 251/391 [2:27:04<1:17:16, 33.12s/it, lr=5e-5, step_loss=0.0492]Steps:  64%|██████▍   | 251/391 [2:27:12<1:17:16, 33.12s/it, lr=5e-5, step_loss=0.0385]Steps:  64%|██████▍   | 251/391 [2:27:21<1:17:16, 33.12s/it, lr=5e-5, step_loss=0.0665]Steps:  64%|██████▍   | 252/391 [2:27:30<1:18:00, 33.67s/it, lr=5e-5, step_loss=0.0665]Steps:  64%|██████▍   | 252/391 [2:27:30<1:18:00, 33.67s/it, lr=5e-5, step_loss=0.0493]Steps:  64%|██████▍   | 252/391 [2:27:36<1:18:00, 33.67s/it, lr=5e-5, step_loss=0.0236]Steps:  65%|██████▍   | 253/391 [2:27:37<59:10, 25.73s/it, lr=5e-5, step_loss=0.0236]  Steps:  65%|██████▍   | 253/391 [2:27:37<59:10, 25.73s/it, lr=5e-5, step_loss=0.0326]Steps:  65%|██████▍   | 253/391 [2:27:53<59:10, 25.73s/it, lr=5e-5, step_loss=0.0657]Steps:  65%|██████▍   | 253/391 [2:28:01<59:10, 25.73s/it, lr=5e-5, step_loss=0.0621]Steps:  65%|██████▍   | 253/391 [2:28:08<59:10, 25.73s/it, lr=5e-5, step_loss=0.0503]Steps:  65%|██████▍   | 254/391 [2:28:17<1:07:56, 29.75s/it, lr=5e-5, step_loss=0.0503]Steps:  65%|██████▍   | 254/391 [2:28:17<1:07:56, 29.75s/it, lr=5e-5, step_loss=0.0486]Steps:  65%|██████▍   | 254/391 [2:28:25<1:07:56, 29.75s/it, lr=5e-5, step_loss=0.0524]Steps:  65%|██████▍   | 254/391 [2:28:33<1:07:56, 29.75s/it, lr=5e-5, step_loss=0.0438]Steps:  65%|██████▍   | 254/391 [2:28:40<1:07:56, 29.75s/it, lr=5e-5, step_loss=0.0434]Steps:  65%|██████▌   | 255/391 [2:28:49<1:09:29, 30.66s/it, lr=5e-5, step_loss=0.0434]Steps:  65%|██████▌   | 255/391 [2:28:49<1:09:29, 30.66s/it, lr=5e-5, step_loss=0.0472]Steps:  65%|██████▌   | 255/391 [2:28:58<1:09:29, 30.66s/it, lr=5e-5, step_loss=0.037] Steps:  65%|██████▌   | 255/391 [2:29:05<1:09:29, 30.66s/it, lr=5e-5, step_loss=0.0379]Steps:  65%|██████▌   | 255/391 [2:29:14<1:09:29, 30.66s/it, lr=5e-5, step_loss=0.0325]Steps:  65%|██████▌   | 256/391 [2:29:22<1:10:04, 31.15s/it, lr=5e-5, step_loss=0.0325]Steps:  65%|██████▌   | 256/391 [2:29:22<1:10:04, 31.15s/it, lr=5e-5, step_loss=0.0606]Steps:  65%|██████▌   | 256/391 [2:29:31<1:10:04, 31.15s/it, lr=5e-5, step_loss=0.068] Steps:  65%|██████▌   | 256/391 [2:29:38<1:10:04, 31.15s/it, lr=5e-5, step_loss=0.04] Steps:  65%|██████▌   | 256/391 [2:29:47<1:10:04, 31.15s/it, lr=5e-5, step_loss=0.0433]Steps:  66%|██████▌   | 257/391 [2:29:55<1:10:46, 31.69s/it, lr=5e-5, step_loss=0.0433]Steps:  66%|██████▌   | 257/391 [2:29:55<1:10:46, 31.69s/it, lr=5e-5, step_loss=0.0198]Steps:  66%|██████▌   | 257/391 [2:30:03<1:10:46, 31.69s/it, lr=5e-5, step_loss=0.0387]Steps:  66%|██████▌   | 257/391 [2:30:12<1:10:46, 31.69s/it, lr=5e-5, step_loss=0.0738]Steps:  66%|██████▌   | 257/391 [2:30:19<1:10:46, 31.69s/it, lr=5e-5, step_loss=0.0393]Steps:  66%|██████▌   | 258/391 [2:30:28<1:11:38, 32.32s/it, lr=5e-5, step_loss=0.0393]Steps:  66%|██████▌   | 258/391 [2:30:28<1:11:38, 32.32s/it, lr=5e-5, step_loss=0.0446]Steps:  66%|██████▌   | 258/391 [2:30:37<1:11:38, 32.32s/it, lr=5e-5, step_loss=0.0425]Steps:  66%|██████▌   | 258/391 [2:30:45<1:11:38, 32.32s/it, lr=5e-5, step_loss=0.0431]Steps:  66%|██████▌   | 258/391 [2:30:53<1:11:38, 32.32s/it, lr=5e-5, step_loss=0.0386]Steps:  66%|██████▌   | 259/391 [2:31:01<1:11:33, 32.53s/it, lr=5e-5, step_loss=0.0386]Steps:  66%|██████▌   | 259/391 [2:31:01<1:11:33, 32.53s/it, lr=5e-5, step_loss=0.0426]Steps:  66%|██████▌   | 259/391 [2:31:10<1:11:33, 32.53s/it, lr=5e-5, step_loss=0.034] Steps:  66%|██████▌   | 259/391 [2:31:19<1:11:33, 32.53s/it, lr=5e-5, step_loss=0.0402]Steps:  66%|██████▌   | 259/391 [2:31:28<1:11:33, 32.53s/it, lr=5e-5, step_loss=0.0612]Steps:  66%|██████▋   | 260/391 [2:31:37<1:12:47, 33.34s/it, lr=5e-5, step_loss=0.0612]Steps:  66%|██████▋   | 260/391 [2:31:37<1:12:47, 33.34s/it, lr=5e-5, step_loss=0.0386]Steps:  66%|██████▋   | 260/391 [2:31:45<1:12:47, 33.34s/it, lr=5e-5, step_loss=0.0429]Steps:  66%|██████▋   | 260/391 [2:31:53<1:12:47, 33.34s/it, lr=5e-5, step_loss=0.0505]Steps:  66%|██████▋   | 260/391 [2:32:01<1:12:47, 33.34s/it, lr=5e-5, step_loss=0.0413]Steps:  67%|██████▋   | 261/391 [2:32:09<1:11:46, 33.13s/it, lr=5e-5, step_loss=0.0413]Steps:  67%|██████▋   | 261/391 [2:32:09<1:11:46, 33.13s/it, lr=5e-5, step_loss=0.0424]Steps:  67%|██████▋   | 261/391 [2:32:18<1:11:46, 33.13s/it, lr=5e-5, step_loss=0.0328]Steps:  67%|██████▋   | 261/391 [2:32:26<1:11:46, 33.13s/it, lr=5e-5, step_loss=0.0344]Steps:  67%|██████▋   | 261/391 [2:32:34<1:11:46, 33.13s/it, lr=5e-5, step_loss=0.0366]Steps:  67%|██████▋   | 262/391 [2:32:42<1:11:00, 33.03s/it, lr=5e-5, step_loss=0.0366]Steps:  67%|██████▋   | 262/391 [2:32:42<1:11:00, 33.03s/it, lr=5e-5, step_loss=0.0488]Steps:  67%|██████▋   | 262/391 [2:32:50<1:11:00, 33.03s/it, lr=5e-5, step_loss=0.0549]Steps:  67%|██████▋   | 262/391 [2:32:58<1:11:00, 33.03s/it, lr=5e-5, step_loss=0.0686]Steps:  67%|██████▋   | 262/391 [2:33:06<1:11:00, 33.03s/it, lr=5e-5, step_loss=0.0433]Steps:  67%|██████▋   | 263/391 [2:33:15<1:10:15, 32.93s/it, lr=5e-5, step_loss=0.0433]Steps:  67%|██████▋   | 263/391 [2:33:15<1:10:15, 32.93s/it, lr=5e-5, step_loss=0.0475]Steps:  67%|██████▋   | 263/391 [2:33:23<1:10:15, 32.93s/it, lr=5e-5, step_loss=0.0454]Steps:  67%|██████▋   | 263/391 [2:33:31<1:10:15, 32.93s/it, lr=5e-5, step_loss=0.0414]Steps:  67%|██████▋   | 263/391 [2:33:40<1:10:15, 32.93s/it, lr=5e-5, step_loss=0.0335]Steps:  68%|██████▊   | 264/391 [2:33:49<1:10:23, 33.25s/it, lr=5e-5, step_loss=0.0335]Steps:  68%|██████▊   | 264/391 [2:33:49<1:10:23, 33.25s/it, lr=5e-5, step_loss=0.0393]Steps:  68%|██████▊   | 264/391 [2:33:58<1:10:23, 33.25s/it, lr=5e-5, step_loss=0.035] Steps:  68%|██████▊   | 264/391 [2:34:05<1:10:23, 33.25s/it, lr=5e-5, step_loss=0.0593]Steps:  68%|██████▊   | 264/391 [2:34:14<1:10:23, 33.25s/it, lr=5e-5, step_loss=0.0484]Steps:  68%|██████▊   | 265/391 [2:34:23<1:10:18, 33.48s/it, lr=5e-5, step_loss=0.0484]Steps:  68%|██████▊   | 265/391 [2:34:23<1:10:18, 33.48s/it, lr=5e-5, step_loss=0.057] Steps:  68%|██████▊   | 265/391 [2:34:32<1:10:18, 33.48s/it, lr=5e-5, step_loss=0.0394]Steps:  68%|██████▊   | 265/391 [2:34:41<1:10:18, 33.48s/it, lr=5e-5, step_loss=0.0554]Steps:  68%|██████▊   | 265/391 [2:34:49<1:10:18, 33.48s/it, lr=5e-5, step_loss=0.0519]Steps:  68%|██████▊   | 266/391 [2:34:57<1:10:05, 33.64s/it, lr=5e-5, step_loss=0.0519]Steps:  68%|██████▊   | 266/391 [2:34:57<1:10:05, 33.64s/it, lr=5e-5, step_loss=0.0598]Steps:  68%|██████▊   | 266/391 [2:35:05<1:10:05, 33.64s/it, lr=5e-5, step_loss=0.062] Steps:  68%|██████▊   | 266/391 [2:35:13<1:10:05, 33.64s/it, lr=5e-5, step_loss=0.0384]Steps:  68%|██████▊   | 266/391 [2:35:21<1:10:05, 33.64s/it, lr=5e-5, step_loss=0.0305]Steps:  68%|██████▊   | 267/391 [2:35:29<1:08:29, 33.14s/it, lr=5e-5, step_loss=0.0305]Steps:  68%|██████▊   | 267/391 [2:35:29<1:08:29, 33.14s/it, lr=5e-5, step_loss=0.0392]Steps:  68%|██████▊   | 267/391 [2:35:37<1:08:29, 33.14s/it, lr=5e-5, step_loss=0.0509]Steps:  68%|██████▊   | 267/391 [2:35:46<1:08:29, 33.14s/it, lr=5e-5, step_loss=0.0795]Steps:  68%|██████▊   | 267/391 [2:35:55<1:08:29, 33.14s/it, lr=5e-5, step_loss=0.0478]Steps:  69%|██████▊   | 268/391 [2:36:02<1:08:14, 33.29s/it, lr=5e-5, step_loss=0.0478]Steps:  69%|██████▊   | 268/391 [2:36:02<1:08:14, 33.29s/it, lr=5e-5, step_loss=0.0288]Steps:  69%|██████▊   | 268/391 [2:36:10<1:08:14, 33.29s/it, lr=5e-5, step_loss=0.0367]Steps:  69%|██████▊   | 268/391 [2:36:19<1:08:14, 33.29s/it, lr=5e-5, step_loss=0.0409]Steps:  69%|██████▊   | 268/391 [2:36:27<1:08:14, 33.29s/it, lr=5e-5, step_loss=0.0412]Steps:  69%|██████▉   | 269/391 [2:36:35<1:07:17, 33.09s/it, lr=5e-5, step_loss=0.0412]Steps:  69%|██████▉   | 269/391 [2:36:35<1:07:17, 33.09s/it, lr=5e-5, step_loss=0.0223]Steps:  69%|██████▉   | 269/391 [2:36:44<1:07:17, 33.09s/it, lr=5e-5, step_loss=0.049] Steps:  69%|██████▉   | 269/391 [2:36:52<1:07:17, 33.09s/it, lr=5e-5, step_loss=0.0378]Steps:  69%|██████▉   | 269/391 [2:36:59<1:07:17, 33.09s/it, lr=5e-5, step_loss=0.0728]Steps:  69%|██████▉   | 270/391 [2:37:08<1:06:25, 32.94s/it, lr=5e-5, step_loss=0.0728]Steps:  69%|██████▉   | 270/391 [2:37:08<1:06:25, 32.94s/it, lr=5e-5, step_loss=0.0447]Steps:  69%|██████▉   | 270/391 [2:37:16<1:06:25, 32.94s/it, lr=5e-5, step_loss=0.0406]Steps:  69%|██████▉   | 270/391 [2:37:24<1:06:25, 32.94s/it, lr=5e-5, step_loss=0.0519]Steps:  69%|██████▉   | 270/391 [2:37:32<1:06:25, 32.94s/it, lr=5e-5, step_loss=0.06]  Steps:  69%|██████▉   | 271/391 [2:37:40<1:05:34, 32.78s/it, lr=5e-5, step_loss=0.06]Steps:  69%|██████▉   | 271/391 [2:37:40<1:05:34, 32.78s/it, lr=5e-5, step_loss=0.0416]Steps:  69%|██████▉   | 271/391 [2:37:48<1:05:34, 32.78s/it, lr=5e-5, step_loss=0.0467]Steps:  69%|██████▉   | 271/391 [2:37:56<1:05:34, 32.78s/it, lr=5e-5, step_loss=0.0479]Steps:  69%|██████▉   | 271/391 [2:38:05<1:05:34, 32.78s/it, lr=5e-5, step_loss=0.0469]Steps:  70%|██████▉   | 272/391 [2:38:14<1:05:30, 33.03s/it, lr=5e-5, step_loss=0.0469]Steps:  70%|██████▉   | 272/391 [2:38:14<1:05:30, 33.03s/it, lr=5e-5, step_loss=0.0264]Steps:  70%|██████▉   | 272/391 [2:38:22<1:05:30, 33.03s/it, lr=5e-5, step_loss=0.0496]Steps:  70%|██████▉   | 272/391 [2:38:30<1:05:30, 33.03s/it, lr=5e-5, step_loss=0.0452]Steps:  70%|██████▉   | 272/391 [2:38:38<1:05:30, 33.03s/it, lr=5e-5, step_loss=0.034] Steps:  70%|██████▉   | 273/391 [2:38:46<1:04:31, 32.81s/it, lr=5e-5, step_loss=0.034]Steps:  70%|██████▉   | 273/391 [2:38:46<1:04:31, 32.81s/it, lr=5e-5, step_loss=0.0382]Steps:  70%|██████▉   | 273/391 [2:38:53<1:04:31, 32.81s/it, lr=5e-5, step_loss=0.0431]Steps:  70%|██████▉   | 273/391 [2:39:00<1:04:31, 32.81s/it, lr=5e-5, step_loss=0.0431]Steps:  70%|██████▉   | 273/391 [2:39:08<1:04:31, 32.81s/it, lr=5e-5, step_loss=0.0408]Steps:  70%|███████   | 274/391 [2:39:16<1:02:34, 32.09s/it, lr=5e-5, step_loss=0.0408]Steps:  70%|███████   | 274/391 [2:39:16<1:02:34, 32.09s/it, lr=5e-5, step_loss=0.0543]Steps:  70%|███████   | 274/391 [2:39:25<1:02:34, 32.09s/it, lr=5e-5, step_loss=0.0616]Steps:  70%|███████   | 274/391 [2:39:34<1:02:34, 32.09s/it, lr=5e-5, step_loss=0.0542]Steps:  70%|███████   | 274/391 [2:39:41<1:02:34, 32.09s/it, lr=5e-5, step_loss=0.0252]Steps:  70%|███████   | 275/391 [2:39:49<1:02:23, 32.27s/it, lr=5e-5, step_loss=0.0252]Steps:  70%|███████   | 275/391 [2:39:49<1:02:23, 32.27s/it, lr=5e-5, step_loss=0.0495]Steps:  70%|███████   | 275/391 [2:39:57<1:02:23, 32.27s/it, lr=5e-5, step_loss=0.0578]Steps:  71%|███████   | 276/391 [2:39:58<48:24, 25.25s/it, lr=5e-5, step_loss=0.0578]  Steps:  71%|███████   | 276/391 [2:39:58<48:24, 25.25s/it, lr=5e-5, step_loss=0.0489]Steps:  71%|███████   | 276/391 [2:40:12<48:24, 25.25s/it, lr=5e-5, step_loss=0.0378]Steps:  71%|███████   | 276/391 [2:40:20<48:24, 25.25s/it, lr=5e-5, step_loss=0.0529]Steps:  71%|███████   | 276/391 [2:40:28<48:24, 25.25s/it, lr=5e-5, step_loss=0.0411]Steps:  71%|███████   | 277/391 [2:40:36<55:16, 29.10s/it, lr=5e-5, step_loss=0.0411]Steps:  71%|███████   | 277/391 [2:40:36<55:16, 29.10s/it, lr=5e-5, step_loss=0.0449]Steps:  71%|███████   | 277/391 [2:40:45<55:16, 29.10s/it, lr=5e-5, step_loss=0.0543]Steps:  71%|███████   | 277/391 [2:40:53<55:16, 29.10s/it, lr=5e-5, step_loss=0.0431]Steps:  71%|███████   | 277/391 [2:41:01<55:16, 29.10s/it, lr=5e-5, step_loss=0.0534]Steps:  71%|███████   | 278/391 [2:41:09<57:11, 30.37s/it, lr=5e-5, step_loss=0.0534]Steps:  71%|███████   | 278/391 [2:41:09<57:11, 30.37s/it, lr=5e-5, step_loss=0.0424]Steps:  71%|███████   | 278/391 [2:41:17<57:11, 30.37s/it, lr=5e-5, step_loss=0.0338]Steps:  71%|███████   | 278/391 [2:41:25<57:11, 30.37s/it, lr=5e-5, step_loss=0.0518]Steps:  71%|███████   | 278/391 [2:41:33<57:11, 30.37s/it, lr=5e-5, step_loss=0.0515]Steps:  71%|███████▏  | 279/391 [2:41:42<57:42, 30.91s/it, lr=5e-5, step_loss=0.0515]Steps:  71%|███████▏  | 279/391 [2:41:42<57:42, 30.91s/it, lr=5e-5, step_loss=0.0451]Steps:  71%|███████▏  | 279/391 [2:41:50<57:42, 30.91s/it, lr=5e-5, step_loss=0.039] Steps:  71%|███████▏  | 279/391 [2:41:58<57:42, 30.91s/it, lr=5e-5, step_loss=0.0546]Steps:  71%|███████▏  | 279/391 [2:42:07<57:42, 30.91s/it, lr=5e-5, step_loss=0.0652]Steps:  72%|███████▏  | 280/391 [2:42:16<59:11, 31.99s/it, lr=5e-5, step_loss=0.0652]Steps:  72%|███████▏  | 280/391 [2:42:16<59:11, 31.99s/it, lr=5e-5, step_loss=0.0462]Steps:  72%|███████▏  | 280/391 [2:42:23<59:11, 31.99s/it, lr=5e-5, step_loss=0.0541]Steps:  72%|███████▏  | 280/391 [2:42:32<59:11, 31.99s/it, lr=5e-5, step_loss=0.0516]Steps:  72%|███████▏  | 280/391 [2:42:40<59:11, 31.99s/it, lr=5e-5, step_loss=0.0439]Steps:  72%|███████▏  | 281/391 [2:42:48<58:49, 32.09s/it, lr=5e-5, step_loss=0.0439]Steps:  72%|███████▏  | 281/391 [2:42:48<58:49, 32.09s/it, lr=5e-5, step_loss=0.0632]Steps:  72%|███████▏  | 281/391 [2:42:57<58:49, 32.09s/it, lr=5e-5, step_loss=0.0497]Steps:  72%|███████▏  | 281/391 [2:43:04<58:49, 32.09s/it, lr=5e-5, step_loss=0.058] Steps:  72%|███████▏  | 281/391 [2:43:13<58:49, 32.09s/it, lr=5e-5, step_loss=0.0471]Steps:  72%|███████▏  | 282/391 [2:43:22<58:59, 32.47s/it, lr=5e-5, step_loss=0.0471]Steps:  72%|███████▏  | 282/391 [2:43:22<58:59, 32.47s/it, lr=5e-5, step_loss=0.0385]Steps:  72%|███████▏  | 282/391 [2:43:30<58:59, 32.47s/it, lr=5e-5, step_loss=0.0469]Steps:  72%|███████▏  | 282/391 [2:43:39<58:59, 32.47s/it, lr=5e-5, step_loss=0.0359]Steps:  72%|███████▏  | 282/391 [2:43:47<58:59, 32.47s/it, lr=5e-5, step_loss=0.0238]Steps:  72%|███████▏  | 283/391 [2:43:55<58:48, 32.67s/it, lr=5e-5, step_loss=0.0238]Steps:  72%|███████▏  | 283/391 [2:43:55<58:48, 32.67s/it, lr=5e-5, step_loss=0.0563]Steps:  72%|███████▏  | 283/391 [2:44:02<58:48, 32.67s/it, lr=5e-5, step_loss=0.0421]Steps:  72%|███████▏  | 283/391 [2:44:09<58:48, 32.67s/it, lr=5e-5, step_loss=0.0606]Steps:  72%|███████▏  | 283/391 [2:44:18<58:48, 32.67s/it, lr=5e-5, step_loss=0.0539]Steps:  73%|███████▎  | 284/391 [2:44:26<57:14, 32.10s/it, lr=5e-5, step_loss=0.0539]Steps:  73%|███████▎  | 284/391 [2:44:26<57:14, 32.10s/it, lr=5e-5, step_loss=0.0372]Steps:  73%|███████▎  | 284/391 [2:44:34<57:14, 32.10s/it, lr=5e-5, step_loss=0.0527]Steps:  73%|███████▎  | 284/391 [2:44:42<57:14, 32.10s/it, lr=5e-5, step_loss=0.0585]Steps:  73%|███████▎  | 284/391 [2:44:50<57:14, 32.10s/it, lr=5e-5, step_loss=0.0568]Steps:  73%|███████▎  | 285/391 [2:44:58<56:53, 32.20s/it, lr=5e-5, step_loss=0.0568]Steps:  73%|███████▎  | 285/391 [2:44:58<56:53, 32.20s/it, lr=5e-5, step_loss=0.0366]Steps:  73%|███████▎  | 285/391 [2:45:07<56:53, 32.20s/it, lr=5e-5, step_loss=0.0573]Steps:  73%|███████▎  | 285/391 [2:45:15<56:53, 32.20s/it, lr=5e-5, step_loss=0.0463]Steps:  73%|███████▎  | 285/391 [2:45:24<56:53, 32.20s/it, lr=5e-5, step_loss=0.0421]Steps:  73%|███████▎  | 286/391 [2:45:33<57:36, 32.92s/it, lr=5e-5, step_loss=0.0421]Steps:  73%|███████▎  | 286/391 [2:45:33<57:36, 32.92s/it, lr=5e-5, step_loss=0.0502]Steps:  73%|███████▎  | 286/391 [2:45:41<57:36, 32.92s/it, lr=5e-5, step_loss=0.036] Steps:  73%|███████▎  | 286/391 [2:45:49<57:36, 32.92s/it, lr=5e-5, step_loss=0.0592]Steps:  73%|███████▎  | 286/391 [2:45:56<57:36, 32.92s/it, lr=5e-5, step_loss=0.0404]Steps:  73%|███████▎  | 287/391 [2:46:04<56:04, 32.35s/it, lr=5e-5, step_loss=0.0404]Steps:  73%|███████▎  | 287/391 [2:46:04<56:04, 32.35s/it, lr=5e-5, step_loss=0.0391]Steps:  73%|███████▎  | 287/391 [2:46:12<56:04, 32.35s/it, lr=5e-5, step_loss=0.0622]Steps:  73%|███████▎  | 287/391 [2:46:20<56:04, 32.35s/it, lr=5e-5, step_loss=0.0388]Steps:  73%|███████▎  | 287/391 [2:46:29<56:04, 32.35s/it, lr=5e-5, step_loss=0.061] Steps:  74%|███████▎  | 288/391 [2:46:37<56:11, 32.73s/it, lr=5e-5, step_loss=0.061]Steps:  74%|███████▎  | 288/391 [2:46:37<56:11, 32.73s/it, lr=5e-5, step_loss=0.0459]Steps:  74%|███████▎  | 288/391 [2:46:46<56:11, 32.73s/it, lr=5e-5, step_loss=0.0404]Steps:  74%|███████▎  | 288/391 [2:46:55<56:11, 32.73s/it, lr=5e-5, step_loss=0.0469]Steps:  74%|███████▎  | 288/391 [2:47:03<56:11, 32.73s/it, lr=5e-5, step_loss=0.0542]Steps:  74%|███████▍  | 289/391 [2:47:11<56:23, 33.17s/it, lr=5e-5, step_loss=0.0542]Steps:  74%|███████▍  | 289/391 [2:47:11<56:23, 33.17s/it, lr=5e-5, step_loss=0.066] Steps:  74%|███████▍  | 289/391 [2:47:18<56:23, 33.17s/it, lr=5e-5, step_loss=0.0697]Steps:  74%|███████▍  | 289/391 [2:47:26<56:23, 33.17s/it, lr=5e-5, step_loss=0.0467]Steps:  74%|███████▍  | 289/391 [2:47:35<56:23, 33.17s/it, lr=5e-5, step_loss=0.0449]Steps:  74%|███████▍  | 290/391 [2:47:43<54:53, 32.61s/it, lr=5e-5, step_loss=0.0449]Steps:  74%|███████▍  | 290/391 [2:47:43<54:53, 32.61s/it, lr=5e-5, step_loss=0.0505]Steps:  74%|███████▍  | 290/391 [2:47:51<54:53, 32.61s/it, lr=5e-5, step_loss=0.0634]Steps:  74%|███████▍  | 290/391 [2:47:59<54:53, 32.61s/it, lr=5e-5, step_loss=0.039] Steps:  74%|███████▍  | 290/391 [2:48:08<54:53, 32.61s/it, lr=5e-5, step_loss=0.0643]Steps:  74%|███████▍  | 291/391 [2:48:18<55:27, 33.28s/it, lr=5e-5, step_loss=0.0643]Steps:  74%|███████▍  | 291/391 [2:48:18<55:27, 33.28s/it, lr=5e-5, step_loss=0.0297]Steps:  74%|███████▍  | 291/391 [2:48:26<55:27, 33.28s/it, lr=5e-5, step_loss=0.0449]Steps:  74%|███████▍  | 291/391 [2:48:34<55:27, 33.28s/it, lr=5e-5, step_loss=0.061] Steps:  74%|███████▍  | 291/391 [2:48:44<55:27, 33.28s/it, lr=5e-5, step_loss=0.0452]Steps:  75%|███████▍  | 292/391 [2:48:52<55:40, 33.74s/it, lr=5e-5, step_loss=0.0452]Steps:  75%|███████▍  | 292/391 [2:48:52<55:40, 33.74s/it, lr=5e-5, step_loss=0.0451]Steps:  75%|███████▍  | 292/391 [2:49:01<55:40, 33.74s/it, lr=5e-5, step_loss=0.0466]Steps:  75%|███████▍  | 292/391 [2:49:09<55:40, 33.74s/it, lr=5e-5, step_loss=0.031] Steps:  75%|███████▍  | 292/391 [2:49:18<55:40, 33.74s/it, lr=5e-5, step_loss=0.0657]Steps:  75%|███████▍  | 293/391 [2:49:27<55:19, 33.88s/it, lr=5e-5, step_loss=0.0657]Steps:  75%|███████▍  | 293/391 [2:49:27<55:19, 33.88s/it, lr=5e-5, step_loss=0.0726]Steps:  75%|███████▍  | 293/391 [2:49:34<55:19, 33.88s/it, lr=5e-5, step_loss=0.0424]Steps:  75%|███████▍  | 293/391 [2:49:44<55:19, 33.88s/it, lr=5e-5, step_loss=0.0461]Steps:  75%|███████▍  | 293/391 [2:49:52<55:19, 33.88s/it, lr=5e-5, step_loss=0.047] Steps:  75%|███████▌  | 294/391 [2:50:01<54:51, 33.93s/it, lr=5e-5, step_loss=0.047]Steps:  75%|███████▌  | 294/391 [2:50:01<54:51, 33.93s/it, lr=5e-5, step_loss=0.0385]Steps:  75%|███████▌  | 294/391 [2:50:09<54:51, 33.93s/it, lr=5e-5, step_loss=0.0493]Steps:  75%|███████▌  | 294/391 [2:50:17<54:51, 33.93s/it, lr=5e-5, step_loss=0.0422]Steps:  75%|███████▌  | 294/391 [2:50:25<54:51, 33.93s/it, lr=5e-5, step_loss=0.0629]Steps:  75%|███████▌  | 295/391 [2:50:32<53:12, 33.25s/it, lr=5e-5, step_loss=0.0629]Steps:  75%|███████▌  | 295/391 [2:50:32<53:12, 33.25s/it, lr=5e-5, step_loss=0.0562]Steps:  75%|███████▌  | 295/391 [2:50:40<53:12, 33.25s/it, lr=5e-5, step_loss=0.0474]Steps:  75%|███████▌  | 295/391 [2:50:49<53:12, 33.25s/it, lr=5e-5, step_loss=0.0424]Steps:  75%|███████▌  | 295/391 [2:50:57<53:12, 33.25s/it, lr=5e-5, step_loss=0.0425]Steps:  76%|███████▌  | 296/391 [2:51:06<52:50, 33.37s/it, lr=5e-5, step_loss=0.0425]Steps:  76%|███████▌  | 296/391 [2:51:06<52:50, 33.37s/it, lr=5e-5, step_loss=0.042] Steps:  76%|███████▌  | 296/391 [2:51:14<52:50, 33.37s/it, lr=5e-5, step_loss=0.0326]Steps:  76%|███████▌  | 296/391 [2:51:24<52:50, 33.37s/it, lr=5e-5, step_loss=0.0521]Steps:  76%|███████▌  | 296/391 [2:51:33<52:50, 33.37s/it, lr=5e-5, step_loss=0.0447]Steps:  76%|███████▌  | 297/391 [2:51:41<53:01, 33.85s/it, lr=5e-5, step_loss=0.0447]Steps:  76%|███████▌  | 297/391 [2:51:41<53:01, 33.85s/it, lr=5e-5, step_loss=0.037] Steps:  76%|███████▌  | 297/391 [2:51:49<53:01, 33.85s/it, lr=5e-5, step_loss=0.0495]Steps:  76%|███████▌  | 297/391 [2:51:58<53:01, 33.85s/it, lr=5e-5, step_loss=0.0415]Steps:  76%|███████▌  | 297/391 [2:52:07<53:01, 33.85s/it, lr=5e-5, step_loss=0.0451]Steps:  76%|███████▌  | 298/391 [2:52:15<52:43, 34.02s/it, lr=5e-5, step_loss=0.0451]Steps:  76%|███████▌  | 298/391 [2:52:15<52:43, 34.02s/it, lr=5e-5, step_loss=0.0359]Steps:  76%|███████▌  | 298/391 [2:52:24<52:43, 34.02s/it, lr=5e-5, step_loss=0.0719]Steps:  76%|███████▋  | 299/391 [2:52:25<40:47, 26.61s/it, lr=5e-5, step_loss=0.0719]Steps:  76%|███████▋  | 299/391 [2:52:25<40:47, 26.61s/it, lr=5e-5, step_loss=0.0403]Steps:  76%|███████▋  | 299/391 [2:52:40<40:47, 26.61s/it, lr=5e-5, step_loss=0.0337]Steps:  76%|███████▋  | 299/391 [2:52:49<40:47, 26.61s/it, lr=5e-5, step_loss=0.0551]Steps:  76%|███████▋  | 299/391 [2:52:57<40:47, 26.61s/it, lr=5e-5, step_loss=0.0334]Steps:  77%|███████▋  | 300/391 [2:53:04<46:07, 30.41s/it, lr=5e-5, step_loss=0.0334]06/08/2025 12:21:40 - INFO - __main__ - 1 checkpoints already exist, removing 1 checkpoints
06/08/2025 12:21:40 - INFO - __main__ - removing checkpoints: checkpoint-200
06/08/2025 12:21:40 - INFO - accelerate.accelerator - Saving current state to finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-300
Configuration saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-300/unet_ema/config.json
Model weights saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-300/unet_ema/diffusion_pytorch_model.safetensors
Configuration saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-300/unet/config.json
Model weights saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-300/unet/diffusion_pytorch_model.safetensors
06/08/2025 12:22:03 - INFO - accelerate.checkpointing - Optimizer state saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-300/optimizer.bin
06/08/2025 12:22:03 - INFO - accelerate.checkpointing - Scheduler state saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-300/scheduler.bin
06/08/2025 12:22:03 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-300/sampler.bin
06/08/2025 12:22:03 - INFO - accelerate.checkpointing - Gradient scaler state saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-300/scaler.pt
06/08/2025 12:22:03 - INFO - accelerate.checkpointing - Random states saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-300/random_states_0.pkl
06/08/2025 12:22:03 - INFO - __main__ - Saved state to finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-300
Steps:  77%|███████▋  | 300/391 [2:53:27<46:07, 30.41s/it, lr=5e-5, step_loss=0.058] Steps:  77%|███████▋  | 300/391 [2:53:35<46:07, 30.41s/it, lr=5e-5, step_loss=0.0319]Steps:  77%|███████▋  | 300/391 [2:53:42<46:07, 30.41s/it, lr=5e-5, step_loss=0.0336]Steps:  77%|███████▋  | 300/391 [2:53:50<46:07, 30.41s/it, lr=5e-5, step_loss=0.056] Steps:  77%|███████▋  | 301/391 [2:53:59<56:30, 37.67s/it, lr=5e-5, step_loss=0.056]Steps:  77%|███████▋  | 301/391 [2:53:59<56:30, 37.67s/it, lr=5e-5, step_loss=0.0398]Steps:  77%|███████▋  | 301/391 [2:54:07<56:30, 37.67s/it, lr=5e-5, step_loss=0.05]  Steps:  77%|███████▋  | 301/391 [2:54:15<56:30, 37.67s/it, lr=5e-5, step_loss=0.0413]Steps:  77%|███████▋  | 301/391 [2:54:24<56:30, 37.67s/it, lr=5e-5, step_loss=0.0551]Steps:  77%|███████▋  | 302/391 [2:54:32<53:54, 36.34s/it, lr=5e-5, step_loss=0.0551]Steps:  77%|███████▋  | 302/391 [2:54:32<53:54, 36.34s/it, lr=5e-5, step_loss=0.0441]Steps:  77%|███████▋  | 302/391 [2:54:40<53:54, 36.34s/it, lr=5e-5, step_loss=0.0376]Steps:  77%|███████▋  | 302/391 [2:54:48<53:54, 36.34s/it, lr=5e-5, step_loss=0.0401]Steps:  77%|███████▋  | 302/391 [2:54:56<53:54, 36.34s/it, lr=5e-5, step_loss=0.0382]Steps:  77%|███████▋  | 303/391 [2:55:03<51:04, 34.82s/it, lr=5e-5, step_loss=0.0382]Steps:  77%|███████▋  | 303/391 [2:55:03<51:04, 34.82s/it, lr=5e-5, step_loss=0.0341]Steps:  77%|███████▋  | 303/391 [2:55:12<51:04, 34.82s/it, lr=5e-5, step_loss=0.0478]Steps:  77%|███████▋  | 303/391 [2:55:21<51:04, 34.82s/it, lr=5e-5, step_loss=0.0249]Steps:  77%|███████▋  | 303/391 [2:55:29<51:04, 34.82s/it, lr=5e-5, step_loss=0.0738]Steps:  78%|███████▊  | 304/391 [2:55:37<50:09, 34.60s/it, lr=5e-5, step_loss=0.0738]Steps:  78%|███████▊  | 304/391 [2:55:37<50:09, 34.60s/it, lr=5e-5, step_loss=0.0429]Steps:  78%|███████▊  | 304/391 [2:55:46<50:09, 34.60s/it, lr=5e-5, step_loss=0.0583]Steps:  78%|███████▊  | 304/391 [2:55:54<50:09, 34.60s/it, lr=5e-5, step_loss=0.0458]Steps:  78%|███████▊  | 304/391 [2:56:02<50:09, 34.60s/it, lr=5e-5, step_loss=0.0282]Steps:  78%|███████▊  | 305/391 [2:56:10<48:55, 34.14s/it, lr=5e-5, step_loss=0.0282]Steps:  78%|███████▊  | 305/391 [2:56:10<48:55, 34.14s/it, lr=5e-5, step_loss=0.0681]Steps:  78%|███████▊  | 305/391 [2:56:19<48:55, 34.14s/it, lr=5e-5, step_loss=0.041] Steps:  78%|███████▊  | 305/391 [2:56:27<48:55, 34.14s/it, lr=5e-5, step_loss=0.0409]Steps:  78%|███████▊  | 305/391 [2:56:36<48:55, 34.14s/it, lr=5e-5, step_loss=0.0667]Steps:  78%|███████▊  | 306/391 [2:56:45<48:26, 34.19s/it, lr=5e-5, step_loss=0.0667]Steps:  78%|███████▊  | 306/391 [2:56:45<48:26, 34.19s/it, lr=5e-5, step_loss=0.0411]Steps:  78%|███████▊  | 306/391 [2:56:53<48:26, 34.19s/it, lr=5e-5, step_loss=0.0552]Steps:  78%|███████▊  | 306/391 [2:57:02<48:26, 34.19s/it, lr=5e-5, step_loss=0.0555]Steps:  78%|███████▊  | 306/391 [2:57:11<48:26, 34.19s/it, lr=5e-5, step_loss=0.0669]Steps:  79%|███████▊  | 307/391 [2:57:20<48:22, 34.56s/it, lr=5e-5, step_loss=0.0669]Steps:  79%|███████▊  | 307/391 [2:57:20<48:22, 34.56s/it, lr=5e-5, step_loss=0.0594]Steps:  79%|███████▊  | 307/391 [2:57:28<48:22, 34.56s/it, lr=5e-5, step_loss=0.0396]Steps:  79%|███████▊  | 307/391 [2:57:38<48:22, 34.56s/it, lr=5e-5, step_loss=0.0502]Steps:  79%|███████▊  | 307/391 [2:57:47<48:22, 34.56s/it, lr=5e-5, step_loss=0.0345]Steps:  79%|███████▉  | 308/391 [2:57:55<48:10, 34.83s/it, lr=5e-5, step_loss=0.0345]Steps:  79%|███████▉  | 308/391 [2:57:55<48:10, 34.83s/it, lr=5e-5, step_loss=0.0636]Steps:  79%|███████▉  | 308/391 [2:58:03<48:10, 34.83s/it, lr=5e-5, step_loss=0.0521]Steps:  79%|███████▉  | 308/391 [2:58:12<48:10, 34.83s/it, lr=5e-5, step_loss=0.0284]Steps:  79%|███████▉  | 308/391 [2:58:22<48:10, 34.83s/it, lr=5e-5, step_loss=0.034] Steps:  79%|███████▉  | 309/391 [2:58:31<47:43, 34.92s/it, lr=5e-5, step_loss=0.034]Steps:  79%|███████▉  | 309/391 [2:58:31<47:43, 34.92s/it, lr=5e-5, step_loss=0.0697]Steps:  79%|███████▉  | 309/391 [2:58:40<47:43, 34.92s/it, lr=5e-5, step_loss=0.0466]Steps:  79%|███████▉  | 309/391 [2:58:48<47:43, 34.92s/it, lr=5e-5, step_loss=0.0419]Steps:  79%|███████▉  | 309/391 [2:58:56<47:43, 34.92s/it, lr=5e-5, step_loss=0.0428]Steps:  79%|███████▉  | 310/391 [2:59:05<46:50, 34.70s/it, lr=5e-5, step_loss=0.0428]Steps:  79%|███████▉  | 310/391 [2:59:05<46:50, 34.70s/it, lr=5e-5, step_loss=0.0328]Steps:  79%|███████▉  | 310/391 [2:59:13<46:50, 34.70s/it, lr=5e-5, step_loss=0.0507]Steps:  79%|███████▉  | 310/391 [2:59:21<46:50, 34.70s/it, lr=5e-5, step_loss=0.0484]Steps:  79%|███████▉  | 310/391 [2:59:28<46:50, 34.70s/it, lr=5e-5, step_loss=0.0435]Steps:  80%|███████▉  | 311/391 [2:59:36<44:48, 33.60s/it, lr=5e-5, step_loss=0.0435]Steps:  80%|███████▉  | 311/391 [2:59:36<44:48, 33.60s/it, lr=5e-5, step_loss=0.0645]Steps:  80%|███████▉  | 311/391 [2:59:44<44:48, 33.60s/it, lr=5e-5, step_loss=0.051] Steps:  80%|███████▉  | 311/391 [2:59:51<44:48, 33.60s/it, lr=5e-5, step_loss=0.0426]Steps:  80%|███████▉  | 311/391 [3:00:00<44:48, 33.60s/it, lr=5e-5, step_loss=0.0486]Steps:  80%|███████▉  | 312/391 [3:00:08<43:47, 33.26s/it, lr=5e-5, step_loss=0.0486]Steps:  80%|███████▉  | 312/391 [3:00:08<43:47, 33.26s/it, lr=5e-5, step_loss=0.0373]Steps:  80%|███████▉  | 312/391 [3:00:17<43:47, 33.26s/it, lr=5e-5, step_loss=0.0466]Steps:  80%|███████▉  | 312/391 [3:00:26<43:47, 33.26s/it, lr=5e-5, step_loss=0.0451]Steps:  80%|███████▉  | 312/391 [3:00:34<43:47, 33.26s/it, lr=5e-5, step_loss=0.0337]Steps:  80%|████████  | 313/391 [3:00:42<43:23, 33.38s/it, lr=5e-5, step_loss=0.0337]Steps:  80%|████████  | 313/391 [3:00:42<43:23, 33.38s/it, lr=5e-5, step_loss=0.0531]Steps:  80%|████████  | 313/391 [3:00:50<43:23, 33.38s/it, lr=5e-5, step_loss=0.0321]Steps:  80%|████████  | 313/391 [3:00:57<43:23, 33.38s/it, lr=5e-5, step_loss=0.0398]Steps:  80%|████████  | 313/391 [3:01:05<43:23, 33.38s/it, lr=5e-5, step_loss=0.0396]Steps:  80%|████████  | 314/391 [3:01:13<41:49, 32.59s/it, lr=5e-5, step_loss=0.0396]Steps:  80%|████████  | 314/391 [3:01:13<41:49, 32.59s/it, lr=5e-5, step_loss=0.0371]Steps:  80%|████████  | 314/391 [3:01:22<41:49, 32.59s/it, lr=5e-5, step_loss=0.0522]Steps:  80%|████████  | 314/391 [3:01:31<41:49, 32.59s/it, lr=5e-5, step_loss=0.0515]Steps:  80%|████████  | 314/391 [3:01:40<41:49, 32.59s/it, lr=5e-5, step_loss=0.0696]Steps:  81%|████████  | 315/391 [3:01:48<42:15, 33.37s/it, lr=5e-5, step_loss=0.0696]Steps:  81%|████████  | 315/391 [3:01:48<42:15, 33.37s/it, lr=5e-5, step_loss=0.0543]Steps:  81%|████████  | 315/391 [3:01:56<42:15, 33.37s/it, lr=5e-5, step_loss=0.0583]Steps:  81%|████████  | 315/391 [3:02:05<42:15, 33.37s/it, lr=5e-5, step_loss=0.0555]Steps:  81%|████████  | 315/391 [3:02:15<42:15, 33.37s/it, lr=5e-5, step_loss=0.0251]Steps:  81%|████████  | 316/391 [3:02:24<42:46, 34.21s/it, lr=5e-5, step_loss=0.0251]Steps:  81%|████████  | 316/391 [3:02:24<42:46, 34.21s/it, lr=5e-5, step_loss=0.0526]Steps:  81%|████████  | 316/391 [3:02:33<42:46, 34.21s/it, lr=5e-5, step_loss=0.0335]Steps:  81%|████████  | 316/391 [3:02:42<42:46, 34.21s/it, lr=5e-5, step_loss=0.0548]Steps:  81%|████████  | 316/391 [3:02:50<42:46, 34.21s/it, lr=5e-5, step_loss=0.0619]Steps:  81%|████████  | 317/391 [3:02:58<42:15, 34.26s/it, lr=5e-5, step_loss=0.0619]Steps:  81%|████████  | 317/391 [3:02:58<42:15, 34.26s/it, lr=5e-5, step_loss=0.062] Steps:  81%|████████  | 317/391 [3:03:08<42:15, 34.26s/it, lr=5e-5, step_loss=0.0419]Steps:  81%|████████  | 317/391 [3:03:16<42:15, 34.26s/it, lr=5e-5, step_loss=0.0576]Steps:  81%|████████  | 317/391 [3:03:25<42:15, 34.26s/it, lr=5e-5, step_loss=0.0342]Steps:  81%|████████▏ | 318/391 [3:03:34<42:13, 34.71s/it, lr=5e-5, step_loss=0.0342]Steps:  81%|████████▏ | 318/391 [3:03:34<42:13, 34.71s/it, lr=5e-5, step_loss=0.0534]Steps:  81%|████████▏ | 318/391 [3:03:43<42:13, 34.71s/it, lr=5e-5, step_loss=0.0232]Steps:  81%|████████▏ | 318/391 [3:03:50<42:13, 34.71s/it, lr=5e-5, step_loss=0.053] Steps:  81%|████████▏ | 318/391 [3:03:59<42:13, 34.71s/it, lr=5e-5, step_loss=0.0522]Steps:  82%|████████▏ | 319/391 [3:04:07<40:50, 34.03s/it, lr=5e-5, step_loss=0.0522]Steps:  82%|████████▏ | 319/391 [3:04:07<40:50, 34.03s/it, lr=5e-5, step_loss=0.0516]Steps:  82%|████████▏ | 319/391 [3:04:15<40:50, 34.03s/it, lr=5e-5, step_loss=0.0552]Steps:  82%|████████▏ | 319/391 [3:04:24<40:50, 34.03s/it, lr=5e-5, step_loss=0.045] Steps:  82%|████████▏ | 319/391 [3:04:32<40:50, 34.03s/it, lr=5e-5, step_loss=0.0611]Steps:  82%|████████▏ | 320/391 [3:04:40<40:10, 33.95s/it, lr=5e-5, step_loss=0.0611]Steps:  82%|████████▏ | 320/391 [3:04:40<40:10, 33.95s/it, lr=5e-5, step_loss=0.0429]Steps:  82%|████████▏ | 320/391 [3:04:48<40:10, 33.95s/it, lr=5e-5, step_loss=0.0475]Steps:  82%|████████▏ | 320/391 [3:04:56<40:10, 33.95s/it, lr=5e-5, step_loss=0.0431]Steps:  82%|████████▏ | 320/391 [3:05:05<40:10, 33.95s/it, lr=5e-5, step_loss=0.037] Steps:  82%|████████▏ | 321/391 [3:05:13<39:04, 33.49s/it, lr=5e-5, step_loss=0.037]Steps:  82%|████████▏ | 321/391 [3:05:13<39:04, 33.49s/it, lr=5e-5, step_loss=0.0475]Steps:  82%|████████▏ | 321/391 [3:05:20<39:04, 33.49s/it, lr=5e-5, step_loss=0.0514]Steps:  82%|████████▏ | 322/391 [3:05:21<29:46, 25.89s/it, lr=5e-5, step_loss=0.0514]Steps:  82%|████████▏ | 322/391 [3:05:21<29:46, 25.89s/it, lr=5e-5, step_loss=0.0554]Steps:  82%|████████▏ | 322/391 [3:05:36<29:46, 25.89s/it, lr=5e-5, step_loss=0.0352]Steps:  82%|████████▏ | 322/391 [3:05:43<29:46, 25.89s/it, lr=5e-5, step_loss=0.0392]Steps:  82%|████████▏ | 322/391 [3:05:52<29:46, 25.89s/it, lr=5e-5, step_loss=0.0489]Steps:  83%|████████▎ | 323/391 [3:06:00<33:53, 29.90s/it, lr=5e-5, step_loss=0.0489]Steps:  83%|████████▎ | 323/391 [3:06:00<33:53, 29.90s/it, lr=5e-5, step_loss=0.0436]Steps:  83%|████████▎ | 323/391 [3:06:08<33:53, 29.90s/it, lr=5e-5, step_loss=0.0321]Steps:  83%|████████▎ | 323/391 [3:06:16<33:53, 29.90s/it, lr=5e-5, step_loss=0.0475]Steps:  83%|████████▎ | 323/391 [3:06:24<33:53, 29.90s/it, lr=5e-5, step_loss=0.0392]Steps:  83%|████████▎ | 324/391 [3:06:33<34:15, 30.68s/it, lr=5e-5, step_loss=0.0392]Steps:  83%|████████▎ | 324/391 [3:06:33<34:15, 30.68s/it, lr=5e-5, step_loss=0.0462]Steps:  83%|████████▎ | 324/391 [3:06:41<34:15, 30.68s/it, lr=5e-5, step_loss=0.0542]Steps:  83%|████████▎ | 324/391 [3:06:49<34:15, 30.68s/it, lr=5e-5, step_loss=0.0562]Steps:  83%|████████▎ | 324/391 [3:06:57<34:15, 30.68s/it, lr=5e-5, step_loss=0.0246]Steps:  83%|████████▎ | 325/391 [3:07:06<34:31, 31.39s/it, lr=5e-5, step_loss=0.0246]Steps:  83%|████████▎ | 325/391 [3:07:06<34:31, 31.39s/it, lr=5e-5, step_loss=0.0412]Steps:  83%|████████▎ | 325/391 [3:07:14<34:31, 31.39s/it, lr=5e-5, step_loss=0.0484]Steps:  83%|████████▎ | 325/391 [3:07:24<34:31, 31.39s/it, lr=5e-5, step_loss=0.0403]Steps:  83%|████████▎ | 325/391 [3:07:32<34:31, 31.39s/it, lr=5e-5, step_loss=0.054] Steps:  83%|████████▎ | 326/391 [3:07:42<35:29, 32.76s/it, lr=5e-5, step_loss=0.054]Steps:  83%|████████▎ | 326/391 [3:07:42<35:29, 32.76s/it, lr=5e-5, step_loss=0.0522]Steps:  83%|████████▎ | 326/391 [3:07:50<35:29, 32.76s/it, lr=5e-5, step_loss=0.0578]Steps:  83%|████████▎ | 326/391 [3:07:59<35:29, 32.76s/it, lr=5e-5, step_loss=0.0392]Steps:  83%|████████▎ | 326/391 [3:08:08<35:29, 32.76s/it, lr=5e-5, step_loss=0.0469]Steps:  84%|████████▎ | 327/391 [3:08:18<36:03, 33.80s/it, lr=5e-5, step_loss=0.0469]Steps:  84%|████████▎ | 327/391 [3:08:18<36:03, 33.80s/it, lr=5e-5, step_loss=0.0454]Steps:  84%|████████▎ | 327/391 [3:08:27<36:03, 33.80s/it, lr=5e-5, step_loss=0.0511]Steps:  84%|████████▎ | 327/391 [3:08:35<36:03, 33.80s/it, lr=5e-5, step_loss=0.0575]Steps:  84%|████████▎ | 327/391 [3:08:44<36:03, 33.80s/it, lr=5e-5, step_loss=0.0532]Steps:  84%|████████▍ | 328/391 [3:08:53<35:44, 34.04s/it, lr=5e-5, step_loss=0.0532]Steps:  84%|████████▍ | 328/391 [3:08:53<35:44, 34.04s/it, lr=5e-5, step_loss=0.0527]Steps:  84%|████████▍ | 328/391 [3:09:01<35:44, 34.04s/it, lr=5e-5, step_loss=0.0513]Steps:  84%|████████▍ | 328/391 [3:09:09<35:44, 34.04s/it, lr=5e-5, step_loss=0.0451]Steps:  84%|████████▍ | 328/391 [3:09:18<35:44, 34.04s/it, lr=5e-5, step_loss=0.0422]Steps:  84%|████████▍ | 329/391 [3:09:27<35:14, 34.10s/it, lr=5e-5, step_loss=0.0422]Steps:  84%|████████▍ | 329/391 [3:09:27<35:14, 34.10s/it, lr=5e-5, step_loss=0.0468]Steps:  84%|████████▍ | 329/391 [3:09:35<35:14, 34.10s/it, lr=5e-5, step_loss=0.0477]Steps:  84%|████████▍ | 329/391 [3:09:43<35:14, 34.10s/it, lr=5e-5, step_loss=0.0389]Steps:  84%|████████▍ | 329/391 [3:09:51<35:14, 34.10s/it, lr=5e-5, step_loss=0.0416]Steps:  84%|████████▍ | 330/391 [3:10:00<34:29, 33.93s/it, lr=5e-5, step_loss=0.0416]Steps:  84%|████████▍ | 330/391 [3:10:00<34:29, 33.93s/it, lr=5e-5, step_loss=0.05]  Steps:  84%|████████▍ | 330/391 [3:10:08<34:29, 33.93s/it, lr=5e-5, step_loss=0.0287]Steps:  84%|████████▍ | 330/391 [3:10:17<34:29, 33.93s/it, lr=5e-5, step_loss=0.0392]Steps:  84%|████████▍ | 330/391 [3:10:25<34:29, 33.93s/it, lr=5e-5, step_loss=0.0498]Steps:  85%|████████▍ | 331/391 [3:10:34<33:52, 33.88s/it, lr=5e-5, step_loss=0.0498]Steps:  85%|████████▍ | 331/391 [3:10:34<33:52, 33.88s/it, lr=5e-5, step_loss=0.0393]Steps:  85%|████████▍ | 331/391 [3:10:43<33:52, 33.88s/it, lr=5e-5, step_loss=0.0331]Steps:  85%|████████▍ | 331/391 [3:10:51<33:52, 33.88s/it, lr=5e-5, step_loss=0.0324]Steps:  85%|████████▍ | 331/391 [3:10:59<33:52, 33.88s/it, lr=5e-5, step_loss=0.0245]Steps:  85%|████████▍ | 332/391 [3:11:07<32:54, 33.46s/it, lr=5e-5, step_loss=0.0245]Steps:  85%|████████▍ | 332/391 [3:11:07<32:54, 33.46s/it, lr=5e-5, step_loss=0.0511]Steps:  85%|████████▍ | 332/391 [3:11:15<32:54, 33.46s/it, lr=5e-5, step_loss=0.0635]Steps:  85%|████████▍ | 332/391 [3:11:24<32:54, 33.46s/it, lr=5e-5, step_loss=0.0634]Steps:  85%|████████▍ | 332/391 [3:11:33<32:54, 33.46s/it, lr=5e-5, step_loss=0.0433]Steps:  85%|████████▌ | 333/391 [3:11:43<33:05, 34.24s/it, lr=5e-5, step_loss=0.0433]Steps:  85%|████████▌ | 333/391 [3:11:43<33:05, 34.24s/it, lr=5e-5, step_loss=0.0256]Steps:  85%|████████▌ | 333/391 [3:11:51<33:05, 34.24s/it, lr=5e-5, step_loss=0.0681]Steps:  85%|████████▌ | 333/391 [3:12:00<33:05, 34.24s/it, lr=5e-5, step_loss=0.0598]Steps:  85%|████████▌ | 333/391 [3:12:09<33:05, 34.24s/it, lr=5e-5, step_loss=0.0461]Steps:  85%|████████▌ | 334/391 [3:12:17<32:34, 34.29s/it, lr=5e-5, step_loss=0.0461]Steps:  85%|████████▌ | 334/391 [3:12:17<32:34, 34.29s/it, lr=5e-5, step_loss=0.0552]Steps:  85%|████████▌ | 334/391 [3:12:26<32:34, 34.29s/it, lr=5e-5, step_loss=0.0647]Steps:  85%|████████▌ | 334/391 [3:12:34<32:34, 34.29s/it, lr=5e-5, step_loss=0.0457]Steps:  85%|████████▌ | 334/391 [3:12:42<32:34, 34.29s/it, lr=5e-5, step_loss=0.0478]Steps:  86%|████████▌ | 335/391 [3:12:50<31:38, 33.89s/it, lr=5e-5, step_loss=0.0478]Steps:  86%|████████▌ | 335/391 [3:12:50<31:38, 33.89s/it, lr=5e-5, step_loss=0.0377]Steps:  86%|████████▌ | 335/391 [3:12:58<31:38, 33.89s/it, lr=5e-5, step_loss=0.036] Steps:  86%|████████▌ | 335/391 [3:13:06<31:38, 33.89s/it, lr=5e-5, step_loss=0.0291]Steps:  86%|████████▌ | 335/391 [3:13:15<31:38, 33.89s/it, lr=5e-5, step_loss=0.0348]Steps:  86%|████████▌ | 336/391 [3:13:23<30:54, 33.72s/it, lr=5e-5, step_loss=0.0348]Steps:  86%|████████▌ | 336/391 [3:13:23<30:54, 33.72s/it, lr=5e-5, step_loss=0.0418]Steps:  86%|████████▌ | 336/391 [3:13:32<30:54, 33.72s/it, lr=5e-5, step_loss=0.0449]Steps:  86%|████████▌ | 336/391 [3:13:41<30:54, 33.72s/it, lr=5e-5, step_loss=0.0393]Steps:  86%|████████▌ | 336/391 [3:13:48<30:54, 33.72s/it, lr=5e-5, step_loss=0.0664]Steps:  86%|████████▌ | 337/391 [3:13:57<30:19, 33.69s/it, lr=5e-5, step_loss=0.0664]Steps:  86%|████████▌ | 337/391 [3:13:57<30:19, 33.69s/it, lr=5e-5, step_loss=0.0442]Steps:  86%|████████▌ | 337/391 [3:14:04<30:19, 33.69s/it, lr=5e-5, step_loss=0.0733]Steps:  86%|████████▌ | 337/391 [3:14:13<30:19, 33.69s/it, lr=5e-5, step_loss=0.0416]Steps:  86%|████████▌ | 337/391 [3:14:21<30:19, 33.69s/it, lr=5e-5, step_loss=0.0672]Steps:  86%|████████▋ | 338/391 [3:14:29<29:21, 33.24s/it, lr=5e-5, step_loss=0.0672]Steps:  86%|████████▋ | 338/391 [3:14:29<29:21, 33.24s/it, lr=5e-5, step_loss=0.0598]Steps:  86%|████████▋ | 338/391 [3:14:37<29:21, 33.24s/it, lr=5e-5, step_loss=0.0534]Steps:  86%|████████▋ | 338/391 [3:14:46<29:21, 33.24s/it, lr=5e-5, step_loss=0.0398]Steps:  86%|████████▋ | 338/391 [3:14:54<29:21, 33.24s/it, lr=5e-5, step_loss=0.0346]Steps:  87%|████████▋ | 339/391 [3:15:04<29:15, 33.76s/it, lr=5e-5, step_loss=0.0346]Steps:  87%|████████▋ | 339/391 [3:15:04<29:15, 33.76s/it, lr=5e-5, step_loss=0.0434]Steps:  87%|████████▋ | 339/391 [3:15:13<29:15, 33.76s/it, lr=5e-5, step_loss=0.0631]Steps:  87%|████████▋ | 339/391 [3:15:21<29:15, 33.76s/it, lr=5e-5, step_loss=0.035] Steps:  87%|████████▋ | 339/391 [3:15:30<29:15, 33.76s/it, lr=5e-5, step_loss=0.0373]Steps:  87%|████████▋ | 340/391 [3:15:38<28:43, 33.80s/it, lr=5e-5, step_loss=0.0373]Steps:  87%|████████▋ | 340/391 [3:15:38<28:43, 33.80s/it, lr=5e-5, step_loss=0.0655]Steps:  87%|████████▋ | 340/391 [3:15:46<28:43, 33.80s/it, lr=5e-5, step_loss=0.0647]Steps:  87%|████████▋ | 340/391 [3:15:54<28:43, 33.80s/it, lr=5e-5, step_loss=0.0386]Steps:  87%|████████▋ | 340/391 [3:16:02<28:43, 33.80s/it, lr=5e-5, step_loss=0.0433]Steps:  87%|████████▋ | 341/391 [3:16:10<27:37, 33.15s/it, lr=5e-5, step_loss=0.0433]Steps:  87%|████████▋ | 341/391 [3:16:10<27:37, 33.15s/it, lr=5e-5, step_loss=0.0523]Steps:  87%|████████▋ | 341/391 [3:16:18<27:37, 33.15s/it, lr=5e-5, step_loss=0.0389]Steps:  87%|████████▋ | 341/391 [3:16:26<27:37, 33.15s/it, lr=5e-5, step_loss=0.0645]Steps:  87%|████████▋ | 341/391 [3:16:35<27:37, 33.15s/it, lr=5e-5, step_loss=0.0452]Steps:  87%|████████▋ | 342/391 [3:16:43<27:10, 33.27s/it, lr=5e-5, step_loss=0.0452]Steps:  87%|████████▋ | 342/391 [3:16:43<27:10, 33.27s/it, lr=5e-5, step_loss=0.0614]Steps:  87%|████████▋ | 342/391 [3:16:52<27:10, 33.27s/it, lr=5e-5, step_loss=0.0395]Steps:  87%|████████▋ | 342/391 [3:17:00<27:10, 33.27s/it, lr=5e-5, step_loss=0.0394]Steps:  87%|████████▋ | 342/391 [3:17:08<27:10, 33.27s/it, lr=5e-5, step_loss=0.0473]Steps:  88%|████████▊ | 343/391 [3:17:17<26:44, 33.43s/it, lr=5e-5, step_loss=0.0473]Steps:  88%|████████▊ | 343/391 [3:17:17<26:44, 33.43s/it, lr=5e-5, step_loss=0.0497]Steps:  88%|████████▊ | 343/391 [3:17:25<26:44, 33.43s/it, lr=5e-5, step_loss=0.0296]Steps:  88%|████████▊ | 343/391 [3:17:32<26:44, 33.43s/it, lr=5e-5, step_loss=0.0721]Steps:  88%|████████▊ | 343/391 [3:17:40<26:44, 33.43s/it, lr=5e-5, step_loss=0.0482]Steps:  88%|████████▊ | 344/391 [3:17:48<25:35, 32.66s/it, lr=5e-5, step_loss=0.0482]Steps:  88%|████████▊ | 344/391 [3:17:48<25:35, 32.66s/it, lr=5e-5, step_loss=0.0398]Steps:  88%|████████▊ | 344/391 [3:17:54<25:35, 32.66s/it, lr=5e-5, step_loss=0.0537]Steps:  88%|████████▊ | 345/391 [3:17:55<19:11, 25.03s/it, lr=5e-5, step_loss=0.0537]Steps:  88%|████████▊ | 345/391 [3:17:55<19:11, 25.03s/it, lr=5e-5, step_loss=0.0348]Steps:  88%|████████▊ | 345/391 [3:18:10<19:11, 25.03s/it, lr=5e-5, step_loss=0.0281]Steps:  88%|████████▊ | 345/391 [3:18:18<19:11, 25.03s/it, lr=5e-5, step_loss=0.053] Steps:  88%|████████▊ | 345/391 [3:18:25<19:11, 25.03s/it, lr=5e-5, step_loss=0.048]Steps:  88%|████████▊ | 346/391 [3:18:34<21:53, 29.20s/it, lr=5e-5, step_loss=0.048]Steps:  88%|████████▊ | 346/391 [3:18:34<21:53, 29.20s/it, lr=5e-5, step_loss=0.0511]Steps:  88%|████████▊ | 346/391 [3:18:42<21:53, 29.20s/it, lr=5e-5, step_loss=0.0505]Steps:  88%|████████▊ | 346/391 [3:18:51<21:53, 29.20s/it, lr=5e-5, step_loss=0.0577]Steps:  88%|████████▊ | 346/391 [3:18:59<21:53, 29.20s/it, lr=5e-5, step_loss=0.0318]Steps:  89%|████████▊ | 347/391 [3:19:06<22:02, 30.06s/it, lr=5e-5, step_loss=0.0318]Steps:  89%|████████▊ | 347/391 [3:19:06<22:02, 30.06s/it, lr=5e-5, step_loss=0.0536]Steps:  89%|████████▊ | 347/391 [3:19:14<22:02, 30.06s/it, lr=5e-5, step_loss=0.0351]Steps:  89%|████████▊ | 347/391 [3:19:22<22:02, 30.06s/it, lr=5e-5, step_loss=0.088] Steps:  89%|████████▊ | 347/391 [3:19:29<22:02, 30.06s/it, lr=5e-5, step_loss=0.0392]Steps:  89%|████████▉ | 348/391 [3:19:38<22:01, 30.72s/it, lr=5e-5, step_loss=0.0392]Steps:  89%|████████▉ | 348/391 [3:19:38<22:01, 30.72s/it, lr=5e-5, step_loss=0.0574]Steps:  89%|████████▉ | 348/391 [3:19:46<22:01, 30.72s/it, lr=5e-5, step_loss=0.0384]Steps:  89%|████████▉ | 348/391 [3:19:54<22:01, 30.72s/it, lr=5e-5, step_loss=0.0525]Steps:  89%|████████▉ | 348/391 [3:20:02<22:01, 30.72s/it, lr=5e-5, step_loss=0.0538]Steps:  89%|████████▉ | 349/391 [3:20:10<21:46, 31.11s/it, lr=5e-5, step_loss=0.0538]Steps:  89%|████████▉ | 349/391 [3:20:10<21:46, 31.11s/it, lr=5e-5, step_loss=0.0513]Steps:  89%|████████▉ | 349/391 [3:20:18<21:46, 31.11s/it, lr=5e-5, step_loss=0.0417]Steps:  89%|████████▉ | 349/391 [3:20:26<21:46, 31.11s/it, lr=5e-5, step_loss=0.0546]Steps:  89%|████████▉ | 349/391 [3:20:34<21:46, 31.11s/it, lr=5e-5, step_loss=0.0483]Steps:  90%|████████▉ | 350/391 [3:20:43<21:32, 31.52s/it, lr=5e-5, step_loss=0.0483]Steps:  90%|████████▉ | 350/391 [3:20:43<21:32, 31.52s/it, lr=5e-5, step_loss=0.0518]Steps:  90%|████████▉ | 350/391 [3:20:51<21:32, 31.52s/it, lr=5e-5, step_loss=0.0318]Steps:  90%|████████▉ | 350/391 [3:20:58<21:32, 31.52s/it, lr=5e-5, step_loss=0.0475]Steps:  90%|████████▉ | 350/391 [3:21:06<21:32, 31.52s/it, lr=5e-5, step_loss=0.0302]Steps:  90%|████████▉ | 351/391 [3:21:14<20:57, 31.43s/it, lr=5e-5, step_loss=0.0302]Steps:  90%|████████▉ | 351/391 [3:21:14<20:57, 31.43s/it, lr=5e-5, step_loss=0.051] Steps:  90%|████████▉ | 351/391 [3:21:23<20:57, 31.43s/it, lr=5e-5, step_loss=0.0438]Steps:  90%|████████▉ | 351/391 [3:21:31<20:57, 31.43s/it, lr=5e-5, step_loss=0.0564]Steps:  90%|████████▉ | 351/391 [3:21:39<20:57, 31.43s/it, lr=5e-5, step_loss=0.0367]Steps:  90%|█████████ | 352/391 [3:21:47<20:48, 32.02s/it, lr=5e-5, step_loss=0.0367]Steps:  90%|█████████ | 352/391 [3:21:47<20:48, 32.02s/it, lr=5e-5, step_loss=0.0416]Steps:  90%|█████████ | 352/391 [3:21:55<20:48, 32.02s/it, lr=5e-5, step_loss=0.0478]Steps:  90%|█████████ | 352/391 [3:22:04<20:48, 32.02s/it, lr=5e-5, step_loss=0.0365]Steps:  90%|█████████ | 352/391 [3:22:12<20:48, 32.02s/it, lr=5e-5, step_loss=0.046] Steps:  90%|█████████ | 353/391 [3:22:21<20:30, 32.37s/it, lr=5e-5, step_loss=0.046]Steps:  90%|█████████ | 353/391 [3:22:21<20:30, 32.37s/it, lr=5e-5, step_loss=0.0387]Steps:  90%|█████████ | 353/391 [3:22:29<20:30, 32.37s/it, lr=5e-5, step_loss=0.046] Steps:  90%|█████████ | 353/391 [3:22:38<20:30, 32.37s/it, lr=5e-5, step_loss=0.0332]Steps:  90%|█████████ | 353/391 [3:22:46<20:30, 32.37s/it, lr=5e-5, step_loss=0.059] Steps:  91%|█████████ | 354/391 [3:22:55<20:15, 32.85s/it, lr=5e-5, step_loss=0.059]Steps:  91%|█████████ | 354/391 [3:22:55<20:15, 32.85s/it, lr=5e-5, step_loss=0.0189]Steps:  91%|█████████ | 354/391 [3:23:03<20:15, 32.85s/it, lr=5e-5, step_loss=0.0573]Steps:  91%|█████████ | 354/391 [3:23:12<20:15, 32.85s/it, lr=5e-5, step_loss=0.0674]Steps:  91%|█████████ | 354/391 [3:23:20<20:15, 32.85s/it, lr=5e-5, step_loss=0.0336]Steps:  91%|█████████ | 355/391 [3:23:28<19:47, 32.98s/it, lr=5e-5, step_loss=0.0336]Steps:  91%|█████████ | 355/391 [3:23:28<19:47, 32.98s/it, lr=5e-5, step_loss=0.044] Steps:  91%|█████████ | 355/391 [3:23:36<19:47, 32.98s/it, lr=5e-5, step_loss=0.0454]Steps:  91%|█████████ | 355/391 [3:23:43<19:47, 32.98s/it, lr=5e-5, step_loss=0.0413]Steps:  91%|█████████ | 355/391 [3:23:52<19:47, 32.98s/it, lr=5e-5, step_loss=0.04]  Steps:  91%|█████████ | 356/391 [3:24:00<19:10, 32.87s/it, lr=5e-5, step_loss=0.04]Steps:  91%|█████████ | 356/391 [3:24:00<19:10, 32.87s/it, lr=5e-5, step_loss=0.056]Steps:  91%|█████████ | 356/391 [3:24:09<19:10, 32.87s/it, lr=5e-5, step_loss=0.0322]Steps:  91%|█████████ | 356/391 [3:24:17<19:10, 32.87s/it, lr=5e-5, step_loss=0.0639]Steps:  91%|█████████ | 356/391 [3:24:26<19:10, 32.87s/it, lr=5e-5, step_loss=0.0407]Steps:  91%|█████████▏| 357/391 [3:24:34<18:42, 33.03s/it, lr=5e-5, step_loss=0.0407]Steps:  91%|█████████▏| 357/391 [3:24:34<18:42, 33.03s/it, lr=5e-5, step_loss=0.0586]Steps:  91%|█████████▏| 357/391 [3:24:42<18:42, 33.03s/it, lr=5e-5, step_loss=0.0287]Steps:  91%|█████████▏| 357/391 [3:24:50<18:42, 33.03s/it, lr=5e-5, step_loss=0.0601]Steps:  91%|█████████▏| 357/391 [3:24:59<18:42, 33.03s/it, lr=5e-5, step_loss=0.0446]Steps:  92%|█████████▏| 358/391 [3:25:08<18:22, 33.41s/it, lr=5e-5, step_loss=0.0446]Steps:  92%|█████████▏| 358/391 [3:25:08<18:22, 33.41s/it, lr=5e-5, step_loss=0.0523]Steps:  92%|█████████▏| 358/391 [3:25:16<18:22, 33.41s/it, lr=5e-5, step_loss=0.0578]Steps:  92%|█████████▏| 358/391 [3:25:24<18:22, 33.41s/it, lr=5e-5, step_loss=0.0246]Steps:  92%|█████████▏| 358/391 [3:25:32<18:22, 33.41s/it, lr=5e-5, step_loss=0.0561]Steps:  92%|█████████▏| 359/391 [3:25:40<17:38, 33.08s/it, lr=5e-5, step_loss=0.0561]Steps:  92%|█████████▏| 359/391 [3:25:40<17:38, 33.08s/it, lr=5e-5, step_loss=0.0339]Steps:  92%|█████████▏| 359/391 [3:25:49<17:38, 33.08s/it, lr=5e-5, step_loss=0.0383]Steps:  92%|█████████▏| 359/391 [3:25:59<17:38, 33.08s/it, lr=5e-5, step_loss=0.065] Steps:  92%|█████████▏| 359/391 [3:26:07<17:38, 33.08s/it, lr=5e-5, step_loss=0.0511]Steps:  92%|█████████▏| 360/391 [3:26:16<17:25, 33.73s/it, lr=5e-5, step_loss=0.0511]Steps:  92%|█████████▏| 360/391 [3:26:16<17:25, 33.73s/it, lr=5e-5, step_loss=0.0473]Steps:  92%|█████████▏| 360/391 [3:26:24<17:25, 33.73s/it, lr=5e-5, step_loss=0.0525]Steps:  92%|█████████▏| 360/391 [3:26:33<17:25, 33.73s/it, lr=5e-5, step_loss=0.0425]Steps:  92%|█████████▏| 360/391 [3:26:42<17:25, 33.73s/it, lr=5e-5, step_loss=0.043] Steps:  92%|█████████▏| 361/391 [3:26:51<17:06, 34.21s/it, lr=5e-5, step_loss=0.043]Steps:  92%|█████████▏| 361/391 [3:26:51<17:06, 34.21s/it, lr=5e-5, step_loss=0.0487]Steps:  92%|█████████▏| 361/391 [3:26:58<17:06, 34.21s/it, lr=5e-5, step_loss=0.0538]Steps:  92%|█████████▏| 361/391 [3:27:06<17:06, 34.21s/it, lr=5e-5, step_loss=0.0277]Steps:  92%|█████████▏| 361/391 [3:27:15<17:06, 34.21s/it, lr=5e-5, step_loss=0.0297]Steps:  93%|█████████▎| 362/391 [3:27:23<16:10, 33.47s/it, lr=5e-5, step_loss=0.0297]Steps:  93%|█████████▎| 362/391 [3:27:23<16:10, 33.47s/it, lr=5e-5, step_loss=0.0461]Steps:  93%|█████████▎| 362/391 [3:27:31<16:10, 33.47s/it, lr=5e-5, step_loss=0.0682]Steps:  93%|█████████▎| 362/391 [3:27:39<16:10, 33.47s/it, lr=5e-5, step_loss=0.0405]Steps:  93%|█████████▎| 362/391 [3:27:47<16:10, 33.47s/it, lr=5e-5, step_loss=0.0481]Steps:  93%|█████████▎| 363/391 [3:27:55<15:29, 33.21s/it, lr=5e-5, step_loss=0.0481]Steps:  93%|█████████▎| 363/391 [3:27:55<15:29, 33.21s/it, lr=5e-5, step_loss=0.0419]Steps:  93%|█████████▎| 363/391 [3:28:04<15:29, 33.21s/it, lr=5e-5, step_loss=0.0442]Steps:  93%|█████████▎| 363/391 [3:28:12<15:29, 33.21s/it, lr=5e-5, step_loss=0.048] Steps:  93%|█████████▎| 363/391 [3:28:20<15:29, 33.21s/it, lr=5e-5, step_loss=0.0316]Steps:  93%|█████████▎| 364/391 [3:28:28<14:54, 33.13s/it, lr=5e-5, step_loss=0.0316]Steps:  93%|█████████▎| 364/391 [3:28:28<14:54, 33.13s/it, lr=5e-5, step_loss=0.0451]Steps:  93%|█████████▎| 364/391 [3:28:36<14:54, 33.13s/it, lr=5e-5, step_loss=0.0327]Steps:  93%|█████████▎| 364/391 [3:28:44<14:54, 33.13s/it, lr=5e-5, step_loss=0.043] Steps:  93%|█████████▎| 364/391 [3:28:52<14:54, 33.13s/it, lr=5e-5, step_loss=0.0542]Steps:  93%|█████████▎| 365/391 [3:29:00<14:07, 32.59s/it, lr=5e-5, step_loss=0.0542]Steps:  93%|█████████▎| 365/391 [3:29:00<14:07, 32.59s/it, lr=5e-5, step_loss=0.0434]Steps:  93%|█████████▎| 365/391 [3:29:08<14:07, 32.59s/it, lr=5e-5, step_loss=0.0346]Steps:  93%|█████████▎| 365/391 [3:29:17<14:07, 32.59s/it, lr=5e-5, step_loss=0.047] Steps:  93%|█████████▎| 365/391 [3:29:25<14:07, 32.59s/it, lr=5e-5, step_loss=0.0468]Steps:  94%|█████████▎| 366/391 [3:29:33<13:37, 32.69s/it, lr=5e-5, step_loss=0.0468]Steps:  94%|█████████▎| 366/391 [3:29:33<13:37, 32.69s/it, lr=5e-5, step_loss=0.0448]Steps:  94%|█████████▎| 366/391 [3:29:41<13:37, 32.69s/it, lr=5e-5, step_loss=0.0324]Steps:  94%|█████████▎| 366/391 [3:29:49<13:37, 32.69s/it, lr=5e-5, step_loss=0.045] Steps:  94%|█████████▎| 366/391 [3:29:58<13:37, 32.69s/it, lr=5e-5, step_loss=0.0431]Steps:  94%|█████████▍| 367/391 [3:30:07<13:13, 33.08s/it, lr=5e-5, step_loss=0.0431]Steps:  94%|█████████▍| 367/391 [3:30:07<13:13, 33.08s/it, lr=5e-5, step_loss=0.0375]Steps:  94%|█████████▍| 367/391 [3:30:14<13:13, 33.08s/it, lr=5e-5, step_loss=0.0424]Steps:  94%|█████████▍| 368/391 [3:30:15<09:47, 25.53s/it, lr=5e-5, step_loss=0.0424]Steps:  94%|█████████▍| 368/391 [3:30:15<09:47, 25.53s/it, lr=5e-5, step_loss=0.0534]Steps:  94%|█████████▍| 368/391 [3:30:30<09:47, 25.53s/it, lr=5e-5, step_loss=0.0548]Steps:  94%|█████████▍| 368/391 [3:30:39<09:47, 25.53s/it, lr=5e-5, step_loss=0.0493]Steps:  94%|█████████▍| 368/391 [3:30:46<09:47, 25.53s/it, lr=5e-5, step_loss=0.0357]Steps:  94%|█████████▍| 369/391 [3:30:54<10:52, 29.67s/it, lr=5e-5, step_loss=0.0357]Steps:  94%|█████████▍| 369/391 [3:30:54<10:52, 29.67s/it, lr=5e-5, step_loss=0.0424]Steps:  94%|█████████▍| 369/391 [3:31:03<10:52, 29.67s/it, lr=5e-5, step_loss=0.0501]Steps:  94%|█████████▍| 369/391 [3:31:10<10:52, 29.67s/it, lr=5e-5, step_loss=0.0444]Steps:  94%|█████████▍| 369/391 [3:31:18<10:52, 29.67s/it, lr=5e-5, step_loss=0.0494]Steps:  95%|█████████▍| 370/391 [3:31:26<10:39, 30.43s/it, lr=5e-5, step_loss=0.0494]Steps:  95%|█████████▍| 370/391 [3:31:26<10:39, 30.43s/it, lr=5e-5, step_loss=0.0501]Steps:  95%|█████████▍| 370/391 [3:31:35<10:39, 30.43s/it, lr=5e-5, step_loss=0.0498]Steps:  95%|█████████▍| 370/391 [3:31:43<10:39, 30.43s/it, lr=5e-5, step_loss=0.043] Steps:  95%|█████████▍| 370/391 [3:31:50<10:39, 30.43s/it, lr=5e-5, step_loss=0.0343]Steps:  95%|█████████▍| 371/391 [3:32:00<10:28, 31.44s/it, lr=5e-5, step_loss=0.0343]Steps:  95%|█████████▍| 371/391 [3:32:00<10:28, 31.44s/it, lr=5e-5, step_loss=0.0513]Steps:  95%|█████████▍| 371/391 [3:32:08<10:28, 31.44s/it, lr=5e-5, step_loss=0.0503]Steps:  95%|█████████▍| 371/391 [3:32:17<10:28, 31.44s/it, lr=5e-5, step_loss=0.0564]Steps:  95%|█████████▍| 371/391 [3:32:26<10:28, 31.44s/it, lr=5e-5, step_loss=0.0411]Steps:  95%|█████████▌| 372/391 [3:32:34<10:14, 32.34s/it, lr=5e-5, step_loss=0.0411]Steps:  95%|█████████▌| 372/391 [3:32:34<10:14, 32.34s/it, lr=5e-5, step_loss=0.0318]Steps:  95%|█████████▌| 372/391 [3:32:43<10:14, 32.34s/it, lr=5e-5, step_loss=0.0354]Steps:  95%|█████████▌| 372/391 [3:32:50<10:14, 32.34s/it, lr=5e-5, step_loss=0.0723]Steps:  95%|█████████▌| 372/391 [3:32:58<10:14, 32.34s/it, lr=5e-5, step_loss=0.0563]Steps:  95%|█████████▌| 373/391 [3:33:07<09:44, 32.48s/it, lr=5e-5, step_loss=0.0563]Steps:  95%|█████████▌| 373/391 [3:33:07<09:44, 32.48s/it, lr=5e-5, step_loss=0.0404]Steps:  95%|█████████▌| 373/391 [3:33:15<09:44, 32.48s/it, lr=5e-5, step_loss=0.0488]Steps:  95%|█████████▌| 373/391 [3:33:24<09:44, 32.48s/it, lr=5e-5, step_loss=0.0332]Steps:  95%|█████████▌| 373/391 [3:33:31<09:44, 32.48s/it, lr=5e-5, step_loss=0.03]  Steps:  96%|█████████▌| 374/391 [3:33:39<09:07, 32.21s/it, lr=5e-5, step_loss=0.03]Steps:  96%|█████████▌| 374/391 [3:33:39<09:07, 32.21s/it, lr=5e-5, step_loss=0.0364]Steps:  96%|█████████▌| 374/391 [3:33:47<09:07, 32.21s/it, lr=5e-5, step_loss=0.0495]Steps:  96%|█████████▌| 374/391 [3:33:56<09:07, 32.21s/it, lr=5e-5, step_loss=0.0412]Steps:  96%|█████████▌| 374/391 [3:34:04<09:07, 32.21s/it, lr=5e-5, step_loss=0.0583]Steps:  96%|█████████▌| 375/391 [3:34:12<08:42, 32.65s/it, lr=5e-5, step_loss=0.0583]Steps:  96%|█████████▌| 375/391 [3:34:12<08:42, 32.65s/it, lr=5e-5, step_loss=0.0356]Steps:  96%|█████████▌| 375/391 [3:34:21<08:42, 32.65s/it, lr=5e-5, step_loss=0.0361]Steps:  96%|█████████▌| 375/391 [3:34:29<08:42, 32.65s/it, lr=5e-5, step_loss=0.0395]Steps:  96%|█████████▌| 375/391 [3:34:38<08:42, 32.65s/it, lr=5e-5, step_loss=0.0553]Steps:  96%|█████████▌| 376/391 [3:34:46<08:14, 32.97s/it, lr=5e-5, step_loss=0.0553]Steps:  96%|█████████▌| 376/391 [3:34:46<08:14, 32.97s/it, lr=5e-5, step_loss=0.0541]Steps:  96%|█████████▌| 376/391 [3:34:54<08:14, 32.97s/it, lr=5e-5, step_loss=0.0567]Steps:  96%|█████████▌| 376/391 [3:35:03<08:14, 32.97s/it, lr=5e-5, step_loss=0.0555]Steps:  96%|█████████▌| 376/391 [3:35:10<08:14, 32.97s/it, lr=5e-5, step_loss=0.044] Steps:  96%|█████████▋| 377/391 [3:35:19<07:39, 32.83s/it, lr=5e-5, step_loss=0.044]Steps:  96%|█████████▋| 377/391 [3:35:19<07:39, 32.83s/it, lr=5e-5, step_loss=0.0367]Steps:  96%|█████████▋| 377/391 [3:35:26<07:39, 32.83s/it, lr=5e-5, step_loss=0.0376]Steps:  96%|█████████▋| 377/391 [3:35:35<07:39, 32.83s/it, lr=5e-5, step_loss=0.0448]Steps:  96%|█████████▋| 377/391 [3:35:43<07:39, 32.83s/it, lr=5e-5, step_loss=0.0408]Steps:  97%|█████████▋| 378/391 [3:35:52<07:07, 32.92s/it, lr=5e-5, step_loss=0.0408]Steps:  97%|█████████▋| 378/391 [3:35:52<07:07, 32.92s/it, lr=5e-5, step_loss=0.056] Steps:  97%|█████████▋| 378/391 [3:35:59<07:07, 32.92s/it, lr=5e-5, step_loss=0.0527]Steps:  97%|█████████▋| 378/391 [3:36:07<07:07, 32.92s/it, lr=5e-5, step_loss=0.0724]Steps:  97%|█████████▋| 378/391 [3:36:15<07:07, 32.92s/it, lr=5e-5, step_loss=0.0455]Steps:  97%|█████████▋| 379/391 [3:36:23<06:30, 32.54s/it, lr=5e-5, step_loss=0.0455]Steps:  97%|█████████▋| 379/391 [3:36:23<06:30, 32.54s/it, lr=5e-5, step_loss=0.047] Steps:  97%|█████████▋| 379/391 [3:36:31<06:30, 32.54s/it, lr=5e-5, step_loss=0.0457]Steps:  97%|█████████▋| 379/391 [3:36:40<06:30, 32.54s/it, lr=5e-5, step_loss=0.0489]Steps:  97%|█████████▋| 379/391 [3:36:48<06:30, 32.54s/it, lr=5e-5, step_loss=0.0487]Steps:  97%|█████████▋| 380/391 [3:36:56<05:56, 32.43s/it, lr=5e-5, step_loss=0.0487]Steps:  97%|█████████▋| 380/391 [3:36:56<05:56, 32.43s/it, lr=5e-5, step_loss=0.0595]Steps:  97%|█████████▋| 380/391 [3:37:03<05:56, 32.43s/it, lr=5e-5, step_loss=0.0386]Steps:  97%|█████████▋| 380/391 [3:37:11<05:56, 32.43s/it, lr=5e-5, step_loss=0.0415]Steps:  97%|█████████▋| 380/391 [3:37:20<05:56, 32.43s/it, lr=5e-5, step_loss=0.0543]Steps:  97%|█████████▋| 381/391 [3:37:27<05:20, 32.07s/it, lr=5e-5, step_loss=0.0543]Steps:  97%|█████████▋| 381/391 [3:37:27<05:20, 32.07s/it, lr=5e-5, step_loss=0.0412]Steps:  97%|█████████▋| 381/391 [3:37:36<05:20, 32.07s/it, lr=5e-5, step_loss=0.0414]Steps:  97%|█████████▋| 381/391 [3:37:44<05:20, 32.07s/it, lr=5e-5, step_loss=0.0654]Steps:  97%|█████████▋| 381/391 [3:37:52<05:20, 32.07s/it, lr=5e-5, step_loss=0.0697]Steps:  98%|█████████▊| 382/391 [3:38:01<04:54, 32.75s/it, lr=5e-5, step_loss=0.0697]Steps:  98%|█████████▊| 382/391 [3:38:01<04:54, 32.75s/it, lr=5e-5, step_loss=0.0374]Steps:  98%|█████████▊| 382/391 [3:38:09<04:54, 32.75s/it, lr=5e-5, step_loss=0.0285]Steps:  98%|█████████▊| 382/391 [3:38:17<04:54, 32.75s/it, lr=5e-5, step_loss=0.0368]Steps:  98%|█████████▊| 382/391 [3:38:25<04:54, 32.75s/it, lr=5e-5, step_loss=0.0424]Steps:  98%|█████████▊| 383/391 [3:38:34<04:22, 32.78s/it, lr=5e-5, step_loss=0.0424]Steps:  98%|█████████▊| 383/391 [3:38:34<04:22, 32.78s/it, lr=5e-5, step_loss=0.0556]Steps:  98%|█████████▊| 383/391 [3:38:41<04:22, 32.78s/it, lr=5e-5, step_loss=0.0448]Steps:  98%|█████████▊| 383/391 [3:38:50<04:22, 32.78s/it, lr=5e-5, step_loss=0.0518]Steps:  98%|█████████▊| 383/391 [3:38:59<04:22, 32.78s/it, lr=5e-5, step_loss=0.0446]Steps:  98%|█████████▊| 384/391 [3:39:06<03:48, 32.61s/it, lr=5e-5, step_loss=0.0446]Steps:  98%|█████████▊| 384/391 [3:39:06<03:48, 32.61s/it, lr=5e-5, step_loss=0.0412]Steps:  98%|█████████▊| 384/391 [3:39:13<03:48, 32.61s/it, lr=5e-5, step_loss=0.045] Steps:  98%|█████████▊| 384/391 [3:39:21<03:48, 32.61s/it, lr=5e-5, step_loss=0.039]Steps:  98%|█████████▊| 384/391 [3:39:28<03:48, 32.61s/it, lr=5e-5, step_loss=0.0482]Steps:  98%|█████████▊| 385/391 [3:39:37<03:12, 32.13s/it, lr=5e-5, step_loss=0.0482]Steps:  98%|█████████▊| 385/391 [3:39:37<03:12, 32.13s/it, lr=5e-5, step_loss=0.0447]Steps:  98%|█████████▊| 385/391 [3:39:46<03:12, 32.13s/it, lr=5e-5, step_loss=0.0471]Steps:  98%|█████████▊| 385/391 [3:39:55<03:12, 32.13s/it, lr=5e-5, step_loss=0.0392]Steps:  98%|█████████▊| 385/391 [3:40:04<03:12, 32.13s/it, lr=5e-5, step_loss=0.0473]Steps:  99%|█████████▊| 386/391 [3:40:12<02:45, 33.02s/it, lr=5e-5, step_loss=0.0473]Steps:  99%|█████████▊| 386/391 [3:40:12<02:45, 33.02s/it, lr=5e-5, step_loss=0.0516]Steps:  99%|█████████▊| 386/391 [3:40:21<02:45, 33.02s/it, lr=5e-5, step_loss=0.0653]Steps:  99%|█████████▊| 386/391 [3:40:28<02:45, 33.02s/it, lr=5e-5, step_loss=0.0426]Steps:  99%|█████████▊| 386/391 [3:40:36<02:45, 33.02s/it, lr=5e-5, step_loss=0.0481]Steps:  99%|█████████▉| 387/391 [3:40:45<02:11, 32.85s/it, lr=5e-5, step_loss=0.0481]Steps:  99%|█████████▉| 387/391 [3:40:45<02:11, 32.85s/it, lr=5e-5, step_loss=0.0446]Steps:  99%|█████████▉| 387/391 [3:40:54<02:11, 32.85s/it, lr=5e-5, step_loss=0.0447]Steps:  99%|█████████▉| 387/391 [3:41:03<02:11, 32.85s/it, lr=5e-5, step_loss=0.0322]Steps:  99%|█████████▉| 387/391 [3:41:11<02:11, 32.85s/it, lr=5e-5, step_loss=0.0453]Steps:  99%|█████████▉| 388/391 [3:41:19<01:39, 33.27s/it, lr=5e-5, step_loss=0.0453]Steps:  99%|█████████▉| 388/391 [3:41:19<01:39, 33.27s/it, lr=5e-5, step_loss=0.0512]Steps:  99%|█████████▉| 388/391 [3:41:28<01:39, 33.27s/it, lr=5e-5, step_loss=0.0477]Steps:  99%|█████████▉| 388/391 [3:41:36<01:39, 33.27s/it, lr=5e-5, step_loss=0.0389]Steps:  99%|█████████▉| 388/391 [3:41:44<01:39, 33.27s/it, lr=5e-5, step_loss=0.0358]Steps:  99%|█████████▉| 389/391 [3:41:53<01:06, 33.36s/it, lr=5e-5, step_loss=0.0358]Steps:  99%|█████████▉| 389/391 [3:41:53<01:06, 33.36s/it, lr=5e-5, step_loss=0.0278]Steps:  99%|█████████▉| 389/391 [3:42:00<01:06, 33.36s/it, lr=5e-5, step_loss=0.0367]Steps:  99%|█████████▉| 389/391 [3:42:08<01:06, 33.36s/it, lr=5e-5, step_loss=0.0535]Steps:  99%|█████████▉| 389/391 [3:42:16<01:06, 33.36s/it, lr=5e-5, step_loss=0.0433]Steps: 100%|█████████▉| 390/391 [3:42:24<00:32, 32.77s/it, lr=5e-5, step_loss=0.0433]06/08/2025 13:11:00 - INFO - __main__ - 1 checkpoints already exist, removing 1 checkpoints
06/08/2025 13:11:00 - INFO - __main__ - removing checkpoints: checkpoint-300
06/08/2025 13:11:00 - INFO - accelerate.accelerator - Saving current state to finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-390
Configuration saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-390/unet_ema/config.json
Model weights saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-390/unet_ema/diffusion_pytorch_model.safetensors
Configuration saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-390/unet/config.json
Model weights saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-390/unet/diffusion_pytorch_model.safetensors
06/08/2025 13:11:22 - INFO - accelerate.checkpointing - Optimizer state saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-390/optimizer.bin
06/08/2025 13:11:22 - INFO - accelerate.checkpointing - Scheduler state saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-390/scheduler.bin
06/08/2025 13:11:22 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-390/sampler.bin
06/08/2025 13:11:22 - INFO - accelerate.checkpointing - Gradient scaler state saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-390/scaler.pt
06/08/2025 13:11:22 - INFO - accelerate.checkpointing - Random states saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-390/random_states_0.pkl
06/08/2025 13:11:22 - INFO - __main__ - Saved state to finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/checkpoint-390
Steps: 100%|█████████▉| 390/391 [3:42:46<00:32, 32.77s/it, lr=5e-5, step_loss=0.0372]Steps: 100%|█████████▉| 390/391 [3:42:53<00:32, 32.77s/it, lr=5e-5, step_loss=0.0521]Steps: 100%|██████████| 391/391 [3:42:54<00:00, 31.97s/it, lr=5e-5, step_loss=0.0521]Steps: 100%|██████████| 391/391 [3:42:54<00:00, 31.97s/it, lr=5e-5, step_loss=0.0436]{'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of pretrained_frameworks/pretrained_IEDMs/instruct-pix2pix.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:01,  3.41it/s][A{'rescale_betas_zero_snr', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as EulerAncestralDiscreteScheduler from `scheduler` subfolder of pretrained_frameworks/pretrained_IEDMs/instruct-pix2pix.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of pretrained_frameworks/pretrained_IEDMs/instruct-pix2pix.
Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of pretrained_frameworks/pretrained_IEDMs/instruct-pix2pix.
Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00, 10.84it/s]
Configuration saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/vae/config.json
Model weights saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/vae/diffusion_pytorch_model.safetensors
Configuration saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/unet/config.json
Model weights saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/unet/diffusion_pytorch_model.safetensors
Configuration saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/scheduler/scheduler_config.json
Configuration saved in finetuned_models/ip2p_nollm_res256_lr5e-5_pretrained_unet_1000steps_13laststeps/model_index.json
Steps: 100%|██████████| 391/391 [3:43:02<00:00, 34.23s/it, lr=5e-5, step_loss=0.0436]
